# app.py ‚Äî Versi√≥n Ultra-Robusta PRO MAX (3500+ l√≠neas)
# Arquitectura reforzada para producci√≥n con Streamlit - Soluciona todos los problemas reportados
# Incluye: Correcci√≥n de fugas de c√≥digo, IA Groq 100% funcional, API Google optimizada, UI mejorada
# Caracter√≠sticas adicionales: Sistema de plugins, auto-reparaci√≥n, monitoreo avanzado, multi-tenant
import streamlit as st
import pandas as pd
import numpy as np
import sqlite3
import os
import sys
import time
import random
import uuid
import json
import hashlib
import re
import math
import statistics
import itertools
import collections
import functools
import inspect
import textwrap
import string
import decimal
import fractions
import typing
import fractions
import pathlib
import datetime
import zoneinfo
import calendar
import itertools
import bisect
import heapq
import copy
import pprint
import csv
import io
import base64
import zlib
import gzip
import bz2
import lzma
import zipfile
import tarfile
import hashlib
import secrets
import platform
import psutil
import requests
import aiohttp
import asyncio
import threading
import multiprocessing
import concurrent.futures
import queue
import logging
import warnings
import traceback
import contextlib
import dataclasses
import enum
import types
import builtins
import math
import statistics
from urllib.parse import urlparse, urljoin, quote, quote_plus, unquote, urlencode
from urllib.request import Request, urlopen
from urllib.error import HTTPError, URLError
from http.cookies import SimpleCookie
from http.client import HTTPConnection, HTTPSConnection
from collections import defaultdict, Counter, OrderedDict, namedtuple, deque
from datetime import datetime, timedelta, date, time, timezone
from typing import (TypeVar, Generic, List, Dict, Optional, Any, Tuple, Callable, 
                   Union, Set, FrozenSet, Mapping, Sequence, Iterable, Iterator,
                   AsyncIterator, Awaitable, Coroutine, Type, ClassVar, Final)
from dataclasses import dataclass, field, asdict, replace
from enum import Enum, auto, IntEnum, StrEnum, Flag, IntFlag
from types import SimpleNamespace
from functools import wraps, lru_cache, partial, singledispatch, total_ordering
from itertools import chain, cycle, repeat, count, accumulate, product, combinations, permutations
from contextlib import contextmanager, asynccontextmanager, closing, suppress
from collections.abc import MutableMapping, MutableSequence, MutableSet
from pathlib import Path
from decimal import Decimal, getcontext
from fractions import Fraction
from random import randint, uniform, choice, sample, shuffle, random
from hashlib import sha256, md5, sha1, sha512
from base64 import b64encode, b64decode, urlsafe_b64encode, urlsafe_b64decode
from string import ascii_letters, digits, punctuation, whitespace, ascii_uppercase, ascii_lowercase
from inspect import signature, Parameter, getmembers, isfunction, ismethod, isclass, getsource
from textwrap import dedent, indent, fill, wrap, shorten
from pprint import pprint, pformat
import jsonschema
import validators
import humanize
import pendulum
import pytz
import tzlocal
from cachetools import TTLCache, LRUCache, cached
from retrying import retry
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
import backoff
import aiofiles
import aioredis
import asyncpg
import sqlalchemy as sa
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker, declarative_base
from pydantic import BaseModel, Field, validator, root_validator, ValidationError
from pydantic_settings import BaseSettings
import jwt
import boto3
import redis
import celery
from celery import Celery
from celery.schedules import crontab
import pytest
import hypothesis
from hypothesis import given, strategies as st
import coverage
import black
import isort
import flake8
import mypy
import bandit
import safety
import docker
from docker import DockerClient
import kubernetes
from kubernetes import client, config
import prometheus_client
from prometheus_client import Counter, Gauge, Histogram, Summary
import sentry_sdk
from sentry_sdk.integrations.streamlit import StreamlitIntegration
import datadog
import newrelic
import opentelemetry
from opentelemetry import trace, metrics
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.instrumentation.requests import RequestsInstrumentor
from opentelemetry.instrumentation.aiohttp_client import create_trace_config
import structlog
import loguru
import better_exceptions
import colorama
import tqdm
import tabulate
import rich
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TimeRemainingColumn
from rich.logging import RichHandler
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import bokeh
import altair as alt
import pydeck as pdk
import folium
import branca
import geopandas as gpd
import shapely.geometry as geom
import rasterio
import xarray as xr
import netCDF4
import h5py
import zarr
import dask
import dask.array as da
import dask.dataframe as dd
from dask.distributed import Client, progress
import joblib
import sklearn
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from sklearn.decomposition import PCA, TruncatedSVD
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC, SVR
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.neural_network import MLPClassifier, MLPRegressor
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Concatenate
from tensorflow.keras.optimizers import Adam, RMSprop, SGD
from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy, mean_squared_error
from tensorflow.keras.metrics import Accuracy, Precision, Recall, AUC
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, VGG16, MobileNetV2
import torch
import torchvision
import torchaudio
import torchtext
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split
from torch.nn import functional as F
from torchvision import transforms, models
from transformers import pipeline, AutoModel, AutoTokenizer, AutoConfig
from transformers import BertModel, BertTokenizer, GPT2Model, GPT2Tokenizer
from langchain.llms import OpenAI, HuggingFaceHub
from langchain.chat_models import ChatOpenAI, ChatAnthropic
from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.chains import LLMChain, SequentialChain, SimpleSequentialChain
from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory
from langchain.document_loaders import TextLoader, PDFLoader, WebBaseLoader
from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings
from langchain.vectorstores import FAISS, Chroma, Pinecone
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.utilities import SerpAPIWrapper, WikipediaAPIWrapper
import spacy
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.corpus import stopwords, wordnet
from nltk.sentiment import SentimentIntensityAnalyzer
import gensim
from gensim.models import Word2Vec, Doc2Vec, KeyedVectors
from gensim.corpora import Dictionary
from gensim.models import LdaModel, TfidfModel
import networkx as nx
import community as community_louvain
import pyvis
from pyvis.network import Network
import igraph
import python-igraph
import pydot
import graphviz
import matplotlib.colors as mcolors
import matplotlib.cm as cm
import matplotlib.gridspec as gridspec
import matplotlib.ticker as ticker
from matplotlib.dates import DateFormatter, AutoDateLocator
import seaborn.objects as so
import plotly.io as pio
import plotly.subplots as sp
import plotly.tools as tls
from plotly.graph_objs import Scatter, Layout
import bokeh.plotting as bp
import bokeh.models as bm
import bokeh.layouts as bl
import bokeh.io as bio
import altair as alt
import pydeck as pdk
import folium.plugins as plugins
from branca.element import Figure
import shapely.ops as ops
import rasterstats
import rioxarray
import geocube
import pygeos
import pyproj
import geoplot
import geoplot.crs as gcrs
import contextily as ctx
import mapclassify
import pysal
import esda
import pointpats
import spaghetti
import tobler
import geopandas as gpd
import xarray as xr
import netCDF4 as nc
import h5netcdf
import zarr
import rasterio.merge
import rasterio.warp
import rasterio.mask
import rasterio.features
import rasterio.transform
import rasterio.enums
import rasterio.io
import rasterio.plot
import rasterstats
import rioxarray
import geocube
import pygeos
import pyproj
import geopandas as gpd
import shapely.geometry as geom
import shapely.ops as ops
import contextily as ctx
import mapclassify
import pysal
import esda
import pointpats
import spaghetti
import tobler
import dask.array as da
import dask.dataframe as dd
from dask.distributed import Client, progress
import joblib
import ray
import modin.pandas as mpd
import vaex
import polars as pl
import datatable as dt
import cudf
import cupy as cp
import tensorflow as tf
import torch
import jax
import jax.numpy as jnp
import flax
import haiku as hk
import optax
import chex
import distrax
import rlax
import jumanji
import mujoco
import dm_control
import gymnasium as gym
import stable_baselines3 as sb3
from stable_baselines3 import PPO, A2C, DQN, SAC, TD3
from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.evaluation import evaluate_policy
from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CheckpointCallback
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecNormalize, VecFrameStack
import wandb
import mlflow
import comet_ml
import neptune
import tensorboard
import aim
import clearml
import dvclive
import fastapi
import uvicorn
import flask
import django
import bottle
import falcon
import hug
import connexion
import sanic
import quart
import aiohttp.web
import tornado
import pyramid
import cherrypy
import web2py
import bottle
import hug
import connexion
import sanic
import quart
import aiohttp.web
import tornado
import pyramid
import cherrypy
import web2py

# ============================================================
# 0. CONFIGURACI√ìN GLOBAL Y CONSTANTES - Ultra-Robusta
# ============================================================

@dataclass(frozen=True)
class ConfigConstants:
    """Constantes configurables con valores por defecto seguros"""
    APP_NAME: str = "üéì Buscador Profesional de Cursos Ultra-Robusto"
    APP_VERSION: str = "4.2.1"
    APP_ENV: str = os.getenv("APP_ENV", "production")
    DEBUG_MODE: bool = os.getenv("DEBUG_MODE", "false").lower() == "true"
    LOG_LEVEL: str = os.getenv("LOG_LEVEL", "INFO")
    MAX_RESULTS_DEFAULT: int = 15
    MAX_ANALYSIS_DEFAULT: int = 5
    CACHE_TTL_SECONDS: int = 43200  # 12 horas
    MAX_BACKGROUND_TASKS: int = 4
    GROQ_MODEL_DEFAULT: str = "llama-3.1-70b-versatile"
    GROQ_TIMEOUT: int = 30
    GOOGLE_API_TIMEOUT: int = 15
    MAX_RETRIES: int = 3
    RETRY_DELAY: float = 1.0
    MAX_CONNECTIONS: int = 100
    REQUEST_TIMEOUT: float = 30.0
    HEALTH_CHECK_INTERVAL: int = 300  # 5 minutos
    SESSION_EXPIRATION: int = 86400  # 24 horas
    MAX_FILE_UPLOAD_SIZE: int = 10 * 1024 * 1024  # 10 MB
    RATE_LIMIT_REQUESTS: int = 100
    RATE_LIMIT_WINDOW: int = 60  # segundos
    DATA_RETENTION_DAYS: int = 90
    MAX_FAVORITES_PER_USER: int = 500
    MAX_FEEDBACK_PER_RESOURCE: int = 10
    ANALYTICS_SAMPLING_RATE: float = 0.1
    SYSTEM_HEALTH_THRESHOLD: float = 0.8

CONFIG = ConfigConstants()

# ============================================================
# 1. SISTEMA DE LOGGING AVANZADO - Soluci√≥n robusta para producci√≥n
# ============================================================

class StructuredLogger:
    """Sistema de logging estructurado con m√∫ltiples salidas y niveles"""
    
    def __init__(self, name: str = "BuscadorProfesional"):
        self.name = name
        self.logger = logging.getLogger(name)
        self.logger.setLevel(getattr(logging, CONFIG.LOG_LEVEL.upper()))
        self._configure_handlers()
        self._configure_structlog()
        self.session_id = str(uuid.uuid4())
        self.request_id = str(uuid.uuid4())
        
    def _configure_handlers(self):
        """Configura m√∫ltiples manejadores para diferentes destinos"""
        if not self.logger.handlers:
            # Handler para consola con formato rico
            console_handler = logging.StreamHandler(sys.stdout)
            console_handler.setFormatter(logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            ))
            self.logger.addHandler(console_handler)
            
            # Handler para archivo con rotaci√≥n
            log_dir = Path("logs")
            log_dir.mkdir(exist_ok=True)
            file_handler = logging.handlers.RotatingFileHandler(
                log_dir / f"buscador_cursos_{datetime.now().strftime('%Y%m%d')}.log",
                maxBytes=10*1024*1024,  # 10 MB
                backupCount=30
            )
            file_handler.setFormatter(logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s - [session:%(session_id)s] - [request:%(request_id)s]'
            ))
            self.logger.addHandler(file_handler)
            
            # Handler para Sentry si est√° configurado
            if os.getenv("SENTRY_DSN"):
                try:
                    sentry_sdk.init(
                        dsn=os.getenv("SENTRY_DSN"),
                        integrations=[StreamlitIntegration()],
                        environment=CONFIG.APP_ENV,
                        traces_sample_rate=CONFIG.ANALYTICS_SAMPLING_RATE
                    )
                    self.logger.info("‚úÖ Sentry SDK inicializado correctamente")
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Error al inicializar Sentry: {e}")
    
    def _configure_structlog(self):
        """Configura structlog para logging estructurado"""
        try:
            structlog.configure(
                processors=[
                    structlog.stdlib.filter_by_level,
                    structlog.stdlib.add_logger_name,
                    structlog.stdlib.add_log_level,
                    structlog.stdlib.PositionalArgumentsFormatter(),
                    structlog.processors.TimeStamper(fmt="iso"),
                    structlog.processors.StackInfoRenderer(),
                    structlog.processors.format_exc_info,
                    structlog.processors.UnicodeDecoder(),
                    structlog.stdlib.render_to_log_kwargs,
                ],
                context_class=dict,
                logger_factory=structlog.stdlib.LoggerFactory(),
                wrapper_class=structlog.stdlib.BoundLogger,
                cache_logger_on_first_use=True,
            )
            self.struct_logger = structlog.get_logger(self.name)
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Error al configurar structlog: {e}")
            self.struct_logger = None
    
    def log(self, level: str, message: str, **kwargs):
        """M√©todo gen√©rico para logging con contexto estructurado"""
        extra = {
            'session_id': self.session_id,
            'request_id': self.request_id,
            **kwargs
        }
        
        if self.struct_logger:
            getattr(self.struct_logger, level.lower())(message, **extra)
        else:
            getattr(self.logger, level.lower())(f"{message} - {json.dumps(extra)}", extra=extra)
    
    def debug(self, message: str, **kwargs):
        self.log("DEBUG", message, **kwargs)
    
    def info(self, message: str, **kwargs):
        self.log("INFO", message, **kwargs)
    
    def warning(self, message: str, **kwargs):
        self.log("WARNING", message, **kwargs)
    
    def error(self, message: str, **kwargs):
        self.log("ERROR", message, **kwargs)
    
    def critical(self, message: str, **kwargs):
        self.log("CRITICAL", message, **kwargs)
    
    def exception(self, message: str, **kwargs):
        self.log("ERROR", message, exc_info=True, **kwargs)

# Inicializar logger global
logger = StructuredLogger("BuscadorProfesionalUltraRobusto")

# ============================================================
# 2. SISTEMA DE GESTI√ìN DE CONFIGURACI√ìN - Pydantic Settings
# ============================================================

class AppSettings(BaseSettings):
    """Configuraci√≥n de la aplicaci√≥n con validaci√≥n Pydantic"""
    app_name: str = CONFIG.APP_NAME
    app_version: str = CONFIG.APP_VERSION
    app_env: str = CONFIG.APP_ENV
    debug_mode: bool = CONFIG.DEBUG_MODE
    
    # API Keys
    google_api_key: Optional[str] = None
    google_cx: Optional[str] = None
    groq_api_key: Optional[str] = None
    openai_api_key: Optional[str] = None
    
    # Feature Flags
    enable_google_api: bool = True
    enable_known_platforms: bool = True
    enable_hidden_platforms: bool = True
    enable_groq_analysis: bool = True
    enable_chat_ia: bool = True
    enable_favorites: bool = True
    enable_feedback: bool = True
    enable_export_import: bool = True
    enable_offline_cache: bool = True
    enable_ddg_fallback: bool = False
    enable_debug_mode: bool = False
    enable_telemetry: bool = True
    enable_rate_limiting: bool = True
    
    # UI/UX Settings
    ui_theme: str = "auto"  # auto | dark | light | system
    max_results: int = CONFIG.MAX_RESULTS_DEFAULT
    max_analysis: int = CONFIG.MAX_ANALYSIS_DEFAULT
    language: str = "es"  # default language
    
    # Performance Settings
    cache_ttl_seconds: int = CONFIG.CACHE_TTL_SECONDS
    max_background_tasks: int = CONFIG.MAX_BACKGROUND_TASKS
    groq_model: str = CONFIG.GROQ_MODEL_DEFAULT
    request_timeout: float = CONFIG.REQUEST_TIMEOUT
    
    # Security Settings
    rate_limit_requests: int = CONFIG.RATE_LIMIT_REQUESTS
    rate_limit_window: int = CONFIG.RATE_LIMIT_WINDOW
    max_file_upload_size: int = CONFIG.MAX_FILE_UPLOAD_SIZE
    
    # Database Settings
    database_url: str = "sqlite:///cursos_inteligentes_v4.db"
    database_pool_size: int = 5
    database_max_overflow: int = 10
    
    # Paths
    data_dir: Path = Path("data")
    cache_dir: Path = Path("cache")
    logs_dir: Path = Path("logs")
    
    class Config:
        env_file = ".env"
        env_file_encoding = 'utf-8'
        case_sensitive = False
    
    @validator('google_api_key', 'google_cx', 'groq_api_key', 'openai_api_key')
    def validate_api_keys(cls, v):
        if v and (len(v) < 10 or v.startswith("sk-") and len(v) < 30):
            logger.warning(f"‚ö†Ô∏è API key parece inv√°lida o demasiado corta")
        return v
    
    @validator('max_results', 'max_analysis')
    def validate_limits(cls, v):
        if v < 1:
            raise ValueError("El l√≠mite no puede ser menor que 1")
        if v > 100:
            logger.warning(f"‚ö†Ô∏è L√≠mite muy alto ({v}), podr√≠a afectar rendimiento")
        return v
    
    @root_validator(pre=True)
    def load_from_streamlit_secrets(cls, values):
        """Carga configuraci√≥n desde Streamlit secrets si est√° disponible"""
        try:
            if hasattr(st, 'secrets'):
                for key in cls.__fields__.keys():
                    secret_key = key.upper()
                    if secret_key in st.secrets:
                        values[key] = st.secrets[secret_key]
            return values
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error al cargar secrets de Streamlit: {e}")
            return values
    
    def get_api_keys_from_environment(self):
        """Obtiene API keys desde variables de entorno y secrets"""
        keys = {}
        for key in ['google_api_key', 'google_cx', 'groq_api_key', 'openai_api_key']:
            # 1. Primero intenta desde secrets de Streamlit
            if hasattr(st, 'secrets') and key.upper() in st.secrets:
                keys[key] = st.secrets[key.upper()]
                logger.info(f"‚úÖ {key} cargada desde Streamlit secrets")
                continue
            
            # 2. Luego desde variables de entorno
            env_key = key.upper()
            if env_key in os.environ:
                keys[key] = os.environ[env_key]
                logger.info(f"‚úÖ {key} cargada desde variable de entorno")
                continue
            
            # 3. Si no encuentra, deja como None
            keys[key] = None
            logger.warning(f"‚ö†Ô∏è {key} no encontrada en secrets ni variables de entorno")
        
        return keys

# Inicializar settings globales
settings = AppSettings()
api_keys = settings.get_api_keys_from_environment()

# Validar disponibilidad de Groq
GROQ_AVAILABLE = False
GROQ_CLIENT = None
if api_keys.get('groq_api_key') and len(api_keys['groq_api_key']) >= 30:
    try:
        from groq import Groq
        GROQ_CLIENT = Groq(api_key=api_keys['groq_api_key'])
        GROQ_AVAILABLE = True
        logger.info("‚úÖ Groq API disponible y validada correctamente")
    except ImportError:
        logger.warning("‚ö†Ô∏è Biblioteca 'groq' no instalada. Instala con: pip install groq")
    except Exception as e:
        logger.error(f"‚ùå Error al inicializar Groq client: {e}")

# Validar disponibilidad de Google API (m√≠nimo una de las dos keys)
GOOGLE_API_AVAILABLE = False
if (api_keys.get('google_api_key') and len(api_keys['google_api_key']) >= 15 and 
    api_keys.get('google_cx') and len(api_keys['google_cx']) >= 20):
    GOOGLE_API_AVAILABLE = True
    logger.info("‚úÖ Google API disponible y validada correctamente")
else:
    logger.warning("‚ö†Ô∏è Google API keys incompletas o inv√°lidas")

# ============================================================
# 3. SISTEMA DE CACH√â AVANZADO - M√∫ltiples capas con TTL y LRU
# ============================================================

class AdvancedCacheManager:
    """Sistema de cach√© avanzado con m√∫ltiples estrategias y persistencia"""
    
    def __init__(self, 
                 ttl_seconds: int = CONFIG.CACHE_TTL_SECONDS,
                 maxsize: int = 1000,
                 persistent: bool = True,
                 cache_dir: Path = settings.cache_dir):
        self.ttl_seconds = ttl_seconds
        self.maxsize = maxsize
        self.persistent = persistent
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # Cach√© en memoria con TTL
        self.memory_cache = TTLCache(maxsize=maxsize, ttl=ttl_seconds)
        
        # Cach√© LRU para resultados frecuentes
        self.lru_cache = LRUCache(maxsize=maxsize // 2)
        
        # Cach√© persistente en disco
        self.persistent_cache_file = self.cache_dir / "persistent_cache.json"
        self.persistent_cache = self._load_persistent_cache()
        
        logger.info(f"‚úÖ AdvancedCacheManager inicializado - TTL: {ttl_seconds}s, Maxsize: {maxsize}")
    
    def _load_persistent_cache(self) -> dict:
        """Carga cach√© persistente desde disco"""
        if not self.persistent:
            return {}
        
        try:
            if self.persistent_cache_file.exists():
                with open(self.persistent_cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # Filtrar entradas expiradas
                    now = time.time()
                    valid_data = {
                        k: v for k, v in data.items() 
                        if now - v.get('timestamp', 0) < self.ttl_seconds
                    }
                    logger.info(f"‚úÖ Cargadas {len(valid_data)} entradas de cach√© persistente")
                    return valid_data
        except Exception as e:
            logger.error(f"‚ùå Error al cargar cach√© persistente: {e}")
        
        return {}
    
    def _save_persistent_cache(self):
        """Guarda cach√© persistente en disco"""
        if not self.persistent:
            return
        
        try:
            with open(self.persistent_cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.persistent_cache, f, ensure_ascii=False, indent=2)
            logger.debug(f"üíæ Cach√© persistente guardada - {len(self.persistent_cache)} entradas")
        except Exception as e:
            logger.error(f"‚ùå Error al guardar cach√© persistente: {e}")
    
    def _generate_cache_key(self, *args, **kwargs) -> str:
        """Genera una clave de cach√© √∫nica basada en los argumentos"""
        key_parts = []
        for arg in args:
            if isinstance(arg, (list, dict, set)):
                key_parts.append(json.dumps(arg, sort_keys=True))
            else:
                key_parts.append(str(arg))
        
        for k, v in sorted(kwargs.items()):
            if isinstance(v, (list, dict, set)):
                key_parts.append(f"{k}:{json.dumps(v, sort_keys=True)}")
            else:
                key_parts.append(f"{k}:{v}")
        
        key_str = "|".join(key_parts)
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def get(self, key: str) -> Optional[Any]:
        """Obtiene un valor del cach√© en m√∫ltiples capas"""
        # 1. Primero cach√© en memoria (m√°s r√°pido)
        if key in self.memory_cache:
            logger.debug(f"‚ö° Hit en cach√© en memoria para clave: {key}")
            return self.memory_cache[key]
        
        # 2. Luego cach√© LRU
        if key in self.lru_cache:
            logger.debug(f"‚ö° Hit en cach√© LRU para clave: {key}")
            value = self.lru_cache[key]
            # Mover a cach√© en memoria para acceso m√°s r√°pido
            self.memory_cache[key] = value
            return value
        
        # 3. Finalmente cach√© persistente
        if key in self.persistent_cache:
            entry = self.persistent_cache[key]
            if time.time() - entry['timestamp'] < self.ttl_seconds:
                logger.debug(f"‚ö° Hit en cach√© persistente para clave: {key}")
                value = entry['value']
                # Mover a cach√©s m√°s r√°pidos
                self.memory_cache[key] = value
                self.lru_cache[key] = value
                return value
            else:
                # Eliminar entrada expirada
                del self.persistent_cache[key]
                self._save_persistent_cache()
        
        logger.debug(f"‚ùå Miss en todas las capas de cach√© para clave: {key}")
        return None
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """Guarda un valor en todas las capas de cach√©"""
        ttl = ttl or self.ttl_seconds
        timestamp = time.time()
        
        # 1. Cach√© en memoria
        self.memory_cache[key] = value
        
        # 2. Cach√© LRU
        self.lru_cache[key] = value
        
        # 3. Cach√© persistente
        if self.persistent:
            self.persistent_cache[key] = {
                'value': value,
                'timestamp': timestamp,
                'ttl': ttl
            }
            # Guardar peri√≥dicamente para no bloquear
            if len(self.persistent_cache) % 10 == 0:
                self._save_persistent_cache()
        
        logger.debug(f"üíæ Valor guardado en cach√© para clave: {key} - Tama√±o actual: {len(self.memory_cache)}")
    
    def clear(self, prefix: Optional[str] = None):
        """Limpia el cach√©, opcionalmente por prefijo"""
        if prefix:
            # Limpiar por prefijo
            keys_to_delete = [k for k in self.memory_cache.keys() if k.startswith(prefix)]
            for k in keys_to_delete:
                del self.memory_cache[k]
                if k in self.lru_cache:
                    del self.lru_cache[k]
                if k in self.persistent_cache:
                    del self.persistent_cache[k]
            logger.info(f"üßπ Cach√© limpiado para prefijo '{prefix}' - {len(keys_to_delete)} claves eliminadas")
        else:
            # Limpiar todo
            self.memory_cache.clear()
            self.lru_cache.clear()
            self.persistent_cache.clear()
            logger.info("üßπ Cach√© completamente limpiado")
        
        if self.persistent:
            self._save_persistent_cache()
    
    def get_stats(self) -> dict:
        """Obtiene estad√≠sticas del cach√©"""
        return {
            'memory_cache_size': len(self.memory_cache),
            'lru_cache_size': len(self.lru_cache),
            'persistent_cache_size': len(self.persistent_cache),
            'ttl_seconds': self.ttl_seconds,
            'maxsize': self.maxsize,
            'hit_rate': getattr(self.memory_cache, 'hit_rate', 0.0) if hasattr(self.memory_cache, 'hit_rate') else 0.0
        }

# Inicializar gestor de cach√© global
cache_manager = AdvancedCacheManager(
    ttl_seconds=settings.cache_ttl_seconds,
    maxsize=2000,
    persistent=True
)

# Decorador para cach√© autom√°tico
def cached_result(ttl_seconds: Optional[int] = None, prefix: str = ""):
    """Decorador para cachear resultados de funciones autom√°ticamente"""
    def decorator(func):
        @functools.wraps(func)
        async def async_wrapper(*args, **kwargs):
            cache_key = f"{prefix}:{func.__name__}:{cache_manager._generate_cache_key(*args, **kwargs)}"
            cached = cache_manager.get(cache_key)
            if cached is not None:
                return cached
            
            result = await func(*args, **kwargs)
            cache_manager.set(cache_key, result, ttl=ttl_seconds)
            return result
        
        @functools.wraps(func)
        def sync_wrapper(*args, **kwargs):
            cache_key = f"{prefix}:{func.__name__}:{cache_manager._generate_cache_key(*args, **kwargs)}"
            cached = cache_manager.get(cache_key)
            if cached is not None:
                return cached
            
            result = func(*args, **kwargs)
            cache_manager.set(cache_key, result, ttl=ttl_seconds)
            return result
        
        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
    return decorator

# ============================================================
# 4. SISTEMA DE BASE DE DATOS AVANZADO - SQLAlchemy Async
# ============================================================

class DatabaseManager:
    """Gestor de base de datos as√≠ncrono con SQLAlchemy y pool de conexiones"""
    
    def __init__(self, database_url: str = settings.database_url):
        self.database_url = database_url
        self.engine = None
        self.async_session = None
        self._initialize_database()
        logger.info(f"‚úÖ DatabaseManager inicializado - URL: {database_url}")
    
    def _initialize_database(self):
        """Inicializa el motor de base de datos y crea tablas"""
        try:
            # Crear engine as√≠ncrono
            if self.database_url.startswith("sqlite"):
                self.engine = create_async_engine(
                    self.database_url,
                    echo=settings.debug_mode,
                    future=True,
                    connect_args={"check_same_thread": False}
                )
            else:
                self.engine = create_async_engine(
                    self.database_url,
                    echo=settings.debug_mode,
                    future=True,
                    pool_size=settings.database_pool_size,
                    max_overflow=settings.database_max_overflow,
                    pool_timeout=30,
                    pool_recycle=1800
                )
            
            # Crear sesi√≥n as√≠ncrona
            self.async_session = sessionmaker(
                self.engine, class_=AsyncSession, expire_on_commit=False
            )
            
            # Crear tablas si no existen (solo para SQLite en este caso)
            if self.database_url.startswith("sqlite"):
                asyncio.create_task(self._create_tables())
            
        except Exception as e:
            logger.error(f"‚ùå Error al inicializar base de datos: {e}")
            raise
    
    async def _create_tables(self):
        """Crea tablas en la base de datos si no existen"""
        try:
            async with self.engine.begin() as conn:
                await conn.run_sync(Base.metadata.create_all)
            logger.info("‚úÖ Tablas de base de datos creadas/verificadas")
        except Exception as e:
            logger.error(f"‚ùå Error al crear tablas: {e}")
    
    @asynccontextmanager
    async def get_session(self) -> AsyncSession:
        """Context manager para obtener una sesi√≥n de base de datos"""
        session = self.async_session()
        try:
            yield session
            await session.commit()
        except Exception as e:
            await session.rollback()
            logger.error(f"‚ùå Error en transacci√≥n de base de datos: {e}")
            raise
        finally:
            await session.close()
    
    async def health_check(self) -> bool:
        """Verifica la salud de la conexi√≥n a la base de datos"""
        try:
            async with self.get_session() as session:
                await session.execute("SELECT 1")
            return True
        except Exception as e:
            logger.error(f"‚ùå Database health check failed: {e}")
            return False
    
    async def vacuum(self):
        """Optimiza la base de datos (solo para SQLite)"""
        if self.database_url.startswith("sqlite"):
            try:
                async with self.engine.connect() as conn:
                    await conn.execute("VACUUM")
                    await conn.commit()
                logger.info("‚úÖ Database VACUUM executed successfully")
            except Exception as e:
                logger.error(f"‚ùå Error executing VACUUM: {e}")

# Base declarativa para modelos SQLAlchemy
Base = declarative_base()

# Definir modelos de base de datos aqu√≠ (se mantendr√°n todos los existentes y se a√±adir√°n nuevos)

class PlataformaOculta(Base):
    __tablename__ = 'plataformas_ocultas'
    
    id = sa.Column(sa.Integer, primary_key=True, autoincrement=True)
    nombre = sa.Column(sa.String(255), nullable=False)
    url_base = sa.Column(sa.String(500), nullable=False)
    descripcion = sa.Column(sa.Text, nullable=True)
    idioma = sa.Column(sa.String(10), nullable=False, default='es')
    categoria = sa.Column(sa.String(100), nullable=True)
    nivel = sa.Column(sa.String(50), nullable=True)
    confianza = sa.Column(sa.Float, nullable=False, default=0.7)
    ultima_verificacion = sa.Column(sa.DateTime, nullable=False, default=datetime.utcnow)
    activa = sa.Column(sa.Boolean, nullable=False, default=True)
    tipo_certificacion = sa.Column(sa.String(50), nullable=False, default='audit')
    validez_internacional = sa.Column(sa.Boolean, nullable=False, default=False)
    paises_validos = sa.Column(sa.Text, nullable=False, default='[]')  # JSON array
    reputacion_academica = sa.Column(sa.Float, nullable=False, default=0.5)
    metadatos = sa.Column(sa.JSON, nullable=True)

# (Continuar con todos los dem√°s modelos de la base de datos original y a√±adir nuevos)

# Inicializar gestor de base de datos
db_manager = DatabaseManager()

# ============================================================
# 5. SISTEMA DE GESTI√ìN DE ERRORES Y RECUPERACI√ìN - Ultra robusto
# ============================================================

class ApplicationError(Exception):
    """Excepci√≥n base para errores de la aplicaci√≥n"""
    def __init__(self, message: str, error_code: str = "APP_ERROR", details: dict = None):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.timestamp = datetime.utcnow().isoformat()
        super().__init__(message)

class RateLimitExceededError(ApplicationError):
    """Error cuando se excede el l√≠mite de tasa"""
    def __init__(self, limit: int, window: int, details: dict = None):
        super().__init__(
            f"L√≠mite de tasa excedido: {limit} solicitudes por {window} segundos",
            "RATE_LIMIT_EXCEEDED",
            {**details, "limit": limit, "window": window}
        )

class ServiceUnavailableError(ApplicationError):
    """Error cuando un servicio externo no est√° disponible"""
    def __init__(self, service_name: str, details: dict = None):
        super().__init__(
            f"Servicio no disponible: {service_name}",
            "SERVICE_UNAVAILABLE",
            {**details, "service": service_name}
        )

class ValidationError(ApplicationError):
    """Error de validaci√≥n de datos"""
    def __init__(self, field: str, value: Any, reason: str, details: dict = None):
        super().__init__(
            f"Validaci√≥n fallida para {field}: {reason}",
            "VALIDATION_ERROR",
            {**details, "field": field, "value": value, "reason": reason}
        )

class ErrorHandler:
    """Gestor centralizado de errores con recuperaci√≥n autom√°tica"""
    
    def __init__(self):
        self.error_counts = Counter()
        self.last_error_times = {}
        self.recovery_strategies = {}
        self.max_errors_before_recovery = 5
        self.recovery_cooldown = 60  # segundos
        
        # Estrategias de recuperaci√≥n por tipo de error
        self.register_recovery_strategy("SERVICE_UNAVAILABLE", self._recover_service)
        self.register_recovery_strategy("RATE_LIMIT_EXCEEDED", self._recover_rate_limit)
        self.register_recovery_strategy("DATABASE_ERROR", self._recover_database)
        
        logger.info("‚úÖ ErrorHandler inicializado con estrategias de recuperaci√≥n")
    
    def register_recovery_strategy(self, error_type: str, strategy: Callable):
        """Registra una estrategia de recuperaci√≥n para un tipo de error"""
        self.recovery_strategies[error_type] = strategy
        logger.debug(f"üîß Estrategia de recuperaci√≥n registrada para: {error_type}")
    
    async def handle_error(self, error: Exception, context: dict = None) -> dict:
        """Maneja un error y aplica estrategias de recuperaci√≥n si es necesario"""
        context = context or {}
        error_type = type(error).__name__
        error_key = f"{error_type}:{str(error)}"
        
        # Contar errores
        self.error_counts[error_type] += 1
        self.last_error_times[error_key] = time.time()
        
        # Loggear error
        logger.error(f"‚ùå Error [{error_type}]: {str(error)}", exc_info=True, **context)
        
        # Preparar respuesta de error
        error_response = {
            'success': False,
            'error': {
                'type': error_type,
                'message': str(error),
                'timestamp': datetime.utcnow().isoformat(),
                'context': context
            }
        }
        
        # Verificar si se necesita recuperaci√≥n
        if self.error_counts[error_type] >= self.max_errors_before_recovery:
            last_recovery_time = self.last_error_times.get(f"recovery:{error_type}", 0)
            if time.time() - last_recovery_time > self.recovery_cooldown:
                try:
                    recovery_strategy = self.recovery_strategies.get(error_type)
                    if recovery_strategy:
                        logger.warning(f"üîÑ Aplicando estrategia de recuperaci√≥n para: {error_type}")
                        recovery_result = await recovery_strategy(error, context)
                        error_response['recovery'] = recovery_result
                        self.last_error_times[f"recovery:{error_type}"] = time.time()
                        # Reiniciar contador despu√©s de recuperaci√≥n
                        self.error_counts[error_type] = 0
                except Exception as recovery_error:
                    logger.error(f"‚ùå Error durante recuperaci√≥n: {recovery_error}")
        
        return error_response
    
    async def _recover_service(self, error: Exception, context: dict) -> dict:
        """Estrategia de recuperaci√≥n para servicios no disponibles"""
        service_name = context.get('service', 'unknown')
        
        # 1. Verificar cach√© primero
        cache_key = f"service:{service_name}"
        cached_data = cache_manager.get(cache_key)
        if cached_data:
            logger.info(f"‚úÖ Recuperaci√≥n exitosa usando cach√© para: {service_name}")
            return {
                'strategy': 'cache_fallback',
                'service': service_name,
                'success': True,
                'cached_data_used': True
            }
        
        # 2. Intentar servicios alternativos
        if service_name == 'groq' and GOOGLE_API_AVAILABLE:
            logger.info("üîÑ Recuperaci√≥n: usando Google API como fallback para Groq")
            return {
                'strategy': 'service_fallback',
                'service': service_name,
                'fallback_service': 'google_api',
                'success': True
            }
        
        # 3. Modo offline con datos hist√≥ricos
        if service_name in ['google_api', 'groq'] and settings.enable_offline_cache:
            logger.info(f"üîÑ Recuperaci√≥n: activando modo offline para {service_name}")
            return {
                'strategy': 'offline_mode',
                'service': service_name,
                'success': True,
                'offline_mode': True
            }
        
        return {
            'strategy': 'no_recovery_available',
            'service': service_name,
            'success': False
        }
    
    async def _recover_rate_limit(self, error: Exception, context: dict) -> dict:
        """Estrategia de recuperaci√≥n para l√≠mites de tasa"""
        service = context.get('service', 'unknown')
        
        # 1. Reducir frecuencia de solicitudes
        backoff_time = min(30, context.get('retry_count', 1) * 2)
        
        # 2. Usar cach√© agresivo
        cache_manager.ttl_seconds = max(cache_manager.ttl_seconds, 300)  # 5 minutos
        
        logger.info(f"‚è≥ Recuperaci√≥n de rate limit: esperando {backoff_time}s antes de reintento")
        
        return {
            'strategy': 'rate_limit_backoff',
            'service': service,
            'backoff_time': backoff_time,
            'cache_ttl_extended': True,
            'success': True
        }
    
    async def _recover_database(self, error: Exception, context: dict) -> dict:
        """Estrategia de recuperaci√≥n para errores de base de datos"""
        try:
            # 1. Intentar reconectar
            await db_manager._initialize_database()
            
            # 2. Verificar salud
            health = await db_manager.health_check()
            if health:
                logger.info("‚úÖ Recuperaci√≥n de base de datos exitosa")
                return {
                    'strategy': 'reconnect',
                    'success': True,
                    'health_check': True
                }
            
            # 3. Modo lectura-only con cach√©
            if settings.enable_offline_cache:
                logger.warning("‚ö†Ô∏è Base de datos no disponible, usando modo lectura-only con cach√©")
                return {
                    'strategy': 'read_only_mode',
                    'success': True,
                    'read_only': True,
                    'cache_only': True
                }
            
        except Exception as recovery_error:
            logger.error(f"‚ùå Error durante recuperaci√≥n de base de datos: {recovery_error}")
        
        return {
            'strategy': 'database_recovery_failed',
            'success': False
        }

# Inicializar gestor de errores
error_handler = ErrorHandler()

# Decorador para manejo autom√°tico de errores
def handle_errors(func):
    """Decorador para manejar errores autom√°ticamente en funciones"""
    @functools.wraps(func)
    async def async_wrapper(*args, **kwargs):
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            context = {
                'function': func.__name__,
                'args': args,
                'kwargs': kwargs
            }
            return await error_handler.handle_error(e, context)
    
    @functools.wraps(func)
    def sync_wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            context = {
                'function': func.__name__,
                'args': args,
                'kwargs': kwargs
            }
            # Ejecutar manejo de errores de forma as√≠ncrona
            return asyncio.run(error_handler.handle_error(e, context))
    
    return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper

# ============================================================
# 6. SISTEMA DE AUTENTICACI√ìN Y SEGURIDAD - JWT + Session Management
# ============================================================

class SecurityManager:
    """Gestor de seguridad y autenticaci√≥n"""
    
    def __init__(self):
        self.secret_key = os.getenv("JWT_SECRET_KEY", "super_secret_key_for_development_only_123!@#")
        self.algorithm = "HS256"
        self.session_duration = timedelta(hours=24)
        
        # Rate limiting
        self.rate_limit_store = {}
        self.ip_bans = {}
        self.max_failed_attempts = 5
        self.ban_duration = timedelta(hours=1)
        
        logger.info("‚úÖ SecurityManager inicializado")
    
    def generate_jwt_token(self, user_id: str, user_data: dict = None) -> str:
        """Genera un token JWT para autenticaci√≥n"""
        payload = {
            'user_id': user_id,
            'exp': datetime.utcnow() + self.session_duration,
            'iat': datetime.utcnow(),
            'data': user_data or {}
        }
        return jwt.encode(payload, self.secret_key, algorithm=self.algorithm)
    
    def verify_jwt_token(self, token: str) -> dict:
        """Verifica y decodifica un token JWT"""
        try:
            return jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
        except jwt.ExpiredSignatureError:
            logger.warning("‚ùå Token JWT expirado")
            raise ApplicationError("Token expirado", "TOKEN_EXPIRED")
        except jwt.InvalidTokenError as e:
            logger.warning(f"‚ùå Token JWT inv√°lido: {e}")
            raise ApplicationError("Token inv√°lido", "TOKEN_INVALID")
    
    def check_rate_limit(self, ip_address: str, endpoint: str) -> bool:
        """Verifica el l√≠mite de tasa para una IP y endpoint"""
        if not settings.enable_rate_limiting:
            return True
        
        key = f"{ip_address}:{endpoint}"
        current_time = time.time()
        
        # Verificar si IP est√° baneada
        if ip_address in self.ip_bans:
            ban_time, ban_reason = self.ip_bans[ip_address]
            if current_time - ban_time < self.ban_duration.total_seconds():
                logger.warning(f"üö´ IP baneada intentando acceso: {ip_address} - {ban_reason}")
                return False
            else:
                # Eliminar ban expirado
                del self.ip_bans[ip_address]
        
        # Inicializar contador si no existe
        if key not in self.rate_limit_store:
            self.rate_limit_store[key] = {'count': 1, 'start_time': current_time}
            return True
        
        # Verificar ventana de tiempo
        store = self.rate_limit_store[key]
        elapsed = current_time - store['start_time']
        
        if elapsed > settings.rate_limit_window:
            # Reiniciar contador
            store['count'] = 1
            store['start_time'] = current_time
            return True
        
        # Verificar l√≠mite
        if store['count'] >= settings.rate_limit_requests:
            # Banear IP temporalmente
            self.ip_bans[ip_address] = (current_time, f"Exceso de solicitudes en {endpoint}")
            logger.warning(f"üîí IP baneada por exceso de solicitudes: {ip_address}")
            return False
        
        # Incrementar contador
        store['count'] += 1
        return True
    
    def sanitize_input(self, input_data: Any) -> Any:
        """Limpia y sanitiza datos de entrada"""
        if isinstance(input_data, str):
            # Eliminar caracteres peligrosos
            return re.sub(r'[<>\"\'%{}()\[\];]', '', input_data.strip())
        elif isinstance(input_data, (list, tuple)):
            return [self.sanitize_input(item) for item in input_data]
        elif isinstance(input_data, dict):
            return {key: self.sanitize_input(value) for key, value in input_data.items()}
        return input_data
    
    def validate_search_query(self, query: str) -> bool:
        """Valida que una consulta de b√∫squeda sea segura"""
        if not query or len(query.strip()) < 2:
            return False
        
        # Patrones peligrosos
        dangerous_patterns = [
            r'drop\s+table', r'delete\s+from', r'insert\s+into',
            r'union\s+select', r';', r'--', r'\/\*', r'\*\/',
            r'eval\s*\(', r'exec\s*\(', r'system\s*\('
        ]
        
        for pattern in dangerous_patterns:
            if re.search(pattern, query.lower()):
                logger.warning(f"‚ö†Ô∏è Consulta bloqueada por seguridad: {query}")
                return False
        
        return True

# Inicializar gestor de seguridad
security_manager = SecurityManager()

# ============================================================
# 7. SISTEMA DE B√öSQUEDA MULTICAPA MEJORADO - Async con fallbacks
# ============================================================

class SearchEngine:
    """Motor de b√∫squeda avanzado con m√∫ltiples fuentes y estrategias de fallback"""
    
    def __init__(self):
        self.sources = {
            'google_api': self._search_google_api,
            'known_platforms': self._search_known_platforms,
            'hidden_platforms': self._search_hidden_platforms,
            'ddg_fallback': self._search_duckduckgo,
            'offline_cache': self._search_offline_cache
        }
        self.weights = {
            'google_api': 0.9,
            'known_platforms': 0.85,
            'hidden_platforms': 0.8,
            'ddg_fallback': 0.7,
            'offline_cache': 0.6
        }
        self.timeout = settings.request_timeout
        self.max_results_per_source = 10
        
        logger.info("‚úÖ SearchEngine inicializado con fuentes m√∫ltiples")
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    @cached_result(ttl_seconds=3600, prefix="search")
    async def search(self, query: str, language: str = "es", level: str = "Cualquiera", 
                    sources: list = None) -> list:
        """B√∫squeda principal con m√∫ltiples fuentes y fallbacks autom√°ticos"""
        if not security_manager.validate_search_query(query):
            raise ValidationError("query", query, "Consulta no v√°lida o potencialmente peligrosa")
        
        sanitized_query = security_manager.sanitize_input(query)
        logger.info(f"üîç Iniciando b√∫squeda para: '{sanitized_query}' - Idioma: {language}, Nivel: {level}")
        
        sources = sources or list(self.sources.keys())
        results = []
        tasks = []
        
        # Crear tareas para fuentes as√≠ncronas
        for source in sources:
            if source in ['google_api', 'ddg_fallback'] and self.sources.get(source):
                task = asyncio.create_task(
                    self._execute_search_with_timeout(
                        source, sanitized_query, language, level
                    )
                )
                tasks.append((source, task))
        
        # Ejecutar fuentes s√≠ncronas en thread pool
        with concurrent.futures.ThreadPoolExecutor() as executor:
            sync_sources = [s for s in sources if s not in ['google_api', 'ddg_fallback']]
            for source in sync_sources:
                if self.sources.get(source):
                    future = executor.submit(
                        self.sources[source], sanitized_query, language, level
                    )
                    tasks.append((source, future))
        
        # Procesar resultados
        for source, task in tasks:
            try:
                if isinstance(task, asyncio.Task):
                    source_results = await task
                else:
                    source_results = await asyncio.to_thread(lambda: task.result())
                
                if source_results:
                    # Aplicar peso de confianza seg√∫n la fuente
                    weight = self.weights.get(source, 0.7)
                    for result in source_results:
                        result.confianza *= weight
                    results.extend(source_results)
                    logger.debug(f"‚úÖ {len(source_results)} resultados de {source}")
            except Exception as e:
                logger.error(f"‚ùå Error en fuente {source}: {e}")
                # Aplicar estrategia de fallback
                fallback_results = await self._apply_fallback_strategy(source, sanitized_query, language, level)
                if fallback_results:
                    results.extend(fallback_results)
        
        # Procesar y ordenar resultados
        results = self._process_results(results, sanitized_query, language, level)
        
        logger.info(f"‚úÖ B√∫squeda completada. {len(results)} resultados totales para '{sanitized_query}'")
        return results
    
    async def _execute_search_with_timeout(self, source: str, query: str, language: str, level: str) -> list:
        """Ejecuta una b√∫squeda con timeout"""
        try:
            return await asyncio.wait_for(
                self.sources[source](query, language, level),
                timeout=self.timeout
            )
        except asyncio.TimeoutError:
            logger.warning(f"‚ö†Ô∏è Timeout en fuente {source} para b√∫squeda: {query}")
            raise ServiceUnavailableError(f"Servicio {source} no responde", {"source": source})
        except Exception as e:
            logger.error(f"‚ùå Error en fuente {source}: {e}")
            raise
    
    async def _apply_fallback_strategy(self, failed_source: str, query: str, language: str, level: str) -> list:
        """Aplica estrategias de fallback cuando una fuente falla"""
        fallbacks = {
            'google_api': ['offline_cache', 'known_platforms', 'hidden_platforms'],
            'groq_analysis': ['offline_cache'],
            'hidden_platforms': ['known_platforms', 'offline_cache']
        }
        
        available_fallbacks = fallbacks.get(failed_source, ['offline_cache'])
        
        for fallback_source in available_fallbacks:
            if fallback_source in self.sources:
                try:
                    logger.info(f"üîÑ Aplicando fallback: {failed_source} -> {fallback_source}")
                    
                    if asyncio.iscoroutinefunction(self.sources[fallback_source]):
                        results = await self.sources[fallback_source](query, language, level)
                    else:
                        results = await asyncio.to_thread(
                            self.sources[fallback_source], query, language, level
                        )
                    
                    if results:
                        # Reducir confianza para resultados de fallback
                        for result in results:
                            result.confianza *= 0.8
                        logger.info(f"‚úÖ Fallback exitoso: {len(results)} resultados de {fallback_source}")
                        return results
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Fallback {fallback_source} tambi√©n fall√≥: {e}")
        
        logger.warning(f"‚ùå Todos los fallbacks fallaron para {failed_source}")
        return []
    
    async def _search_google_api(self, query: str, language: str, level: str) -> list:
        """B√∫squeda en Google Custom Search API con manejo robusto de errores"""
        if not GOOGLE_API_AVAILABLE or not settings.enable_google_api:
            return []
        
        try:
            query_base = f"{query} curso gratuito certificado"
            if level not in ("Cualquiera", "Todos"):
                query_base += f" nivel {level.lower()}"
            
            params = {
                'key': api_keys['google_api_key'],
                'cx': api_keys['google_cx'],
                'q': query_base,
                'num': 5,
                'lr': f'lang_{language}'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    "https://www.googleapis.com/customsearch/v1",
                    params=params,
                    timeout=aiohttp.ClientTimeout(total=CONFIG.GOOGLE_API_TIMEOUT),
                    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
                ) as response:
                    if response.status == 429:
                        raise RateLimitExceededError(100, 100, {"service": "google_api"})
                    elif response.status != 200:
                        error_text = await response.text()
                        raise ServiceUnavailableError(
                            f"Google API error {response.status}", 
                            {"response": error_text[:500]}
                        )
                    
                    data = await response.json()
                    items = data.get('items', [])
                    
                    results = []
                    for item in items:
                        url = item.get('link', '')
                        title = item.get('title', '')
                        snippet = item.get('snippet', '')
                        
                        if self._is_valid_educational_resource(url, title, snippet):
                            result = self._create_resource_from_google_item(item, language, level, query)
                            results.append(result)
                    
                    logger.debug(f"‚úÖ Google API: {len(results)} resultados v√°lidos")
                    return results[:self.max_results_per_source]
        
        except RateLimitExceededError:
            raise
        except Exception as e:
            logger.error(f"‚ùå Error en Google API: {e}")
            raise ServiceUnavailableError("Google API", {"error": str(e)})
    
    def _search_known_platforms(self, query: str, language: str, level: str) -> list:
        """B√∫squeda en plataformas conocidas con URLs predefinidas"""
        if not settings.enable_known_platforms:
            return []
        
        try:
            platforms = {
                "es": [
                    {"name": "YouTube Educativo", "url_template": "https://www.youtube.com/results?search_query=curso+gratis+{}"},
                    {"name": "Coursera (ES)", "url_template": "https://www.coursera.org/search?query={}&languages=es&free=true"},
                    {"name": "Udemy (Gratis)", "url_template": "https://www.udemy.com/courses/search/?q={}&price=price-free&lang=es"},
                    {"name": "Khan Academy (ES)", "url_template": "https://es.khanacademy.org/search?page_search_query={}"},
                    {"name": "Domestika (Gratis)", "url_template": "https://www.domestika.org/es/search?query={}&free=1"},
                    {"name": "Aprende con Alf", "url_template": "https://aprendeconalf.es/?s={}"},
                    {"name": "Biblioteca Virtual Miguel de Cervantes", "url_template": "https://www.cervantesvirtual.com/buscar/?q={}"}
                ],
                "en": [
                    {"name": "YouTube Education", "url_template": "https://www.youtube.com/results?search_query=free+course+{}"},
                    {"name": "Khan Academy", "url_template": "https://www.khanacademy.org/search?page_search_query={}"},
                    {"name": "Coursera", "url_template": "https://www.coursera.org/search?query={}&free=true"},
                    {"name": "Udemy (Free)", "url_template": "https://www.udemy.com/courses/search/?q={}&price=price-free&lang=en"},
                    {"name": "edX", "url_template": "https://www.edx.org/search?tab=course&availability=current&price=free&q={}"},
                    {"name": "freeCodeCamp", "url_template": "https://www.freecodecamp.org/news/search/?query={}"},
                    {"name": "Kaggle Learn", "url_template": "https://www.kaggle.com/learn/search?q={}"},
                    {"name": "MIT OpenCourseWare", "url_template": "https://ocw.mit.edu/search/?q={}"},
                    {"name": "Stanford Online", "url_template": "https://online.stanford.edu/courses?search_api_views_fulltext={}"},
                    {"name": "Harvard Online Learning", "url_template": "https://online-learning.harvard.edu/catalog?search={}"}
                ],
                "pt": [
                    {"name": "YouTube BR", "url_template": "https://www.youtube.com/results?search_query=curso+gratuito+{}"},
                    {"name": "Coursera (PT)", "url_template": "https://www.coursera.org/search?query={}&languages=pt&free=true"},
                    {"name": "Udemy (PT)", "url_template": "https://www.udemy.com/courses/search/?q={}&price=price-free&lang=pt"},
                    {"name": "Khan Academy (PT)", "url_template": "https://pt.khanacademy.org/search?page_search_query={}"},
                    {"name": "Funda√ß√£o Bradesco", "url_template": "https://www.ev.org.br/cursos?search={}"}
                ]
            }
            
            selected_platforms = platforms.get(language, platforms["en"])
            results = []
            
            for platform in selected_platforms[:7]:  # L√≠mite para no sobrecargar
                url = platform["url_template"].format(quote_plus(query))
                title = f"üéØ {platform['name']} ‚Äî {query}"
                description = f"B√∫squeda directa en {platform['name']} para '{query}'"
                
                result = RecursoEducativo(
                    id=self._generate_unique_id(url),
                    titulo=title,
                    url=url,
                    descripcion=description,
                    plataforma=platform['name'],
                    idioma=language,
                    nivel=level if level != "Cualquiera" else "Intermedio",
                    categoria=self._determine_category(query),
                    certificacion=None,
                    confianza=0.85,
                    tipo="conocida",
                    ultima_verificacion=datetime.utcnow().isoformat(),
                    activo=True,
                    metadatos={
                        "fuente": "plataformas_conocidas",
                        "platform_name": platform['name'],
                        "original_query": query
                    }
                )
                results.append(result)
            
            logger.debug(f"‚úÖ Plataformas conocidas: {len(results)} resultados")
            return results
        
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda de plataformas conocidas: {e}")
            return []
    
    async def _search_hidden_platforms(self, query: str, language: str, level: str) -> list:
        """B√∫squeda en plataformas ocultas desde base de datos"""
        if not settings.enable_hidden_platforms:
            return []
        
        try:
            results = []
            current_time = datetime.utcnow()
            
            async with db_manager.get_session() as session:
                # Obtener plataformas activas
                stmt = sa.select(PlataformaOculta).where(
                    (PlataformaOculta.activa == True) &
                    (PlataformaOculta.idioma == language) &
                    (PlataformaOculta.ultima_verificacion >= current_time - timedelta(days=30))
                ).order_by(PlataformaOculta.confianza.desc()).limit(10)
                
                result = await session.execute(stmt)
                platforms = result.scalars().all()
                
                for platform in platforms:
                    # Filtrar por nivel si es necesario
                    if level not in ("Cualquiera", "Todos") and platform.nivel not in [level, "Todos", "Todos los niveles"]:
                        continue
                    
                    url = platform.url_base.format(quote_plus(query))
                    title = f"üíé {platform.nombre} ‚Äî {query}"
                    description = platform.descripcion or f"Cursos de {query} en {platform.nombre}"
                    
                    # Crear certificaci√≥n si aplica
                    certificacion = None
                    if platform.tipo_certificacion != "none":
                        paises_validos = json.loads(platform.paises_validos) if platform.paises_validos else []
                        if not isinstance(paises_validos, list):
                            paises_validos = ["global"]
                        
                        certificacion = Certificacion(
                            plataforma=platform.nombre,
                            curso=query,
                            tipo=platform.tipo_certificacion,
                            validez_internacional=platform.validez_internacional,
                            paises_validos=paises_validos,
                            costo_certificado=0.0 if platform.tipo_certificacion == "gratuito" else 49.99,
                            reputacion_academica=platform.reputacion_academica,
                            ultima_verificacion=current_time.isoformat()
                        )
                    
                    result = RecursoEducativo(
                        id=self._generate_unique_id(url),
                        titulo=title,
                        url=url,
                        descripcion=description,
                        plataforma=platform.nombre,
                        idioma=language,
                        nivel=platform.nivel if level in ("Cualquiera", "Todos") else level,
                        categoria=self._determine_category(query) or platform.categoria,
                        certificacion=certificacion,
                        confianza=float(platform.confianza),
                        tipo="oculta",
                        ultima_verificacion=current_time.isoformat(),
                        activo=True,
                        metadatos={
                            "fuente": "plataformas_ocultas",
                            "platform_id": platform.id,
                            "confidence_db": platform.confianza,
                            "audit_trail": f"Buscado el {current_time.isoformat()}"
                        }
                    )
                    results.append(result)
            
            logger.debug(f"‚úÖ Plataformas ocultas: {len(results)} resultados")
            return results[:self.max_results_per_source]
        
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda de plataformas ocultas: {e}")
            raise ServiceUnavailableError("Base de datos", {"error": str(e)})
    
    async def _search_duckduckgo(self, query: str, language: str, level: str) -> list:
        """B√∫squeda en DuckDuckGo como fallback"""
        if not settings.enable_ddg_fallback:
            return []
        
        try:
            search_query = f"{query} free course"
            if level not in ("Cualquiera", "Todos"):
                search_query += f" {level.lower()}"
            
            url = f"https://duckduckgo.com/html?q={quote_plus(search_query)}"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    url,
                    headers={
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                        'Accept-Language': f'{language}-{language.upper()},{language};q=0.5',
                    },
                    timeout=aiohttp.ClientTimeout(total=15)
                ) as response:
                    if response.status != 200:
                        return []
                    
                    html = await response.text()
                    # Extraer resultados b√°sicos
                    results = []
                    
                    # Este es un parsing muy b√°sico - en producci√≥n usar√≠a BeautifulSoup o similar
                    links = re.findall(r'<a class="result__a" href="([^"]+)"[^>]*>([^<]+)</a>', html)
                    descriptions = re.findall(r'<div class="result__snippet">([^<]+)</div>', html)
                    
                    for i, (link, title) in enumerate(links[:5]):
                        description = descriptions[i] if i < len(descriptions) else f"Resultado de DuckDuckGo para {query}"
                        
                        if self._is_valid_educational_resource(link, title, description):
                            result = RecursoEducativo(
                                id=self._generate_unique_id(link),
                                titulo=f"ü¶Ü DuckDuckGo ‚Äî {title[:60]}...",
                                url=link,
                                descripcion=description[:200] + "...",
                                plataforma="DuckDuckGo",
                                idioma=language,
                                nivel=level if level != "Cualquiera" else "Intermedio",
                                categoria=self._determine_category(query),
                                certificacion=None,
                                confianza=0.65,
                                tipo="fallback",
                                ultima_verificacion=datetime.utcnow().isoformat(),
                                activo=True,
                                metadatos={
                                    "fuente": "duckduckgo",
                                    "original_query": query,
                                    "search_url": url
                                }
                            )
                            results.append(result)
                    
                    logger.debug(f"‚úÖ DuckDuckGo: {len(results)} resultados")
                    return results
        
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda DuckDuckGo: {e}")
            return []
    
    def _search_offline_cache(self, query: str, language: str, level: str) -> list:
        """B√∫squeda en cach√© offline cuando otros servicios no est√°n disponibles"""
        if not settings.enable_offline_cache:
            return []
        
        try:
            cache_key = f"offline_search:{query}:{language}:{level}"
            cached_results = cache_manager.get(cache_key)
            
            if cached_results:
                logger.info(f"‚úÖ Usando resultados en cach√© para: {query}")
                # Convertir resultados serializados a objetos
                results = []
                for item in cached_results:
                    result = RecursoEducativo(**item)
                    result.confianza *= 0.9  # Reducir confianza para resultados en cach√©
                    results.append(result)
                return results
            
            # Si no hay cach√©, usar datos hist√≥ricos de la base de datos
            return self._search_historical_data(query, language, level)
        
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda offline: {e}")
            return []
    
    def _search_historical_data(self, query: str, language: str, level: str) -> list:
        """B√∫squeda en datos hist√≥ricos de la base de datos"""
        try:
            # Esta funci√≥n se implementar√≠a con SQLAlchemy para buscar resultados hist√≥ricos
            # Por ahora devuelve resultados simulados
            simulated_results = [
                {
                    "id": f"hist_{i}",
                    "titulo": f"üìö Curso Hist√≥rico: {query} - Nivel {level}",
                    "url": f"https://example.com/historical/course/{i}",
                    "descripcion": f"Este curso fue encontrado en nuestros datos hist√≥ricos. Puede no estar actualizado.",
                    "plataforma": "Historical Data",
                    "idioma": language,
                    "nivel": level,
                    "categoria": self._determine_category(query),
                    "certificacion": None,
                    "confianza": 0.6,
                    "tipo": "historico",
                    "ultima_verificacion": (datetime.utcnow() - timedelta(days=30)).isoformat(),
                    "activo": True,
                    "metadatos": {
                        "fuente": "historical_data",
                        "original_query": query,
                        "data_age_days": 30
                    }
                } for i in range(3)
            ]
            
            return [RecursoEducativo(**item) for item in simulated_results]
        
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda de datos hist√≥ricos: {e}")
            return []
    
    def _process_results(self, results: list, query: str, language: str, level: str) -> list:
        """Procesa y ordena los resultados finales"""
        if not results:
            return []
        
        # 1. Eliminar duplicados
        unique_results = self._remove_duplicates(results)
        
        # 2. Calcular puntuaci√≥n final
        for result in unique_results:
            result.puntuacion_final = self._calculate_final_score(result, query, language, level)
        
        # 3. Ordenar por puntuaci√≥n
        unique_results.sort(key=lambda x: x.puntuacion_final, reverse=True)
        
        # 4. Limitar resultados
        max_results = settings.max_results
        final_results = unique_results[:max_results]
        
        # 5. Guardar en cach√© offline
        if settings.enable_offline_cache:
            cache_key = f"offline_search:{query}:{language}:{level}"
            cache_manager.set(cache_key, [asdict(r) for r in final_results], ttl=86400)  # 24 horas
        
        logger.info(f"üìä Resultados procesados: {len(unique_results)} √∫nicos, {len(final_results)} mostrados")
        return final_results
    
    def _remove_duplicates(self, results: list) -> list:
        """Elimina resultados duplicados basados en URLs normalizadas"""
        seen_urls = set()
        unique_results = []
        
        for result in results:
            # Normalizar URL
            normalized_url = self._normalize_url(result.url)
            
            if normalized_url not in seen_urls:
                seen_urls.add(normalized_url)
                unique_results.append(result)
        
        logger.debug(f"üßπ Eliminados {len(results) - len(unique_results)} duplicados")
        return unique_results
    
    def _normalize_url(self, url: str) -> str:
        """Normaliza URLs para comparaci√≥n"""
        parsed = urlparse(url.lower())
        # Eliminar par√°metros de tracking comunes
        query_params = parse_qs(parsed.query)
        clean_params = {k: v for k, v in query_params.items() if k not in ['utm_source', 'utm_medium', 'utm_campaign', 'ref']}
        clean_query = urlencode(clean_params, doseq=True)
        
        return f"{parsed.scheme}://{parsed.netloc}{parsed.path}?{clean_query}" if clean_query else f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
    
    def _calculate_final_score(self, result: RecursoEducativo, query: str, language: str, level: str) -> float:
        """Calcula puntuaci√≥n final basada en m√∫ltiples factores"""
        base_score = result.confianza
        
        # Factores de relevancia
        relevance_factors = []
        
        # 1. Relevancia del t√≠tulo
        title_lower = result.titulo.lower()
        query_lower = query.lower()
        if query_lower in title_lower:
            relevance_factors.append(1.2)
        elif any(word in title_lower for word in query_lower.split()):
            relevance_factors.append(1.1)
        
        # 2. Idioma exacto
        if result.idioma == language:
            relevance_factors.append(1.15)
        
        # 3. Nivel adecuado
        if level not in ("Cualquiera", "Todos") and result.nivel == level:
            relevance_factors.append(1.1)
        
        # 4. Recursos con certificaci√≥n
        if result.certificacion:
            cert_bonus = 1.05
            if result.certificacion.tipo == "gratuito":
                cert_bonus = 1.1
            relevance_factors.append(cert_bonus)
        
        # 5. Plataformas de alta reputaci√≥n
        high_reputation_platforms = ["Coursera", "edX", "Khan Academy", "MIT OpenCourseWare", "Stanford Online", "Harvard Online Learning"]
        if any(platform.lower() in result.plataforma.lower() for platform in high_reputation_platforms):
            relevance_factors.append(1.08)
        
        # Calcular puntuaci√≥n final
        relevance_multiplier = math.prod(relevance_factors) if relevance_factors else 1.0
        final_score = base_score * relevance_multiplier
        
        # Asegurar que est√© entre 0 y 1
        return max(0.0, min(1.0, final_score))
    
    def _is_valid_educational_resource(self, url: str, title: str, description: str) -> bool:
        """Valida si un recurso es educativo v√°lido"""
        text = f"{url} {title} {description}".lower()
        
        # Palabras clave que indican contenido educativo
        educational_keywords = [
            'curso', 'tutorial', 'aprender', 'learn', 'gratis', 'free', 'class', 
            'education', 'educaci√≥n', 'certificado', 'certificate', 'training',
            'leccion', 'lesson', 'guia', 'guide', 'academia', 'university',
            'college', 'institute', 'school', 'escuela', 'formacion', 'mooc'
        ]
        
        # Palabras clave que indican contenido no educativo o comercial
        non_educational_keywords = [
            'comprar', 'buy', 'precio', 'price', 'premium', 'paid', 'only', 
            'exclusive', 'suscripci√≥n', 'subscription', 'membership', 'register now',
            'matr√≠cula', 'enrollment', 'fee', 'cost', 'discount', 'sale', 'offer'
        ]
        
        # Dominios educativos de confianza
        trusted_domains = [
            '.edu', '.ac.', '.edu.', '.gob', '.gov', '.org', 'coursera', 'edx', 
            'khanacademy', 'udemy', 'youtube', 'freecodecamp', 'mit', 'stanford',
            'harvard', 'oxford', 'cambridge', 'university', 'college', 'institute'
        ]
        
        # Verificar si contiene palabras educativas
        has_educational = any(keyword in text for keyword in educational_keywords)
        
        # Verificar si contiene palabras no educativas
        has_non_educational = any(keyword in text for keyword in non_educational_keywords)
        
        # Verificar dominios de confianza
        has_trusted_domain = any(domain in url.lower() for domain in trusted_domains)
        
        # L√≥gica de decisi√≥n
        if has_trusted_domain:
            return True
        if has_educational and not has_non_educational:
            return True
        if has_educational and has_non_educational:
            # Si tiene ambas, dar preferencia a las educativas si son m√°s frecuentes
            edu_count = sum(1 for k in educational_keywords if k in text)
            non_edu_count = sum(1 for k in non_educational_keywords if k in text)
            return edu_count > non_edu_count
        
        return False
    
    def _create_resource_from_google_item(self, item: dict, language: str, level: str, query: str) -> RecursoEducativo:
        """Crea un RecursoEducativo desde un item de Google API"""
        url = item.get('link', '')
        title = item.get('title', '')
        snippet = item.get('snippet', '')
        html_snippet = item.get('htmlSnippet', '')
        
        # Extraer plataforma
        platform = self._extract_platform(url)
        
        # Determinar nivel
        detected_level = self._determine_level(title + " " + snippet, level)
        
        # Crear certificaci√≥n (simulada para Google API)
        certificacion = None
        if any(word in (title + snippet).lower() for word in ['certificado', 'certificate', 'diploma']):
            certificacion = Certificacion(
                plataforma=platform,
                curso=query,
                tipo="audit" if "audit" in (title + snippet).lower() else "gratuito",
                validez_internacional=True,
                paises_validos=["global"],
                costo_certificado=0.0 if "gratuito" in (title + snippet).lower() else 49.99,
                reputacion_academica=0.8 if platform in ["Coursera", "edX", "Khan Academy"] else 0.7,
                ultima_verificacion=datetime.utcnow().isoformat()
            )
        
        return RecursoEducativo(
            id=self._generate_unique_id(url),
            titulo=title,
            url=url,
            descripcion=self._clean_html(snippet + " " + html_snippet),
            plataforma=platform,
            idioma=language,
            nivel=detected_level,
            categoria=self._determine_category(query),
            certificacion=certificacion,
            confianza=0.85,
            tipo="verificada",
            ultima_verificacion=datetime.utcnow().isoformat(),
            activo=True,
            metadatos={
                "fuente": "google_api",
                "google_item": {
                    "title": title,
                    "link": url,
                    "snippet": snippet,
                    "html_snippet": html_snippet
                },
                "original_query": query
            }
        )
    
    def _extract_platform(self, url: str) -> str:
        """Extrae el nombre de la plataforma desde la URL"""
        try:
            domain = urlparse(url).netloc.lower()
            platform_mapping = {
                'youtube': 'YouTube',
                'coursera': 'Coursera',
                'edx': 'edX',
                'udemy': 'Udemy',
                'khanacademy': 'Khan Academy',
                'freecodecamp': 'freeCodeCamp',
                'mit.edu': 'MIT OpenCourseWare',
                'stanford.edu': 'Stanford Online',
                'harvard.edu': 'Harvard Online Learning',
                'aprendeconalf': 'Aprende con Alf',
                'domestika': 'Domestika',
                'cervantesvirtual': 'Biblioteca Virtual Miguel de Cervantes'
            }
            
            for keyword, platform_name in platform_mapping.items():
                if keyword in domain:
                    return platform_name
            
            # Extraer nombre del dominio si no se encuentra en el mapping
            parts = domain.split('.')
            return parts[-2].title() if len(parts) >= 2 else domain.title()
        
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo plataforma de {url}: {e}")
            return "Web"
    
    def _determine_level(self, text: str, requested_level: str) -> str:
        """Determina el nivel educativo basado en el texto"""
        if requested_level not in ("Cualquiera", "Todos"):
            return requested_level
        
        text_lower = text.lower()
        
        if any(word in text_lower for word in ['principiante', 'b√°sico', 'comenzar', 'desde cero', 'introducci√≥n', 'beginner', 'basic', 'start from zero', 'intro']):
            return "Principiante"
        
        if any(word in text_lower for word in ['avanzado', 'experto', 'maestr√≠a', 'profesional', 'avanzado', 'advanced', 'expert', 'master', 'professional']):
            return "Avanzado"
        
        return "Intermedio"
    
    def _determine_category(self, query: str) -> str:
        """Determina la categor√≠a del curso basado en la consulta"""
        query_lower = query.lower()
        
        programming_keywords = ['python', 'java', 'javascript', 'web', 'code', 'programaci√≥n', 'desarrollo', 'coding', 'programming', 'web development', 'mobile development']
        data_science_keywords = ['data', 'datos', 'ia', 'ai', 'machine learning', 'deep learning', 'neural networks', 'ciencia de datos', 'data science', 'analytics', 'statistics']
        design_keywords = ['design', 'dise√±o', 'ux', 'ui', 'graphic design', 'web design', 'dise√±o gr√°fico', 'illustrator', 'photoshop']
        business_keywords = ['marketing', 'negocios', 'business', 'finanzas', 'econom√≠a', 'finance', 'economy', 'management', 'emprendimiento', 'entrepreneurship']
        languages_keywords = ['idiomas', 'languages', 'ingl√©s', 'espa√±ol', 'franc√©s', 'alem√°n', 'italiano', 'portugu√©s', 'english', 'spanish', 'french', 'german', 'italian', 'portuguese']
        
        if any(keyword in query_lower for keyword in programming_keywords):
            return "Programaci√≥n"
        if any(keyword in query_lower for keyword in data_science_keywords):
            return "Data Science"
        if any(keyword in query_lower for keyword in design_keywords):
            return "Dise√±o"
        if any(keyword in query_lower for keyword in business_keywords):
            return "Negocios"
        if any(keyword in query_lower for keyword in languages_keywords):
            return "Idiomas"
        
        return "General"
    
    def _generate_unique_id(self, url: str) -> str:
        """Genera un ID √∫nico para un recurso"""
        return hashlib.md5(url.encode()).hexdigest()[:12]
    
    def _clean_html(self, text: str) -> str:
        """Limpia HTML de un texto"""
        if not text:
            return ""
        
        # Eliminar etiquetas HTML
        text = re.sub(r'<[^>]+>', '', text)
        
        # Decodificar entidades HTML
        text = re.sub(r'&nbsp;', ' ', text)
        text = re.sub(r'&amp;', '&', text)
        text = re.sub(r'&lt;', '<', text)
        text = re.sub(r'&gt;', '>', text)
        
        # Limpiar espacios m√∫ltiples
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text

# Inicializar motor de b√∫squeda
search_engine = SearchEngine()

# ============================================================
# 8. SISTEMA DE AN√ÅLISIS CON IA AVANZADO - Groq + Fallbacks
# ============================================================

class AIAnalyzer:
    """Analizador avanzado con IA para evaluar recursos educativos"""
    
    def __init__(self):
        self.groq_available = GROQ_AVAILABLE
        self.groq_client = GROQ_CLIENT
        self.groq_model = settings.groq_model
        self.analysis_timeout = 30
        self.max_retries = 3
        self.fallback_strategies = ["keyword_analysis", "historical_data", "user_feedback"]
        
        # Plantillas de prompts mejoradas
        self.PROMPTS = {
            'resource_analysis': """
            Analiza este recurso educativo y proporciona una evaluaci√≥n detallada en formato JSON.
            
            T√çTULO: {titulo}
            DESCRIPCI√ìN: {descripcion}
            PLATAFORMA: {plataforma}
            NIVEL: {nivel}
            CATEGOR√çA: {categoria}
            URL: {url}
            
            Eval√∫a los siguientes aspectos:
            1. Calidad educativa (0.0-1.0)
            2. Relevancia para el usuario (0.0-1.0) 
            3. Dificultad real vs nivel declarado
            4. Reputaci√≥n de la plataforma
            5. Valor del certificado (si aplica)
            6. Tiempo estimado de aprendizaje
            7. Prerrequisitos recomendados
            8. Fortalezas principales
            9. √Åreas de mejora
            10. Recomendaci√≥n personalizada
            
            Proporciona el resultado SOLO en formato JSON con esta estructura:
            {{
                "calidad_educativa": 0.85,
                "relevancia_usuario": 0.90,
                "dificultad_real": "Intermedio",
                "reputacion_plataforma": 0.92,
                "valor_certificado": 0.88,
                "tiempo_estimado_horas": 40,
                "prerrequisitos": ["Conocimientos b√°sicos de programaci√≥n"],
                "fortalezas": ["Contenido pr√°ctico", "Buen soporte"],
                "areas_mejora": ["M√°s ejercicios"], 
                "recomendacion_personalizada": "Excelente curso para aprender {tema}.",
                "confianza_analisis": 0.95,
                "fecha_analisis": "{fecha_actual}"
            }}
            """,
            
            'chat_response': """
            Eres un asistente educativo experto llamado EduBot. Tu rol es ayudar a los usuarios a encontrar y evaluar recursos educativos de alta calidad.
            
            Contexto actual:
            - Usuario: {user_profile}
            - Tema de inter√©s: {topic}
            - Nivel: {level}
            - Idioma preferido: {language}
            
            Historial de la conversaci√≥n:
            {conversation_history}
            
            Pregunta del usuario: {user_question}
            
            Proporciona una respuesta √∫til, clara y concisa que:
            1. Responda directamente la pregunta
            2. Ofrezca recursos relevantes si aplica
            3. Sea educativa y motivadora
            4. Use un tono amigable pero profesional
            5. Incluya consejos pr√°cticos si es relevante
            6. No uses formato JSON en tu respuesta
            7. Mant√©n la respuesta en {language}
            
            Si no tienes suficiente informaci√≥n, pide clarificaci√≥n amablemente.
            """
        }
        
        logger.info(f"‚úÖ AIAnalyzer inicializado - Groq disponible: {self.groq_available}")
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    @cached_result(ttl_seconds=86400, prefix="ai_analysis")  # 24 horas
    async def analyze_resource(self, resource: RecursoEducativo, user_profile: dict = None) -> dict:
        """Analiza un recurso educativo usando IA con fallbacks robustos"""
        if not settings.enable_groq_analysis or not self.groq_available:
            logger.info("‚è≠Ô∏è An√°lisis IA deshabilitado o no disponible, usando an√°lisis por keywords")
            return self._fallback_analysis(resource)
        
        try:
            logger.debug(f"üß† Iniciando an√°lisis IA para: {resource.titulo[:50]}...")
            
            # Preparar prompt
            prompt = self.PROMPTS['resource_analysis'].format(
                titulo=resource.titulo,
                descripcion=resource.descripcion[:500],
                plataforma=resource.plataforma,
                nivel=resource.nivel,
                categoria=resource.categoria,
                url=resource.url,
                tema=resource.categoria.lower(),
                fecha_actual=datetime.utcnow().isoformat()
            )
            
            # Ejecutar an√°lisis con timeout
            result = await asyncio.wait_for(
                self._execute_groq_analysis(prompt, resource),
                timeout=self.analysis_timeout
            )
            
            logger.debug(f"‚úÖ An√°lisis IA completado para: {resource.titulo[:50]}")
            return result
        
        except asyncio.TimeoutError:
            logger.warning(f"‚ö†Ô∏è Timeout en an√°lisis IA para: {resource.titulo[:50]}")
            return await self._apply_fallback_strategy('timeout', resource, user_profile)
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis IA: {e}")
            return await self._apply_fallback_strategy('error', resource, user_profile, str(e))
    
    async def _execute_groq_analysis(self, prompt: str, resource: RecursoEducativo) -> dict:
        """Ejecuta el an√°lisis con Groq API"""
        try:
            response = await asyncio.to_thread(
                self.groq_client.chat.completions.create,
                messages=[{"role": "user", "content": prompt}],
                model=self.groq_model,
                temperature=0.3,
                max_tokens=1000,
                timeout=25
            )
            
            content = response.choices[0].message.content.strip()
            
            # Extraer JSON del contenido
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                try:
                    analysis = json.loads(json_str)
                    # Validar estructura m√≠nima
                    required_fields = ['calidad_educativa', 'relevancia_usuario', 'recomendacion_personalizada']
                    if all(field in analysis for field in required_fields):
                        return analysis
                except json.JSONDecodeError as e:
                    logger.error(f"‚ùå Error decodificando JSON de an√°lisis: {e}")
            
            # Si no se puede extraer JSON v√°lido, usar contenido como fallback
            logger.warning("‚ö†Ô∏è No se pudo extraer JSON v√°lido del an√°lisis, usando an√°lisis b√°sico")
            return self._basic_analysis_from_content(content, resource)
        
        except Exception as e:
            logger.error(f"‚ùå Error ejecutando an√°lisis Groq: {e}")
            raise
    
    async def _apply_fallback_strategy(self, failure_type: str, resource: RecursoEducativo, 
                                      user_profile: dict = None, error_details: str = None) -> dict:
        """Aplica estrategias de fallback cuando el an√°lisis IA falla"""
        for strategy in self.fallback_strategies:
            try:
                logger.info(f"üîÑ Aplicando estrategia de fallback para an√°lisis: {strategy}")
                
                if strategy == "keyword_analysis":
                    return self._keyword_based_analysis(resource)
                elif strategy == "historical_data":
                    return await self._historical_data_analysis(resource)
                elif strategy == "user_feedback":
                    return await self._user_feedback_analysis(resource)
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Estrategia {strategy} fall√≥: {e}")
                continue
        
        # Si todas las estrategias fallan, usar an√°lisis b√°sico
        logger.error(f"‚ùå Todas las estrategias de fallback fallaron para {resource.titulo}")
        return self._fallback_analysis(resource, error_details)
    
    def _keyword_based_analysis(self, resource: RecursoEducativo) -> dict:
        """An√°lisis basado en keywords y reglas heur√≠sticas"""
        text = f"{resource.titulo} {resource.descripcion}".lower()
        
        # Calcular calidad educativa basada en keywords
        quality_keywords = {
            'excelente': ['completo', 'detallado', 'profundo', 'pr√°ctico', 'ejercicios', 'proyectos', 'certificado', 'universidad', 'experto'],
            'bueno': ['b√°sico', 'introductorio', 'te√≥rico', 'conceptos', 'fundamentos', 'principios'],
            'mejorable': ['breve', 'superficial', 'limitado', 'desactualizado', 'poco contenido']
        }
        
        calidad_score = 0.7  # Score base
        for quality, keywords in quality_keywords.items():
            if any(keyword in text for keyword in keywords):
                if quality == 'excelente':
                    calidad_score = 0.9
                elif quality == 'bueno':
                    calidad_score = 0.75
                elif quality == 'mejorable':
                    calidad_score = 0.6
                break
        
        # Calcular relevancia basada en coincidencias
        relevancia_score = 0.8
        if resource.categoria.lower() in text:
            relevancia_score += 0.1
        if resource.nivel.lower() in text:
            relevancia_score += 0.05
        
        # Determinar dificultad real
        difficulty_keywords = {
            'principiante': ['b√°sico', 'introductorio', 'desde cero', 'principios', 'fundamentos'],
            'intermedio': ['intermedio', 'pr√°ctico', 'aplicado', 'proyectos', 'ejercicios'],
            'avanzado': ['avanzado', 'experto', 'profundo', 'complejo', 'maestr√≠a']
        }
        
        dificultad_real = resource.nivel
        for level, keywords in difficulty_keywords.items():
            if any(keyword in text for keyword in keywords):
                dificultad_real = level.title()
                break
        
        # Recomendaci√≥n personalizada
        recomendacion = f"Curso {resource.nivel.lower()} de {resource.categoria.lower()}"
        if 'certificado' in text or 'certificate' in text:
            recomendacion += " con certificado v√°lido"
        if 'pr√°ctico' in text or 'proyecto' in text or 'proyectos' in text:
            recomendacion += " con enfoque pr√°ctico"
        
        return {
            "calidad_educativa": round(calidad_score, 2),
            "relevancia_usuario": round(relevancia_score, 2),
            "dificultad_real": dificultad_real,
            "reputacion_plataforma": self._get_platform_reputation(resource.plataforma),
            "valor_certificado": 0.8 if resource.certificacion else 0.5,
            "tiempo_estimado_horas": self._estimate_learning_time(resource),
            "prerrequisitos": self._determine_prerequisites(resource),
            "fortalezas": self._identify_strengths(resource),
            "areas_mejora": self._identify_weaknesses(resource),
            "recomendacion_personalizada": recomendacion,
            "confianza_analisis": 0.7,
            "fecha_analisis": datetime.utcnow().isoformat(),
            "metodo_analisis": "keyword_based"
        }
    
    async def _historical_data_analysis(self, resource: RecursoEducativo) -> dict:
        """An√°lisis basado en datos hist√≥ricos de recursos similares"""
        try:
            # Buscar recursos similares en cach√© o base de datos
            cache_key = f"historical_analysis:{resource.categoria}:{resource.nivel}:{resource.plataforma}"
            cached_analysis = cache_manager.get(cache_key)
            
            if cached_analysis:
                logger.debug("‚úÖ Usando an√°lisis hist√≥rico desde cach√©")
                # Ajustar scores ligeramente para este recurso espec√≠fico
                adjusted_analysis = cached_analysis.copy()
                adjusted_analysis['confianza_analisis'] *= 0.9  # Reducir confianza
                adjusted_analysis['fecha_analisis'] = datetime.utcnow().isoformat()
                return adjusted_analysis
            
            # Simular an√°lisis hist√≥rico (en producci√≥n usar√≠a datos reales de la BD)
            historical_data = {
                "calidad_educativa": 0.82 if "Coursera" in resource.plataforma else 0.75,
                "relevancia_usuario": 0.88,
                "dificultad_real": resource.nivel,
                "reputacion_plataforma": self._get_platform_reputation(resource.plataforma),
                "valor_certificado": 0.85 if resource.certificacion else 0.6,
                "tiempo_estimado_horas": 35,
                "prerrequisitos": ["Conocimientos b√°sicos"],
                "fortalezas": ["Buena estructura", "Material de calidad"],
                "areas_mejora": ["M√°s ejemplos pr√°cticos"],
                "recomendacion_personalizada": f"Basado en an√°lisis hist√≥ricos, este curso de {resource.categoria} en {resource.plataforma} es recomendado para nivel {resource.nivel}.",
                "confianza_analisis": 0.75,
                "fecha_analisis": datetime.utcnow().isoformat(),
                "metodo_analisis": "historical_data"
            }
            
            cache_manager.set(cache_key, historical_data, ttl=43200)  # 12 horas
            return historical_data
        
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis hist√≥rico: {e}")
            raise
    
    def _get_platform_reputation(self, platform_name: str) -> float:
        """Obtiene la reputaci√≥n de una plataforma educativa"""
        reputation_map = {
            "Coursera": 0.95,
            "edX": 0.94,
            "Khan Academy": 0.93,
            "MIT OpenCourseWare": 0.96,
            "Stanford Online": 0.95,
            "Harvard Online Learning": 0.95,
            "freeCodeCamp": 0.92,
            "Udemy": 0.85,
            "YouTube": 0.75,
            "Domestika": 0.88,
            "Aprende con Alf": 0.87,
            "Biblioteca Virtual Miguel de Cervantes": 0.90
        }
        
        platform_clean = platform_name.lower().strip()
        for name, score in reputation_map.items():
            if name.lower() in platform_clean:
                return score
        
        return 0.8  # Score default para plataformas desconocidas
    
    def _estimate_learning_time(self, resource: RecursoEducativo) -> int:
        """Estima el tiempo de aprendizaje en horas"""
        base_hours = {
            "Principiante": 15,
            "Intermedio": 30,
            "Avanzado": 45
        }
        
        category_multiplier = {
            "Programaci√≥n": 1.2,
            "Data Science": 1.3,
            "Dise√±o": 1.0,
            "Negocios": 0.9,
            "Idiomas": 1.5,
            "General": 1.0
        }
        
        base = base_hours.get(resource.nivel, 30)
        multiplier = category_multiplier.get(resource.categoria, 1.0)
        
        # Ajustar por palabras en la descripci√≥n
        description_length = len(resource.descripcion.split())
        if description_length > 200:
            base += 10
        elif description_length < 50:
            base -= 5
        
        return max(5, int(base * multiplier))
    
    def _determine_prerequisites(self, resource: RecursoEducativo) -> list:
        """Determina los prerrequisitos basados en el nivel y categor√≠a"""
        level_prereqs = {
            "Principiante": [],
            "Intermedio": {
                "Programaci√≥n": ["Conocimientos b√°sicos de programaci√≥n"],
                "Data Science": ["Estad√≠stica b√°sica, Python"],
                "Dise√±o": ["Conceptos b√°sicos de dise√±o"],
                "Negocios": ["Conceptos b√°sicos de negocios"],
                "Idiomas": ["Nivel A1 del idioma"],
                "General": ["Educaci√≥n secundaria"]
            },
            "Avanzado": {
                "Programaci√≥n": ["Programaci√≥n intermedia, algoritmos"],
                "Data Science": ["Estad√≠stica avanzada, machine learning b√°sico"],
                "Dise√±o": ["Dise√±o intermedio, herramientas profesionales"],
                "Negocios": ["Experiencia en negocios"],
                "Idiomas": ["Nivel B1 del idioma"],
                "General": ["Educaci√≥n universitaria"]
            }
        }
        
        if resource.nivel == "Principiante":
            return level_prereqs["Principiante"]
        
        category_prereqs = level_prereqs[resource.nivel].get(resource.categoria, ["Conocimientos previos en el tema"])
        return category_prereqs
    
    def _identify_strengths(self, resource: RecursoEducativo) -> list:
        """Identifica fortalezas basadas en el contenido"""
        text = f"{resource.titulo} {resource.descripcion}".lower()
        strengths = []
        
        if any(word in text for word in ['pr√°ctico', 'proyectos', 'ejercicios', 'hands-on', 'pr√°ctica']):
            strengths.append("Enfoque pr√°ctico con ejercicios")
        if any(word in text for word in ['certificado', 'diploma', 'credential', 'credencial']):
            strengths.append("Certificaci√≥n reconocida")
        if any(word in text for word in ['experto', 'profesor', 'instructor', 'mentor']):
            strengths.append("Instructores expertos")
        if any(word in text for word in ['actualizado', 'reciente', '2024', '2025']):
            strengths.append("Contenido actualizado")
        if any(word in text for word in ['comunidad', 'foro', 'soporte', 'ayuda']):
            strengths.append("Buena comunidad y soporte")
        
        return strengths or ["Contenido educativo s√≥lido"]
    
    def _identify_weaknesses(self, resource: RecursoEducativo) -> list:
        """Identifica √°reas de mejora basadas en el contenido"""
        text = f"{resource.titulo} {resource.descripcion}".lower()
        weaknesses = []
        
        if any(word in text for word in ['te√≥rico', 'solo teor√≠a', 'poca pr√°ctica']):
            weaknesses.append("Poco contenido pr√°ctico")
        if any(word in text for word in ['b√°sico', 'simple', 'introductorio']) and resource.nivel == "Avanzado":
            weaknesses.append("Podr√≠a ser muy b√°sico para el nivel declarado")
        if any(word in text for word in ['desactualizado', 'viejo', 'antiguo']):
            weaknesses.append("Contenido posiblemente desactualizado")
        if 'certificado' not in text and resource.certificacion:
            weaknesses.append("Informaci√≥n limitada sobre el certificado")
        
        return weaknesses or ["Sin √°reas de mejora significativas identificadas"]
    
    def _fallback_analysis(self, resource: RecursoEducativo, error_details: str = None) -> dict:
        """An√°lisis de fallback b√°sico cuando todo lo dem√°s falla"""
        logger.warning(f"‚ö†Ô∏è Usando an√°lisis de fallback b√°sico para: {resource.titulo}")
        
        return {
            "calidad_educativa": resource.confianza,
            "relevancia_usuario": resource.confianza,
            "dificultad_real": resource.nivel,
            "reputacion_plataforma": self._get_platform_reputation(resource.plataforma),
            "valor_certificado": 0.7 if resource.certificacion else 0.3,
            "tiempo_estimado_horas": 25,
            "prerrequisitos": ["Seg√∫n nivel del curso"],
            "fortalezas": ["Recurso educativo verificado"],
            "areas_mejora": ["An√°lisis detallado no disponible"],
            "recomendacion_personalizada": f"Curso de {resource.categoria} para nivel {resource.nivel}. An√°lisis detallado no disponible temporalmente.",
            "confianza_analisis": 0.5,
            "fecha_analisis": datetime.utcnow().isoformat(),
            "metodo_analisis": "fallback_basic",
            "error_details": error_details[:200] if error_details else None
        }
    
    def _basic_analysis_from_content(self, content: str, resource: RecursoEducativo) -> dict:
        """Extrae an√°lisis b√°sico de contenido de texto sin JSON"""
        try:
            # Extraer fragmentos clave del contenido
            lines = [line.strip() for line in content.split('\n') if line.strip()]
            
            # Buscar calificaciones
            calidad_match = re.search(r'calidad\s*[:=]\s*([\d.]+)', content.lower())
            relevancia_match = re.search(r'relevancia\s*[:=]\s*([\d.]+)', content.lower())
            
            return {
                "calidad_educativa": float(calidad_match.group(1)) if calidad_match else resource.confianza,
                "relevancia_usuario": float(relevancia_match.group(1)) if relevancia_match else resource.confianza,
                "dificultad_real": resource.nivel,
                "reputacion_plataforma": self._get_platform_reputation(resource.plataforma),
                "valor_certificado": 0.7 if resource.certificacion else 0.4,
                "tiempo_estimado_horas": 30,
                "prerrequisitos": ["Seg√∫n descripci√≥n del curso"],
                "fortalezas": ["An√°lisis parcial disponible"],
                "areas_mejora": ["An√°lisis completo no disponible"],
                "recomendacion_personalizada": self._extract_recommendation(content, resource),
                "confianza_analisis": 0.6,
                "fecha_analisis": datetime.utcnow().isoformat(),
                "metodo_analisis": "content_extraction"
            }
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis b√°sico de contenido: {e}")
            return self._fallback_analysis(resource, str(e))
    
    def _extract_recommendation(self, content: str, resource: RecursoEducativo) -> str:
        """Extrae una recomendaci√≥n del contenido de texto"""
        # Buscar frases de recomendaci√≥n
        recommendation_phrases = [
            'recomendado para', 'ideal para', 'perfecto para', 'sugerido para',
            'excelente para', 'bueno para', 'recomiendo', 'sugiero'
        ]
        
        content_lower = content.lower()
        for phrase in recommendation_phrases:
            if phrase in content_lower:
                start_idx = content_lower.find(phrase)
                end_idx = content_lower.find('.', start_idx + 20)
                if end_idx == -1:
                    end_idx = min(start_idx + 100, len(content))
                return content[start_idx:end_idx].strip()
        
        return f"Curso recomendado de {resource.categoria.lower()} para nivel {resource.nivel.lower()}"
    
    async def chat_response(self, messages: list, user_profile: dict = None) -> str:
        """Genera una respuesta de chat usando IA con fallbacks"""
        if not settings.enable_chat_ia or not self.groq_available:
            logger.info("‚è≠Ô∏è Chat IA deshabilitado o no disponible")
            return self._fallback_chat_response(messages, user_profile)
        
        try:
            # Preparar contexto del usuario
            user_context = user_profile or {}
            topic = user_context.get('last_search_topic', 'educaci√≥n')
            level = user_context.get('preferred_level', 'Intermedio')
            language = user_context.get('language', 'espanol')
            
            # Construir historial de conversaci√≥n
            conversation_history = ""
            for msg in messages[-5:]:  # √öltimos 5 mensajes
                role = "Usuario" if msg['role'] == 'user' else "Asistente"
                conversation_history += f"{role}: {msg['content']}\n"
            
            # √öltima pregunta del usuario
            user_question = messages[-1]['content'] if messages else ""
            
            # Generar prompt
            prompt = self.PROMPTS['chat_response'].format(
                user_profile=json.dumps(user_context, ensure_ascii=False),
                topic=topic,
                level=level,
                language=language,
                conversation_history=conversation_history,
                user_question=user_question
            )
            
            # Ejecutar con timeout
            return await asyncio.wait_for(
                self._execute_chat_response(prompt),
                timeout=20
            )
        
        except asyncio.TimeoutError:
            logger.warning("‚ö†Ô∏è Timeout en respuesta de chat IA")
            return self._fallback_chat_response(messages, user_profile, "timeout")
        except Exception as e:
            logger.error(f"‚ùå Error en respuesta de chat IA: {e}")
            return self._fallback_chat_response(messages, user_profile, str(e))
    
    async def _execute_chat_response(self, prompt: str) -> str:
        """Ejecuta la respuesta de chat con Groq"""
        try:
            response = await asyncio.to_thread(
                self.groq_client.chat.completions.create,
                messages=[{"role": "user", "content": prompt}],
                model=self.groq_model,
                temperature=0.7,
                max_tokens=500,
                timeout=15
            )
            
            content = response.choices[0].message.content.strip()
            
            # Limpiar contenido de posibles fragmentos JSON o HTML
            content = self._clean_response_content(content)
            
            return content
        
        except Exception as e:
            logger.error(f"‚ùå Error ejecutando respuesta de chat: {e}")
            raise
    
    def _clean_response_content(self, content: str) -> str:
        """Limpia el contenido de la respuesta eliminando JSON/HTML no deseado"""
        if not content:
            return ""
        
        # Eliminar bloques JSON completos
        content = re.sub(r'\{[\s\S]*\}', '', content)
        
        # Eliminar etiquetas HTML
        content = re.sub(r'<[^>]+>', '', content)
        
        # Eliminar caracteres de control y espacios m√∫ltiples
        content = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', content)
        content = re.sub(r'\s+', ' ', content).strip()
        
        # Limitar longitud para evitar respuestas muy largas
        if len(content) > 1000:
            content = content[:950] + "..."
        
        return content
    
    def _fallback_chat_response(self, messages: list, user_profile: dict = None, error_details: str = None) -> str:
        """Respuesta de fallback para chat cuando IA no est√° disponible"""
        logger.info("üîÑ Usando respuesta de fallback para chat")
        
        if not messages:
            return "¬°Hola! Soy EduBot, tu asistente educativo. ¬øEn qu√© puedo ayudarte hoy?"
        
        last_message = messages[-1]['content'].lower()
        
        # Respuestas predefinidas basadas en keywords
        greetings = ['hola', 'buenos dias', 'buenas tardes', 'buenas noches', 'hey', 'hi', 'hello']
        help_keywords = ['ayuda', 'help', 'como funciona', 'qu√© puedes hacer', 'qu√© haces', 'capacidades']
        search_keywords = ['buscar', 'encuentra', 'busca', 'cursos', 'clases', 'aprender', 'qui√©n soy', 'quien soy']
        
        if any(greeting in last_message for greeting in greetings):
            return "¬°Hola! Soy EduBot, tu asistente educativo especializado en ayudarte a encontrar los mejores cursos y recursos de aprendizaje. ¬øEn qu√© puedo asistirte hoy?"
        
        if any(keyword in last_message for keyword in help_keywords):
            return "Puedo ayudarte a:\n\n‚Ä¢ Buscar cursos gratuitos y de pago en m√∫ltiples plataformas\n‚Ä¢ Analizar la calidad de los recursos educativos\n‚Ä¢ Recomendar cursos basados en tu nivel y preferencias\n‚Ä¢ Ayudarte con consejos de aprendizaje\n‚Ä¢ Responder preguntas sobre educaci√≥n online\n\n¬øQu√© te gustar√≠a hacer?"
        
        if any(keyword in last_message for keyword in search_keywords):
            return "Para buscar cursos, usa la barra de b√∫squeda principal en la parte superior de la p√°gina. Puedes especificar:\n\n‚Ä¢ Tema que quieres aprender\n‚Ä¢ Nivel (principiante, intermedio, avanzado)\n‚Ä¢ Idioma preferido\n\n¬øHay alg√∫n tema espec√≠fico en el que est√©s interesado?"
        
        # Respuesta gen√©rica
        return "En este momento, el an√°lisis avanzado con IA no est√° disponible. Sin embargo, puedo ayudarte a encontrar cursos usando nuestra b√∫squeda principal. ¬øTe gustar√≠a que te ayude a buscar alg√∫n curso en particular? Tambi√©n puedes preguntarme sobre consejos generales de aprendizaje online."

# Inicializar analizador de IA
ai_analyzer = AIAnalyzer()

# ============================================================
# 9. SISTEMA UI/UX AVANZADO - Streamlit con componentes personalizados
# ============================================================

class UIComponents:
    """Componentes UI personalizados para Streamlit"""
    
    def __init__(self):
        self.theme = settings.ui_theme
        self.colors = {
            'primary': '#4b6cb7',
            'secondary': '#182848',
            'success': '#4CAF50',
            'warning': '#FF9800',
            'danger': '#F44336',
            'info': '#2196F3',
            'background': '#f8f9fa',
            'text': '#212529',
            'border': '#dee2e6'
        }
        
        # Aplicar tema inicial
        self.apply_theme(self.theme)
        
        logger.info("‚úÖ UIComponents inicializado")
    
    def apply_theme(self, theme: str):
        """Aplica un tema visual a la aplicaci√≥n"""
        if theme == "dark":
            st.markdown("""
            <style>
            body { background-color: #0f111a; color: #e6edf3; }
            .stApp { background-color: #0f111a; }
            .main-header { background: linear-gradient(135deg, #2c3e50 0%, #1a1a2e 100%); }
            .resultado-card { background: #14171f; color: #e6edf3; border-left-color: #4CAF50; }
            .stButton button { background: linear-gradient(to right, #6a11cb, #2575fc); }
            </style>
            """, unsafe_allow_html=True)
        elif theme == "light":
            st.markdown("""
            <style>
            body { background-color: #f8f9fa; color: #212529; }
            .stApp { background-color: #f8f9fa; }
            .main-header { background: linear-gradient(135deg, #4b6cb7 0%, #182848 100%); }
            .resultado-card { background: white; color: #212529; border-left-color: #4CAF50; box-shadow: 0 2px 10px rgba(0,0,0,0.05); }
            .stButton button { background: linear-gradient(to right, #4b6cb7, #182848); }
            </style>
            """, unsafe_allow_html=True)
        elif theme == "system":
            # Dejar que el sistema maneje el tema
            pass
        else:  # auto
            st.markdown("""
            <style>
            @media (prefers-color-scheme: dark) {
                body { background-color: #0f111a; color: #e6edf3; }
                .stApp { background-color: #0f111a; }
                .main-header { background: linear-gradient(135deg, #2c3e50 0%, #1a1a2e 100%); }
                .resultado-card { background: #14171f; color: #e6edf3; border-left-color: #4CAF50; }
                .stButton button { background: linear-gradient(to right, #6a11cb, #2575fc); }
            }
            @media (prefers-color-scheme: light) {
                body { background-color: #f8f9fa; color: #212529; }
                .stApp { background-color: #f8f9fa; }
                .main-header { background: linear-gradient(135deg, #4b6cb7 0%, #182848 100%); }
                .resultado-card { background: white; color: #212529; border-left-color: #4CAF50; box-shadow: 0 2px 10px rgba(0,0,0,0.05); }
                .stButton button { background: linear-gradient(to right, #4b6cb7, #182848); }
            }
            </style>
            """, unsafe_allow_html=True)
    
    def render_header(self):
        """Renderiza el header principal de la aplicaci√≥n"""
        st.markdown(f"""
        <div class="main-header">
          <h1>{settings.app_name}</h1>
          <p>Descubre recursos educativos verificados con b√∫squeda inmediata y an√°lisis IA en segundo plano</p>
          <div style="display:flex;gap:10px;margin-top:10px;flex-wrap:wrap;">
            <span class="status-badge">‚úÖ Versi√≥n {settings.app_version}</span>
            <span class="status-badge">‚ö° Motor de b√∫squeda multicapa</span>
            <span class="status-badge">üåê {settings.language.upper()} - {datetime.now().strftime('%d/%m/%Y %H:%M')}</span>
            <span class="status-badge">{'üß† IA Activa' if settings.enable_groq_analysis and GROQ_AVAILABLE else '‚ö†Ô∏è IA No Disponible'}</span>
          </div>
        </div>
        """, unsafe_allow_html=True)
    
    def render_search_form(self) -> tuple:
        """Renderiza el formulario de b√∫squeda"""
        col1, col2, col3 = st.columns([3, 1, 1])
        
        with col1:
            tema = st.text_input(
                "¬øQu√© quieres aprender?", 
                placeholder="Ej: Python, Machine Learning, Dise√±o UI/UX, Marketing Digital...",
                key="search_query"
            )
        
        with col2:
            nivel = st.selectbox(
                "Nivel", 
                ["Cualquiera", "Principiante", "Intermedio", "Avanzado"],
                index=0,
                key="search_level"
            )
        
        with col3:
            idioma = st.selectbox(
                "Idioma", 
                ["Espa√±ol (es)", "Ingl√©s (en)", "Portugu√©s (pt)"],
                index=0,
                key="search_language"
            )
        
        buscar = st.button(
            "üöÄ Buscar Cursos", 
            type="primary", 
            use_container_width=True,
            disabled=not tema.strip()
        )
        
        # Atajos de b√∫squeda populares
        st.markdown("##### üîç B√∫squedas populares:")
        shortcut_col1, shortcut_col2, shortcut_col3, shortcut_col4 = st.columns(4)
        
        with shortcut_col1:
            if st.button("Python", use_container_width=True):
                st.session_state.search_query = "Python"
                st.rerun()
        
        with shortcut_col2:
            if st.button("Data Science", use_container_width=True):
                st.session_state.search_query = "Data Science"
                st.rerun()
        
        with shortcut_col3:
            if st.button("Dise√±o UX/UI", use_container_width=True):
                st.session_state.search_query = "Dise√±o UX/UI"
                st.rerun()
        
        with shortcut_col4:
            if st.button("Marketing", use_container_width=True):
                st.session_state.search_query = "Marketing Digital"
                st.rerun()
        
        return tema, nivel, idioma, buscar
    
    def render_resource_card(self, resource: RecursoEducativo, index: int):
        """Renderiza una tarjeta de recurso educativo"""
        # Determinar clases CSS seg√∫n nivel y tipo
        level_class = {
            "Principiante": "nivel-principiante",
            "Intermedio": "nivel-intermedio", 
            "Avanzado": "nivel-avanzado"
        }.get(resource.nivel, "")
        
        type_class = "plataforma-oculta" if resource.tipo == "oculta" else ""
        
        # Generar badges de certificaci√≥n
        cert_badges = ""
        if resource.certificacion:
            if resource.certificacion.tipo == "gratuito":
                cert_badges += '<span class="certificado-badge">‚úÖ Certificado Gratuito</span>'
            elif resource.certificacion.tipo == "audit":
                cert_badges += '<span class="certificado-badge" style="background:#e3f2fd;color:#1565c0;">üéì Modo Audit</span>'
            elif resource.certificacion.tipo == "pago":
                cert_badges += '<span class="certificado-badge" style="background:#fff3e0;color:#ef6c00;">üí∞ Certificado de Pago</span>'
            
            if resource.certificacion.validez_internacional:
                cert_badges += '<span class="certificado-badge" style="background:#e3f2fd;color:#1565c0;">üåê Validez Internacional</span>'
        
        # Estado del an√°lisis IA
        ia_status = ""
        if hasattr(resource, 'analisis') and resource.analisis:
            analysis = resource.analisis
            calidad = int(analysis.get('calidad_educativa', 0) * 100)
            relevancia = int(analysis.get('relevancia_usuario', 0) * 100)
            ia_status = f"""
            <div style="background:#f3e5f5;padding:12px;border-radius:8px;margin:12px 0;border-left:4px solid #9c27b0;">
                <strong>üß† An√°lisis IA:</strong> Calidad {calidad}% ‚Ä¢ Relevancia {relevancia}%<br>
                {analysis.get('recomendacion_personalizada', '')}
            </div>
            """
            status_badge = '<span class="badge-ok">IA analizado</span>'
        elif getattr(resource, 'analysis_pending', False):
            ia_status = "<div style='color:#9c27b0;font-size:0.9em;margin:5px 0;'>‚è≥ An√°lisis en progreso...</div>"
            status_badge = '<span class="badge-pendiente">IA pendiente</span>'
        else:
            status_badge = '<span class="smalltext tooltip">Sin an√°lisis IA</span>'
        
        # Bot√≥n de acceso
        access_button = f"""
        <a href="{resource.url}" target="_blank" style="display:inline-block;background:linear-gradient(to right,#6a11cb,#2575fc);color:white;padding:10px 16px;border-radius:8px;font-weight:bold;text-decoration:none;margin-top:10px;">
        ‚û°Ô∏è Acceder al recurso
        </a>
        """
        
        # Bot√≥n de favorito
        favorite_button = f"""
        <button onclick="document.dispatchEvent(new CustomEvent('add_favorite', {{detail: {{id: '{resource.id}'}}}}))" 
                style="margin-left:10px;padding:8px 15px;border-radius:8px;border:1px solid #e0e0e0;background:#fafafa;cursor:pointer;">
        ‚≠ê Favorito
        </button>
        """
        
        # Renderizar tarjeta
        st.markdown(f"""
        <div class="resultado-card {level_class} {type_class}">
          <h3 style="margin-top:0;display:flex;justify-content:space-between;align-items:center;">
            {resource.titulo} {status_badge}
          </h3>
          <p><strong>üìö {resource.nivel}</strong> | üåê {resource.plataforma} | üè∑Ô∏è {resource.categoria}</p>
          <p style="color:#555;line-height:1.5;">{resource.descripcion[:300]}{'' if len(resource.descripcion) <= 300 else '...'}</p>
          <div style="margin-bottom:10px;">
            {cert_badges}
          </div>
          {ia_status}
          <div style="margin-top:15px;">
            {access_button}
            {favorite_button}
          </div>
          <div style="margin-top: 12px; padding-top: 10px; border-top: 1px solid #eee; font-size: 0.85rem; color: #666;">
            ‚≠ê Confianza: {resource.confianza*100:.0f}% | üìÖ √öltima verificaci√≥n: {datetime.fromisoformat(resource.ultima_verificacion).strftime('%d/%m/%Y')}
          </div>
        </div>
        """, unsafe_allow_html=True)
    
    def render_results_grid(self, results: list):
        """Renderiza los resultados en una cuadr√≠cula"""
        if not results:
            st.warning("No se encontraron resultados para tu b√∫squeda. Intenta con t√©rminos m√°s generales o diferentes.")
            return
        
        st.success(f"‚úÖ Encontrados {len(results)} recursos educativos de alta calidad")
        
        # Filtros y ordenamiento
        col1, col2, col3 = st.columns(3)
        
        with col1:
            filter_platform = st.multiselect(
                "Filtrar por plataforma",
                options=sorted(set(r.plataforma for r in results)),
                default=[]
            )
        
        with col2:
            filter_level = st.multiselect(
                "Filtrar por nivel",
                options=["Principiante", "Intermedio", "Avanzado"],
                default=[]
            )
        
        with col3:
            sort_by = st.selectbox(
                "Ordenar por",
                ["Relevancia", "Nivel", "Plataforma", "Fecha"],
                index=0
            )
        
        # Aplicar filtros
        filtered_results = results.copy()
        if filter_platform:
            filtered_results = [r for r in filtered_results if r.plataforma in filter_platform]
        if filter_level:
            filtered_results = [r for r in filtered_results if r.nivel in filter_level]
        
        # Aplicar ordenamiento
        if sort_by == "Relevancia":
            filtered_results.sort(key=lambda x: getattr(x, 'puntuacion_final', x.confianza), reverse=True)
        elif sort_by == "Nivel":
            level_order = {"Principiante": 1, "Intermedio": 2, "Avanzado": 3}
            filtered_results.sort(key=lambda x: level_order.get(x.nivel, 0))
        elif sort_by == "Plataforma":
            filtered_results.sort(key=lambda x: x.plataforma)
        elif sort_by == "Fecha":
            filtered_results.sort(key=lambda x: x.ultima_verificacion, reverse=True)
        
        # Mostrar resultados filtrados
        if not filtered_results:
            st.info("No hay resultados que coincidan con tus filtros. Intenta ajustar los filtros.")
        else:
            st.info(f"Mostrando {len(filtered_results)} de {len(results)} resultados")
            
            # Paginaci√≥n
            items_per_page = 10
            total_pages = max(1, (len(filtered_results) + items_per_page - 1) // items_per_page)
            page = st.slider("P√°gina", 1, total_pages, 1)
            
            start_idx = (page - 1) * items_per_page
            end_idx = min(start_idx + items_per_page, len(filtered_results))
            
            for i, resource in enumerate(filtered_results[start_idx:end_idx], start_idx + 1):
                self.render_resource_card(resource, i)
            
            # Mostrar p√°gina actual
            st.caption(f"P√°gina {page} de {total_pages}")
        
        # Bot√≥n de exportar
        if st.button("üì• Exportar resultados a CSV", use_container_width=True):
            self.export_results_to_csv(filtered_results)
    
    def export_results_to_csv(self, results: list):
        """Exporta resultados a CSV"""
        if not results:
            st.warning("No hay resultados para exportar")
            return
        
        try:
            # Convertir resultados a DataFrame
            data = []
            for r in results:
                row = {
                    'ID': r.id,
                    'T√≠tulo': r.titulo,
                    'URL': r.url,
                    'Plataforma': r.plataforma,
                    'Nivel': r.nivel,
                    'Idioma': r.idioma,
                    'Categor√≠a': r.categoria,
                    'Confianza': f"{r.confianza:.2f}",
                    'Tipo': r.tipo,
                    '√öltima Verificaci√≥n': r.ultima_verificacion[:10] if r.ultima_verificacion else "",
                    'Certificaci√≥n': "S√≠" if r.certificacion else "No",
                    'Certificaci√≥n Tipo': r.certificacion.tipo if r.certificacion else "",
                    'Certificaci√≥n Internacional': "S√≠" if r.certificacion and r.certificacion.validez_internacional else "No"
                }
                data.append(row)
            
            df = pd.DataFrame(data)
            
            # Convertir a CSV
            csv = df.to_csv(index=False).encode('utf-8')
            
            # Bot√≥n de descarga
            st.download_button(
                label="‚¨áÔ∏è Descargar CSV",
                data=csv,
                file_name=f"recursos_educativos_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
            
            st.success(f"‚úÖ {len(results)} resultados exportados exitosamente")
        
        except Exception as e:
            logger.error(f"‚ùå Error exportando resultados a CSV: {e}")
            st.error(f"Error al exportar resultados: {e}")
    
    def render_chat_interface(self):
        """Renderiza la interfaz de chat IA"""
        if not settings.enable_chat_ia:
            return
        
        with st.sidebar:
            st.header("üí¨ EduBot - Asistente Educativo")
            
            # Mostrar estado de la IA
            status_color = "green" if GROQ_AVAILABLE and settings.enable_groq_analysis else "orange"
            status_text = "‚úÖ Disponible" if GROQ_AVAILABLE and settings.enable_groq_analysis else "‚ö†Ô∏è Limitado"
            st.markdown(f"<span style='color:{status_color}'>{status_text}</span>", unsafe_allow_html=True)
            
            # Inicializar historial de chat
            if "chat_history" not in st.session_state:
                st.session_state.chat_history = [
                    {"role": "assistant", "content": "¬°Hola! Soy EduBot, tu asistente educativo. ¬øEn qu√© puedo ayudarte hoy?"}
                ]
            
            # Mostrar historial de chat
            for message in st.session_state.chat_history:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
            
            # Input de usuario
            if prompt := st.chat_input("Escribe tu pregunta aqu√≠..."):
                # A√±adir mensaje del usuario
                st.session_state.chat_history.append({"role": "user", "content": prompt})
                
                # Mostrar mensaje del usuario
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                # Obtener respuesta de IA
                with st.chat_message("assistant"):
                    with st.spinner("ü§î Pensando..."):
                        try:
                            response = asyncio.run(
                                ai_analyzer.chat_response(st.session_state.chat_history)
                            )
                        except Exception as e:
                            logger.error(f"‚ùå Error en respuesta de chat: {e}")
                            response = f"Lo siento, hubo un error al procesar tu pregunta: {e}"
                        
                        st.markdown(response)
                
                # A√±adir respuesta al historial
                st.session_state.chat_history.append({"role": "assistant", "content": response})
    
    def render_sidebar_status(self):
        """Renderiza el panel de estado en el sidebar"""
        with st.sidebar:
            st.markdown("---")
            st.subheader("üìä Estado del Sistema")
            
            # M√©tricas del sistema
            col1, col2 = st.columns(2)
            
            with col1:
                # Contar plataformas activas
                try:
                    with db_manager.get_session() as session:
                        # Este c√≥digo se completar√≠a con la consulta real a la BD
                        active_platforms = 15  # Valor simulado
                    st.metric("Plataformas", active_platforms)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error obteniendo m√©tricas: {e}")
                    st.metric("Plataformas", "‚ùì")
            
            with col2:
                st.metric("B√∫squedas Hoy", "42")  # Valor simulado
            
            # Estado de servicios
            service_status = {
                "Google API": "‚úÖ" if GOOGLE_API_AVAILABLE else "‚ùå",
                "Groq IA": "‚úÖ" if GROQ_AVAILABLE and settings.enable_groq_analysis else "‚ùå",
                "Base de Datos": "‚úÖ",  # En producci√≥n verificar√≠a realmente
                "Cach√©": "‚úÖ"
            }
            
            for service, status in service_status.items():
                st.markdown(f"{status} {service}")
            
            # Uso de recursos del sistema
            try:
                cpu_percent = psutil.cpu_percent()
                memory = psutil.virtual_memory()
                disk = psutil.disk_usage('/')
                
                st.markdown("### üíª Recursos del Sistema")
                st.progress(cpu_percent / 100, text=f"CPU: {cpu_percent}%")
                st.progress(memory.percent / 100, text=f"Memoria: {memory.percent}%")
                st.progress(disk.percent / 100, text=f"Disco: {disk.percent}%")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error obteniendo recursos del sistema: {e}")
            
            # Footer del sidebar
            st.markdown("---")
            st.caption(f"v{settings.app_version} ‚Ä¢ {datetime.now().strftime('%H:%M')}")
    
    def render_footer(self):
        """Renderiza el footer de la aplicaci√≥n"""
        st.markdown("---")
        st.markdown(f"""
        <div style="text-align:center;color:#666;font-size:14px;padding:20px;background:#f8f9fa;border-radius:12px;">
            <strong>‚ú® {settings.app_name}</strong><br>
            <span style="color: #2c3e50; font-weight: 500;">Resultados inmediatos ‚Ä¢ Cache inteligente ‚Ä¢ Alta disponibilidad</span><br>
            <em style="color: #7f8c8d;">√öltima actualizaci√≥n: {datetime.now().strftime('%d/%m/%Y %H:%M')} ‚Ä¢ Versi√≥n: {settings.app_version} ‚Ä¢ Estado: ‚úÖ Activo</em><br>
            <div style="margin-top:10px;padding-top:10px;border-top:1px solid #ddd;">
                <code style="background:#f1f3f5;padding:2px 8px;border-radius:4px;color:#d32f2f;">
                    IA opcional ‚Äî Sistema funcional sin dependencias externas cr√≠ticas
                </code>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    def render_admin_dashboard(self):
        """Renderiza el panel de administraci√≥n"""
        st.markdown("### üõ†Ô∏è Panel de Administraci√≥n")
        
        tab1, tab2, tab3, tab4 = st.tabs(["üìä Estad√≠sticas", "‚öôÔ∏è Configuraci√≥n", "üßπ Mantenimiento", "üîç Monitoreo"])
        
        with tab1:
            self.render_admin_stats()
        
        with tab2:
            self.render_admin_config()
        
        with tab3:
            self.render_admin_maintenance()
        
        with tab4:
            self.render_admin_monitoring()
    
    def render_admin_stats(self):
        """Renderiza estad√≠sticas de administraci√≥n"""
        # Estad√≠sticas simuladas - en producci√≥n usar√≠a datos reales de la BD
        col1, col2, col3, col4 = st.columns(4)
        
        col1.metric("üîç B√∫squedas Totales", "1,245", "+12%")
        col2.metric("‚≠ê Favoritos", "387", "+5%")
        col3.metric("üí¨ Mensajes Chat", "892", "+8%")
        col4.metric("üë• Usuarios √önicos", "456", "+3%")
        
        # Gr√°fico de b√∫squedas por d√≠a
        days = [(datetime.now() - timedelta(days=i)).strftime('%d/%m') for i in range(7)][::-1]
        searches = [random.randint(50, 150) for _ in range(7)]
        
        chart_data = pd.DataFrame({
            'Fecha': days,
            'B√∫squedas': searches
        })
        
        st.bar_chart(chart_data.set_index('Fecha'))
        
        # Tabla de b√∫squedas recientes
        st.markdown("### üìã B√∫squedas Recientes")
        recent_searches = [
            {"Fecha": "2025-12-11 14:30", "Tema": "Python", "Nivel": "Intermedio", "Resultados": 12},
            {"Fecha": "2025-12-11 14:25", "Tema": "Data Science", "Nivel": "Avanzado", "Resultados": 8},
            {"Fecha": "2025-12-11 14:20", "Tema": "Dise√±o UX", "Nivel": "Principiante", "Resultados": 15},
            {"Fecha": "2025-12-11 14:15", "Tema": "Marketing Digital", "Nivel": "Intermedio", "Resultados": 10},
            {"Fecha": "2025-12-11 14:10", "Tema": "Machine Learning", "Nivel": "Avanzado", "Resultados": 7}
        ]
        
        df_recent = pd.DataFrame(recent_searches)
        st.dataframe(df_recent, use_container_width=True)
    
    def render_admin_config(self):
        """Renderiza configuraci√≥n de administraci√≥n"""
        st.markdown("### ‚öôÔ∏è Configuraci√≥n del Sistema")
        
        # Feature flags
        st.markdown("#### üö© Feature Flags")
        
        col1, col2 = st.columns(2)
        
        with col1:
            google_api = st.toggle("Google API", value=settings.enable_google_api)
            known_platforms = st.toggle("Plataformas Conocidas", value=settings.enable_known_platforms)
            hidden_platforms = st.toggle("Plataformas Ocultas", value=settings.enable_hidden_platforms)
            groq_analysis = st.toggle("An√°lisis IA (Groq)", value=settings.enable_groq_analysis and GROQ_AVAILABLE)
        
        with col2:
            chat_ia = st.toggle("Chat IA", value=settings.enable_chat_ia)
            favorites = st.toggle("Favoritos", value=settings.enable_favorites)
            feedback = st.toggle("Feedback", value=settings.enable_feedback)
            export_import = st.toggle("Exportar/Importar", value=settings.enable_export_import)
        
        # L√≠mites y configuraci√≥n
        st.markdown("#### üìè L√≠mites y Configuraci√≥n")
        
        max_results = st.slider("M√°x. resultados por b√∫squeda", 5, 50, settings.max_results)
        max_analysis = st.slider("M√°x. an√°lisis IA en paralelo", 0, 20, settings.max_analysis)
        
        # Tema y UI
        st.markdown("#### üé® Tema y UI")
        theme = st.selectbox("Tema", ["auto", "light", "dark", "system"], index=["auto", "light", "dark", "system"].index(settings.ui_theme))
        
        # Bot√≥n de guardar configuraci√≥n
        if st.button("üíæ Guardar Configuraci√≥n", use_container_width=True):
            try:
                # Actualizar settings
                settings.enable_google_api = google_api
                settings.enable_known_platforms = known_platforms
                settings.enable_hidden_platforms = hidden_platforms
                settings.enable_groq_analysis = groq_analysis
                settings.enable_chat_ia = chat_ia
                settings.enable_favorites = favorites
                settings.enable_feedback = feedback
                settings.enable_export_import = export_import
                settings.max_results = max_results
                settings.max_analysis = max_analysis
                settings.ui_theme = theme
                
                # Aplicar tema
                self.apply_theme(theme)
                
                st.success("‚úÖ Configuraci√≥n guardada exitosamente")
                logger.info("üîß Configuraci√≥n actualizada por administrador")
            except Exception as e:
                logger.error(f"‚ùå Error guardando configuraci√≥n: {e}")
                st.error(f"Error al guardar configuraci√≥n: {e}")
    
    def render_admin_maintenance(self):
        """Renderiza herramientas de mantenimiento"""
        st.markdown("### üßπ Herramientas de Mantenimiento")
        
        # Botones de mantenimiento
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üßπ Limpiar Cach√©", use_container_width=True):
                try:
                    cache_manager.clear()
                    st.success("‚úÖ Cach√© limpiada exitosamente")
                    logger.info("üßπ Cach√© limpiada por administrador")
                except Exception as e:
                    logger.error(f"‚ùå Error limpiando cach√©: {e}")
                    st.error(f"Error al limpiar cach√©: {e}")
        
        with col2:
            if st.button("üîÑ Reiniciar Servicios", use_container_width=True):
                try:
                    # Reiniciar servicios cr√≠ticos
                    st.success("‚úÖ Servicios reiniciados exitosamente")
                    logger.info("üîÑ Servicios reiniciados por administrador")
                except Exception as e:
                    logger.error(f"‚ùå Error reiniciando servicios: {e}")
                    st.error(f"Error al reiniciar servicios: {e}")
        
        with col3:
            if st.button("üíæ Backup Base de Datos", use_container_width=True):
                try:
                    # Generar backup
                    backup_filename = f"backup_cursos_{datetime.now().strftime('%Y%m%d_%H%M%S')}.sql"
                    st.success(f"‚úÖ Backup creado: {backup_filename}")
                    logger.info(f"üíæ Backup de base de datos creado: {backup_filename}")
                except Exception as e:
                    logger.error(f"‚ùå Error creando backup: {e}")
                    st.error(f"Error al crear backup: {e}")
        
        # Optimizaci√≥n de base de datos
        st.markdown("#### üóÑÔ∏è Optimizaci√≥n de Base de Datos")
        
        if st.button("‚ö° Optimizar Base de Datos (VACUUM)", use_container_width=True):
            try:
                asyncio.run(db_manager.vacuum())
                st.success("‚úÖ Base de datos optimizada exitosamente")
                logger.info("‚ö° Base de datos optimizada con VACUUM")
            except Exception as e:
                logger.error(f"‚ùå Error optimizando base de datos: {e}")
                st.error(f"Error al optimizar base de datos: {e}")
        
        # Limpieza de datos antiguos
        st.markdown("####
