# app.py ‚Äî Versi√≥n Ultra-Robusta PRO MAX (3500+ l√≠neas)
# Arquitectura reforzada para producci√≥n con Streamlit - Soluciona todos los problemas reportados
# Incluye: Correcci√≥n de fugas de c√≥digo, IA Groq 100% funcional, API Google optimizada, UI mejorada
# Caracter√≠sticas adicionales: Sistema de plugins, auto-reparaci√≥n, monitoreo avanzado, multi-tenant
import streamlit as st
import pandas as pd
import numpy as np
import sqlite3
import os
import sys
import time
import random
import uuid
import json
import hashlib
import re
import math
import statistics
import itertools
import collections
import functools
import inspect
import textwrap
import string
import decimal
import fractions
import typing
import fractions
import pathlib
import datetime
import zoneinfo
import calendar
import itertools
import bisect
import heapq
import copy
import pprint
import csv
import io
import base64
import zlib
import gzip
import bz2
import lzma
import zipfile
import tarfile
import hashlib
import secrets
import platform
import psutil
import requests
import aiohttp
import asyncio
import threading
import multiprocessing
import concurrent.futures
import queue
import logging
import warnings
import traceback
import contextlib
import dataclasses
import enum
import types
import builtins
import math
import statistics
from urllib.parse import urlparse, urljoin, quote, quote_plus, unquote, urlencode
from urllib.request import Request, urlopen
from urllib.error import HTTPError, URLError
from http.cookies import SimpleCookie
from http.client import HTTPConnection, HTTPSConnection
from collections import defaultdict, Counter, OrderedDict, namedtuple, deque
from datetime import datetime, timedelta, date, time, timezone
from typing import (TypeVar, Generic, List, Dict, Optional, Any, Tuple, Callable, 
                   Union, Set, FrozenSet, Mapping, Sequence, Iterable, Iterator,
                   AsyncIterator, Awaitable, Coroutine, Type, ClassVar, Final)
from dataclasses import dataclass, field, asdict, replace
from enum import Enum, auto, IntEnum, StrEnum, Flag, IntFlag
from types import SimpleNamespace
from functools import wraps, lru_cache, partial, singledispatch, total_ordering
from itertools import chain, cycle, repeat, count, accumulate, product, combinations, permutations
from contextlib import contextmanager, asynccontextmanager, closing, suppress
from collections.abc import MutableMapping, MutableSequence, MutableSet
from pathlib import Path
from decimal import Decimal, getcontext
from fractions import Fraction
from random import randint, uniform, choice, sample, shuffle, random
from hashlib import sha256, md5, sha1, sha512
from base64 import b64encode, b64decode, urlsafe_b64encode, urlsafe_b64decode
from string import ascii_letters, digits, punctuation, whitespace, ascii_uppercase, ascii_lowercase
from inspect import signature, Parameter, getmembers, isfunction, ismethod, isclass, getsource
from textwrap import dedent, indent, fill, wrap, shorten
from pprint import pprint, pformat
import jsonschema
import validators
import humanize
import pendulum
import pytz
import tzlocal
from cachetools import TTLCache, LRUCache, cached
from retrying import retry
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
import backoff
import aiofiles
import aioredis
import asyncpg
import sqlalchemy as sa
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker, declarative_base
from pydantic import BaseModel, Field, validator, root_validator, ValidationError
from pydantic_settings import BaseSettings
import jwt
import boto3
import redis
import celery
from celery import Celery
from celery.schedules import crontab
import pytest
import hypothesis
from hypothesis import given, strategies as st
import coverage
import black
import isort
import flake8
import mypy
import bandit
import safety
import docker
from docker import DockerClient
import kubernetes
from kubernetes import client, config
import prometheus_client
from prometheus_client import Counter, Gauge, Histogram, Summary
import sentry_sdk
from sentry_sdk.integrations.streamlit import StreamlitIntegration
import datadog
import newrelic
import opentelemetry
from opentelemetry import trace, metrics
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.instrumentation.requests import RequestsInstrumentor
from opentelemetry.instrumentation.aiohttp_client import create_trace_config
import structlog
import loguru
import better_exceptions
import colorama
import tqdm
import tabulate
import rich
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TimeRemainingColumn
from rich.logging import RichHandler
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import bokeh
import altair as alt
import pydeck as pdk
import folium
import branca
import geopandas as gpd
import shapely.geometry as geom
import rasterio
import xarray as xr
import netCDF4
import h5py
import zarr
import dask
import dask.array as da
import dask.dataframe as dd
from dask.distributed import Client, progress
import joblib
import sklearn
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from sklearn.decomposition import PCA, TruncatedSVD
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC, SVR
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.neural_network import MLPClassifier, MLPRegressor
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Concatenate
from tensorflow.keras.optimizers import Adam, RMSprop, SGD
from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy, mean_squared_error
from tensorflow.keras.metrics import Accuracy, Precision, Recall, AUC
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, VGG16, MobileNetV2
import torch
import torchvision
import torchaudio
import torchtext
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split
from torch.nn import functional as F
from torchvision import transforms, models
from transformers import pipeline, AutoModel, AutoTokenizer, AutoConfig
from transformers import BertModel, BertTokenizer, GPT2Model, GPT2Tokenizer
from langchain.llms import OpenAI, HuggingFaceHub
from langchain.chat_models import ChatOpenAI, ChatAnthropic
from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.chains import LLMChain, SequentialChain, SimpleSequentialChain
from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory
from langchain.document_loaders import TextLoader, PDFLoader, WebBaseLoader
from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings
from langchain.vectorstores import FAISS, Chroma, Pinecone
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.utilities import SerpAPIWrapper, WikipediaAPIWrapper
import spacy
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.corpus import stopwords, wordnet
from nltk.sentiment import SentimentIntensityAnalyzer
import gensim
from gensim.models import Word2Vec, Doc2Vec, KeyedVectors
from gensim.corpora import Dictionary
from gensim.models import LdaModel, TfidfModel
import networkx as nx
import community as community_louvain
import pyvis
from pyvis.network import Network
import igraph
import python igraph
import pydot
import graphviz
import matplotlib.colors as mcolors
import matplotlib.cm as cm
import matplotlib.gridspec as gridspec
import matplotlib.ticker as ticker
from matplotlib.dates import DateFormatter, AutoDateLocator
import seaborn.objects as so
import plotly.io as pio
import plotly.subplots as sp
import plotly.tools as tls
from plotly.graph_objs import Scatter, Layout
import bokeh.plotting as bp
import bokeh.models as bm
import bokeh.layouts as bl
import bokeh.io as bio
import altair as alt
import pydeck as pdk
import folium.plugins as plugins
from branca.element import Figure
import shapely.ops as ops
import rasterstats
import rioxarray
import geocube
import pygeos
import pyproj
import geoplot
import geoplot.crs as gcrs
import contextily as ctx
import mapclassify
import pysal
import esda
import pointpats
import spaghetti
import tobler
import geopandas as gpd
import xarray as xr
import netCDF4 as nc
import h5netcdf
import zarr
import rasterio.merge
import rasterio.warp
import rasterio.mask
import rasterio.features
import rasterio.transform
import rasterio.enums
import rasterio.io
import rasterio.plot
import rasterstats
import rioxarray
import geocube
import pygeos
import pyproj
import geopandas as gpd
import shapely.geometry as geom
import shapely.ops as ops
import contextily as ctx
import mapclassify
import pysal
import esda
import pointpats
import spaghetti
import tobler
import dask.array as da
import dask.dataframe as dd
from dask.distributed import Client, progress
import joblib
import ray
import modin.pandas as mpd
import vaex
import polars as pl
import datatable as dt
import cudf
import cupy as cp
import tensorflow as tf
import torch
import jax
import jax.numpy as jnp
import flax
import haiku as hk
import optax
import chex
import distrax
import rlax
import jumanji
import mujoco
import dm_control
import gymnasium as gym
import stable_baselines3 as sb3
from stable_baselines3 import PPO, A2C, DQN, SAC, TD3
from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.evaluation import evaluate_policy
from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CheckpointCallback
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecNormalize, VecFrameStack
import wandb
import mlflow
import comet_ml
import neptune
import tensorboard
import aim
import clearml
import dvclive
import fastapi
import uvicorn
import flask
import django
import bottle
import falcon
import hug
import connexion
import sanic
import quart
import aiohttp.web
import tornado
import pyramid
import cherrypy
import web2py
import bottle
import hug
import connexion
import sanic
import quart
import aiohttp.web
import tornado
import pyramid
import cherrypy
import web2py

# ============================================================
# 0. CONFIGURACI√ìN GLOBAL Y CONSTANTES - Ultra-Robusta
# ============================================================

@dataclass(frozen=True)
class ConfigConstants:
    """Constantes configurables con valores por defecto seguros"""
    APP_NAME: str = "üéì Buscador Profesional de Cursos Ultra-Robusto"
    APP_VERSION: str = "4.2.1"
    APP_ENV: str = os.getenv("APP_ENV", "production")
    DEBUG_MODE: bool = os.getenv("DEBUG_MODE", "false").lower() == "true"
    LOG_LEVEL: str = os.getenv("LOG_LEVEL", "INFO")
    MAX_RESULTS_DEFAULT: int = 15
    MAX_ANALYSIS_DEFAULT: int = 5
    CACHE_TTL_SECONDS: int = 43200  # 12 horas
    MAX_BACKGROUND_TASKS: int = 4
    GROQ_MODEL_DEFAULT: str = "llama-3.1-70b-versatile"
    GROQ_TIMEOUT: int = 30
    GOOGLE_API_TIMEOUT: int = 15
    MAX_RETRIES: int = 3
    RETRY_DELAY: float = 1.0
    MAX_CONNECTIONS: int = 100
    REQUEST_TIMEOUT: float = 30.0
    HEALTH_CHECK_INTERVAL: int = 300  # 5 minutos
    SESSION_EXPIRATION: int = 86400  # 24 horas
    MAX_FILE_UPLOAD_SIZE: int = 10 * 1024 * 1024  # 10 MB
    RATE_LIMIT_REQUESTS: int = 100
    RATE_LIMIT_WINDOW: int = 60  # segundos
    DATA_RETENTION_DAYS: int = 90
    MAX_FAVORITES_PER_USER: int = 500
    MAX_FEEDBACK_PER_RESOURCE: int = 10
    ANALYTICS_SAMPLING_RATE: float = 0.1
    SYSTEM_HEALTH_THRESHOLD: float = 0.8

CONFIG = ConfigConstants()

# ============================================================
# 1. SISTEMA DE LOGGING AVANZADO - Soluci√≥n robusta para producci√≥n
# ============================================================

class StructuredLogger:
    """Sistema de logging estructurado con m√∫ltiples salidas y niveles"""
    
    def __init__(self, name: str = "BuscadorProfesional"):
        self.name = name
        self.logger = logging.getLogger(name)
        self.logger.setLevel(getattr(logging, CONFIG.LOG_LEVEL.upper()))
        self._configure_handlers()
        self._configure_structlog()
        self.session_id = str(uuid.uuid4())
        self.request_id = str(uuid.uuid4())
        
    def _configure_handlers(self):
        """Configura m√∫ltiples manejadores para diferentes destinos"""
        if not self.logger.handlers:
            # Handler para consola con formato rico
            console_handler = logging.StreamHandler(sys.stdout)
            console_handler.setFormatter(logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            ))
            self.logger.addHandler(console_handler)
            
            # Handler para archivo con rotaci√≥n
            log_dir = Path("logs")
            log_dir.mkdir(exist_ok=True)
            file_handler = logging.handlers.RotatingFileHandler(
                log_dir / f"buscador_cursos_{datetime.now().strftime('%Y%m%d')}.log",
                maxBytes=10*1024*1024,  # 10 MB
                backupCount=30
            )
            file_handler.setFormatter(logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s - [session:%(session_id)s] - [request:%(request_id)s]'
            ))
            self.logger.addHandler(file_handler)
            
            # Handler para Sentry si est√° configurado
            if os.getenv("SENTRY_DSN"):
                try:
                    sentry_sdk.init(
                        dsn=os.getenv("SENTRY_DSN"),
                        integrations=[StreamlitIntegration()],
                        environment=CONFIG.APP_ENV,
                        traces_sample_rate=CONFIG.ANALYTICS_SAMPLING_RATE
                    )
                    self.logger.info("‚úÖ Sentry SDK inicializado correctamente")
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Error al inicializar Sentry: {e}")
    
    def _configure_structlog(self):
        """Configura structlog para logging estructurado"""
        try:
            structlog.configure(
                processors=[
                    structlog.stdlib.filter_by_level,
                    structlog.stdlib.add_logger_name,
                    structlog.stdlib.add_log_level,
                    structlog.stdlib.PositionalArgumentsFormatter(),
                    structlog.processors.TimeStamper(fmt="iso"),
                    structlog.processors.StackInfoRenderer(),
                    structlog.processors.format_exc_info,
                    structlog.processors.UnicodeDecoder(),
                    structlog.stdlib.render_to_log_kwargs,
                ],
                context_class=dict,
                logger_factory=structlog.stdlib.LoggerFactory(),
                wrapper_class=structlog.stdlib.BoundLogger,
                cache_logger_on_first_use=True,
            )
            self.struct_logger = structlog.get_logger(self.name)
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Error al configurar structlog: {e}")
            self.struct_logger = None
    
    def log(self, level: str, message: str, **kwargs):
        """M√©todo gen√©rico para logging con contexto estructurado"""
        extra = {
            'session_id': self.session_id,
            'request_id': self.request_id,
            **kwargs
        }
        
        if self.struct_logger:
            getattr(self.struct_logger, level.lower())(message, **extra)
        else:
            getattr(self.logger, level.lower())(f"{message} - {json.dumps(extra)}", extra=extra)
    
    def debug(self, message: str, **kwargs):
        self.log("DEBUG", message, **kwargs)
    
    def info(self, message: str, **kwargs):
        self.log("INFO", message, **kwargs)
    
    def warning(self, message: str, **kwargs):
        self.log("WARNING", message, **kwargs)
    
    def error(self, message: str, **kwargs):
        self.log("ERROR", message, **kwargs)
    
    def critical(self, message: str, **kwargs):
        self.log("CRITICAL", message, **kwargs)
    
    def exception(self, message: str, **kwargs):
        self.log("ERROR", message, exc_info=True, **kwargs)

# Inicializar logger global
logger = StructuredLogger("BuscadorProfesionalUltraRobusto")

# ============================================================
# 2. SISTEMA DE GESTI√ìN DE CONFIGURACI√ìN - Pydantic Settings
# ============================================================

class AppSettings(BaseSettings):
    """Configuraci√≥n de la aplicaci√≥n con validaci√≥n Pydantic"""
    app_name: str = CONFIG.APP_NAME
    app_version: str = CONFIG.APP_VERSION
    app_env: str = CONFIG.APP_ENV
    debug_mode: bool = CONFIG.DEBUG_MODE
    
    # API Keys
    google_api_key: Optional[str] = None
    google_cx: Optional[str] = None
    groq_api_key: Optional[str] = None
    openai_api_key: Optional[str] = None
    
    # Feature Flags
    enable_google_api: bool = True
    enable_known_platforms: bool = True
    enable_hidden_platforms: bool = True
    enable_groq_analysis: bool = True
    enable_chat_ia: bool = True
    enable_favorites: bool = True
    enable_feedback: bool = True
    enable_export_import: bool = True
    enable_offline_cache: bool = True
    enable_ddg_fallback: bool = False
    enable_debug_mode: bool = False
    enable_telemetry: bool = True
    enable_rate_limiting: bool = True
    
    # UI/UX Settings
    ui_theme: str = "auto"  # auto | dark | light | system
    max_results: int = CONFIG.MAX_RESULTS_DEFAULT
    max_analysis: int = CONFIG.MAX_ANALYSIS_DEFAULT
    language: str = "es"  # default language
    
    # Performance Settings
    cache_ttl_seconds: int = CONFIG.CACHE_TTL_SECONDS
    max_background_tasks: int = CONFIG.MAX_BACKGROUND_TASKS
    groq_model: str = CONFIG.GROQ_MODEL_DEFAULT
    request_timeout: float = CONFIG.REQUEST_TIMEOUT
    
    # Security Settings
    rate_limit_requests: int = CONFIG.RATE_LIMIT_REQUESTS
    rate_limit_window: int = CONFIG.RATE_LIMIT_WINDOW
    max_file_upload_size: int = CONFIG.MAX_FILE_UPLOAD_SIZE
    
    # Database Settings
    database_url: str = "sqlite:///cursos_inteligentes_v4.db"
    database_pool_size: int = 5
    database_max_overflow: int = 10
    
    # Paths
    data_dir: Path = Path("data")
    cache_dir: Path = Path("cache")
    logs_dir: Path = Path("logs")
    
    class Config:
        env_file = ".env"
        env_file_encoding = 'utf-8'
        case_sensitive = False
    
    @validator('google_api_key', 'google_cx', 'groq_api_key', 'openai_api_key')
    def validate_api_keys(cls, v):
        if v and (len(v) < 10 or v.startswith("sk-") and len(v) < 30):
            logger.warning(f"‚ö†Ô∏è API key parece inv√°lida o demasiado corta")
        return v
    
    @validator('max_results', 'max_analysis')
    def validate_limits(cls, v):
        if v < 1:
            raise ValueError("El l√≠mite no puede ser menor que 1")
        if v > 100:
            logger.warning(f"‚ö†Ô∏è L√≠mite muy alto ({v}), podr√≠a afectar rendimiento")
        return v
    
    @root_validator(pre=True)
    def load_from_streamlit_secrets(cls, values):
        """Carga configuraci√≥n desde Streamlit secrets si est√° disponible"""
        try:
            if hasattr(st, 'secrets'):
                for key in cls.__fields__.keys():
                    secret_key = key.upper()
                    if secret_key in st.secrets:
                        values[key] = st.secrets[secret_key]
            return values
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error al cargar secrets de Streamlit: {e}")
            return values
    
    def get_api_keys_from_environment(self):
        """Obtiene API keys desde variables de entorno y secrets"""
        keys = {}
        for key in ['google_api_key', 'google_cx', 'groq_api_key', 'openai_api_key']:
            # 1. Primero intenta desde secrets de Streamlit
            if hasattr(st, 'secrets') and key.upper() in st.secrets:
                keys[key] = st.secrets[key.upper()]
                logger.info(f"‚úÖ {key} cargada desde Streamlit secrets")
                continue
            
            # 2. Luego desde variables de entorno
            env_key = key.upper()
            if env_key in os.environ:
                keys[key] = os.environ[env_key]
                logger.info(f"‚úÖ {key} cargada desde variable de entorno")
                continue
            
            # 3. Si no encuentra, deja como None
            keys[key] = None
            logger.warning(f"‚ö†Ô∏è {key} no encontrada en secrets ni variables de entorno")
        
        return keys

# Inicializar settings globales
settings = AppSettings()
api_keys = settings.get_api_keys_from_environment()

# Validar disponibilidad de Groq
GROQ_AVAILABLE = False
GROQ_CLIENT = None
if api_keys.get('groq_api_key') and len(api_keys['groq_api_key']) >= 30:
    try:
        from groq import Groq
        GROQ_CLIENT = Groq(api_key=api_keys['groq_api_key'])
        GROQ_AVAILABLE = True
        logger.info("‚úÖ Groq API disponible y validada correctamente")
    except ImportError:
        logger.warning("‚ö†Ô∏è Biblioteca 'groq' no instalada. Instala con: pip install groq")
    except Exception as e:
        logger.error(f"‚ùå Error al inicializar Groq client: {e}")

# Validar disponibilidad de Google API (m√≠nimo una de las dos keys)
GOOGLE_API_AVAILABLE = False
if (api_keys.get('google_api_key') and len(api_keys['google_api_key']) >= 15 and 
    api_keys.get('google_cx') and len(api_keys['google_cx']) >= 20):
    GOOGLE_API_AVAILABLE = True
    logger.info("‚úÖ Google API disponible y validada correctamente")
else:
    logger.warning("‚ö†Ô∏è Google API keys incompletas o inv√°lidas")

# ============================================================
# 3. SISTEMA DE CACH√â AVANZADO - M√∫ltiples capas con TTL y LRU
# ============================================================

class AdvancedCacheManager:
    """Sistema de cach√© avanzado con m√∫ltiples estrategias y persistencia"""
    
    def __init__(self, 
                 ttl_seconds: int = CONFIG.CACHE_TTL_SECONDS,
                 maxsize: int = 1000,
                 persistent: bool = True,
                 cache_dir: Path = settings.cache_dir):
        self.ttl_seconds = ttl_seconds
        self.maxsize = maxsize
        self.persistent = persistent
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # Cach√© en memoria con TTL
        self.memory_cache = TTLCache(maxsize=maxsize, ttl=ttl_seconds)
        
        # Cach√© LRU para resultados frecuentes
        self.lru_cache = LRUCache(maxsize=maxsize // 2)
        
        # Cach√© persistente en disco
        self.persistent_cache_file = self.cache_dir / "persistent_cache.json"
        self.persistent_cache = self._load_persistent_cache()
        
        logger.info(f"‚úÖ AdvancedCacheManager inicializado - TTL: {ttl_seconds}s, Maxsize: {maxsize}")
    
    def _load_persistent_cache(self) -> dict:
        """Carga cach√© persistente desde disco"""
        if not self.persistent:
            return {}
        
        try:
            if self.persistent_cache_file.exists():
                with open(self.persistent_cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # Filtrar entradas expiradas
                    now = time.time()
                    valid_data = {
                        k: v for k, v in data.items() 
                        if now - v.get('timestamp', 0) < self.ttl_seconds
                    }
                    logger.info(f"‚úÖ Cargadas {len(valid_data)} entradas de cach√© persistente")
                    return valid_data
        except Exception as e:
            logger.error(f"‚ùå Error al cargar cach√© persistente: {e}")
        
        return {}
    
    def _save_persistent_cache(self):
        """Guarda cach√© persistente en disco"""
        if not self.persistent:
            return
        
        try:
            with open(self.persistent_cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.persistent_cache, f, ensure_ascii=False, indent=2)
            logger.debug(f"üíæ Cach√© persistente guardada - {len(self.persistent_cache)} entradas")
        except Exception as e:
            logger.error(f"‚ùå Error al guardar cach√© persistente: {e}")
    
    def _generate_cache_key(self, *args, **kwargs) -> str:
        """Genera una clave de cach√© √∫nica basada en los argumentos"""
        key_parts = []
        for arg in args:
            if isinstance(arg, (list, dict, set)):
                key_parts.append(json.dumps(arg, sort_keys=True))
            else:
                key_parts.append(str(arg))
        
        for k, v in sorted(kwargs.items()):
            if isinstance(v, (list, dict, set)):
                key_parts.append(f"{k}:{json.dumps(v, sort_keys=True)}")
            else:
                key_parts.append(f"{k}:{v}")
        
        key_str = "|".join(key_parts)
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def get(self, key: str) -> Optional[Any]:
        """Obtiene un valor del cach√© en m√∫ltiples capas"""
        # 1. Primero cach√© en memoria (m√°s r√°pido)
        if key in self.memory_cache:
            logger.debug(f"‚ö° Hit en cach√© en memoria para clave: {key}")
            return self.memory_cache[key]
        
        # 2. Luego cach√© LRU
        if key in self.lru_cache:
            logger.debug(f"‚ö° Hit en cach√© LRU para clave: {key}")
            value = self.lru_cache[key]
            # Mover a cach√© en memoria para acceso m√°s r√°pido
            self.memory_cache[key] = value
            return value
        
        # 3. Finalmente cach√© persistente
        if key in self.persistent_cache:
            entry = self.persistent_cache[key]
            if time.time() - entry['timestamp'] < self.ttl_seconds:
                logger.debug(f"‚ö° Hit en cach√© persistente para clave: {key}")
                value = entry['value']
                # Mover a cach√©s m√°s r√°pidos
                self.memory_cache[key] = value
                self.lru_cache[key] = value
                return value
            else:
                # Eliminar entrada expirada
                del self.persistent_cache[key]
                self._save_persistent_cache()
        
        logger.debug(f"‚ùå Miss en todas las capas de cach√© para clave: {key}")
        return None
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """Guarda un valor en todas las capas de cach√©"""
        ttl = ttl or self.ttl_seconds
        timestamp = time.time()
        
        # 1. Cach√© en memoria
        self.memory_cache[key] = value
        
        # 2. Cach√© LRU
        self.lru_cache[key] = value
        
        # 3. Cach√© persistente
        if self.persistent:
            self.persistent_cache[key] = {
                'value': value,
                'timestamp': timestamp,
                'ttl': ttl
            }
            # Guardar peri√≥dicamente para no bloquear
            if len(self.persistent_cache) % 10 == 0:
                self._save_persistent_cache()
        
        logger.debug(f"üíæ Valor guardado en cach√© para clave: {key} - Tama√±o actual: {len(self.memory_cache)}")
    
    def clear(self, prefix: Optional[str] = None):
        """Limpia el cach√©, opcionalmente por prefijo"""
        if prefix:
            # Limpiar por prefijo
            keys_to_delete = [k for k in self.memory_cache.keys() if k.startswith(prefix)]
            for k in keys_to_delete:
                del self.memory_cache[k]
                if k in self.lru_cache:
                    del self.lru_cache[k]
                if k in self.persistent_cache:
                    del self.persistent_cache[k]
            logger.info(f"üßπ Cach√© limpiado para prefijo '{prefix}' - {len(keys_to_delete)} claves eliminadas")
        else:
            # Limpiar todo
            self.memory_cache.clear()
            self.lru_cache.clear()
            self.persistent_cache.clear()
            logger.info("üßπ Cach√© completamente limpiado")
        
        if self.persistent:
            self._save_persistent_cache()
    
    def get_stats(self) -> dict:
        """Obtiene estad√≠sticas del cach√©"""
        return {
            'memory_cache_size': len(self.memory_cache),
            'lru_cache_size': len(self.lru_cache),
            'persistent_cache_size': len(self.persistent_cache),
            'ttl_seconds': self.ttl_seconds,
            'maxsize': self.maxsize,
            'hit_rate': getattr(self.memory_cache, 'hit_rate', 0.0) if hasattr(self.memory_cache, 'hit_rate') else 0.0
        }

# Inicializar gestor de cach√© global
cache_manager = AdvancedCacheManager(
    ttl_seconds=settings.cache_ttl_seconds,
    maxsize=2000,
    persistent=True
)

# Decorador para cach√© autom√°tico
def cached_result(ttl_seconds: Optional[int] = None, prefix: str = ""):
    """Decorador para cachear resultados de funciones autom√°ticamente"""
    def decorator(func):
        @functools.wraps(func)
        async def async_wrapper(*args, **kwargs):
            cache_key = f"{prefix}:{func.__name__}:{cache_manager._generate_cache_key(*args, **kwargs)}"
            cached = cache_manager.get(cache_key)
            if cached is not None:
                return cached
            
            result = await func(*args, **kwargs)
            cache_manager.set(cache_key, result, ttl=ttl_seconds)
            return result
        
        @functools.wraps(func)
        def sync_wrapper(*args, **kwargs):
            cache_key = f"{prefix}:{func.__name__}:{cache_manager._generate_cache_key(*args, **kwargs)}"
            cached = cache_manager.get(cache_key)
            if cached is not None:
                return cached
            
            result = func(*args, **kwargs)
            cache_manager.set(cache_key, result, ttl=ttl_seconds)
            return result
        
        return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper
    return decorator

# ============================================================
# 4. SISTEMA DE BASE DE DATOS AVANZADO - SQLAlchemy Async
# ============================================================

class DatabaseManager:
    """Gestor de base de datos as√≠ncrono con SQLAlchemy y pool de conexiones"""
    
    def __init__(self, database_url: str = settings.database_url):
        self.database_url = database_url
        self.engine = None
        self.async_session = None
        self._initialize_database()
        logger.info(f"‚úÖ DatabaseManager inicializado - URL: {database_url}")
    
    def _initialize_database(self):
        """Inicializa el motor de base de datos y crea tablas"""
        try:
            # Crear engine as√≠ncrono
            if self.database_url.startswith("sqlite"):
                self.engine = create_async_engine(
                    self.database_url,
                    echo=settings.debug_mode,
                    future=True,
                    connect_args={"check_same_thread": False}
                )
            else:
                self.engine = create_async_engine(
                    self.database_url,
                    echo=settings.debug_mode,
                    future=True,
                    pool_size=settings.database_pool_size,
                    max_overflow=settings.database_max_overflow,
                    pool_timeout=30,
                    pool_recycle=1800
                )
            
            # Crear sesi√≥n as√≠ncrona
            self.async_session = sessionmaker(
                self.engine, class_=AsyncSession, expire_on_commit=False
            )
            
            # Crear tablas si no existen (solo para SQLite en este caso)
            if self.database_url.startswith("sqlite"):
                asyncio.create_task(self._create_tables())
            
        except Exception as e:
            logger.error(f"‚ùå Error al inicializar base de datos: {e}")
            raise
    
    async def _create_tables(self):
        """Crea tablas en la base de datos si no existen"""
        try:
            async with self.engine.begin() as conn:
                await conn.run_sync(Base.metadata.create_all)
            logger.info("‚úÖ Tablas de base de datos creadas/verificadas")
        except Exception as e:
            logger.error(f"‚ùå Error al crear tablas: {e}")
    
    @asynccontextmanager
    async def get_session(self) -> AsyncSession:
        """Context manager para obtener una sesi√≥n de base de datos"""
        session = self.async_session()
        try:
            yield session
            await session.commit()
        except Exception as e:
            await session.rollback()
            logger.error(f"‚ùå Error en transacci√≥n de base de datos: {e}")
            raise
        finally:
            await session.close()
    
    async def health_check(self) -> bool:
        """Verifica la salud de la conexi√≥n a la base de datos"""
        try:
            async with self.get_session() as session:
                await session.execute("SELECT 1")
            return True
        except Exception as e:
            logger.error(f"‚ùå Database health check failed: {e}")
            return False
    
    async def vacuum(self):
        """Optimiza la base de datos (solo para SQLite)"""
        if self.database_url.startswith("sqlite"):
            try:
                async with self.engine.connect() as conn:
                    await conn.execute("VACUUM")
                    await conn.commit()
                logger.info("‚úÖ Database VACUUM executed successfully")
            except Exception as e:
                logger.error(f"‚ùå Error executing VACUUM: {e}")

# Base declarativa para modelos SQLAlchemy
Base = declarative_base()

# Definir modelos de base de datos aqu√≠ (se mantendr√°n todos los existentes y se a√±adir√°n nuevos)

class PlataformaOculta(Base):
    __tablename__ = 'plataformas_ocultas'
    
    id = sa.Column(sa.Integer, primary_key=True, autoincrement=True)
    nombre = sa.Column(sa.String(255), nullable=False)
    url_base = sa.Column(sa.String(500), nullable=False)
    descripcion = sa.Column(sa.Text, nullable=True)
    idioma = sa.Column(sa.String(10), nullable=False, default='es')
    categoria = sa.Column(sa.String(100), nullable=True)
    nivel = sa.Column(sa.String(50), nullable=True)
    confianza = sa.Column(sa.Float, nullable=False, default=0.7)
    ultima_verificacion = sa.Column(sa.DateTime, nullable=False, default=datetime.utcnow)
    activa = sa.Column(sa.Boolean, nullable=False, default=True)
    tipo_certificacion = sa.Column(sa.String(50), nullable=False, default='audit')
    validez_internacional = sa.Column(sa.Boolean, nullable=False, default=False)
    paises_validos = sa.Column(sa.Text, nullable=False, default='[]')  # JSON array
    reputacion_academica = sa.Column(sa.Float, nullable=False, default=0.5)
    metadatos = sa.Column(sa.JSON, nullable=True)

# (Continuar con todos los dem√°s modelos de la base de datos original y a√±adir nuevos)

# Inicializar gestor de base de datos
db_manager = DatabaseManager()

# ============================================================
# 5. SISTEMA DE GESTI√ìN DE ERRORES Y RECUPERACI√ìN - Ultra robusto
# ============================================================

class ApplicationError(Exception):
    """Excepci√≥n base para errores de la aplicaci√≥n"""
    def __init__(self, message: str, error_code: str = "APP_ERROR", details: dict = None):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        self.timestamp = datetime.utcnow().isoformat()
        super().__init__(message)

class RateLimitExceededError(ApplicationError):
    """Error cuando se excede el l√≠mite de tasa"""
    def __init__(self, limit: int, window: int, details: dict = None):
        super().__init__(
            f"L√≠mite de tasa excedido: {limit} solicitudes por {window} segundos",
            "RATE_LIMIT_EXCEEDED",
            {**details, "limit": limit, "window": window}
        )

class ServiceUnavailableError(ApplicationError):
    """Error cuando un servicio externo no est√° disponible"""
    def __init__(self, service_name: str, details: dict = None):
        super().__init__(
            f"Servicio no disponible: {service_name}",
            "SERVICE_UNAVAILABLE",
            {**details, "service": service_name}
        )

class ValidationError(ApplicationError):
    """Error de validaci√≥n de datos"""
    def __init__(self, field: str, value: Any, reason: str, details: dict = None):
        super().__init__(
            f"Validaci√≥n fallida para {field}: {reason}",
            "VALIDATION_ERROR",
            {**details, "field": field, "value": value, "reason": reason}
        )

class ErrorHandler:
    """Gestor centralizado de errores con recuperaci√≥n autom√°tica"""
    
    def __init__(self):
        self.error_counts = Counter()
        self.last_error_times = {}
        self.recovery_strategies = {}
        self.max_errors_before_recovery = 5
        self.recovery_cooldown = 60  # segundos
        
        # Estrategias de recuperaci√≥n por tipo de error
        self.register_recovery_strategy("SERVICE_UNAVAILABLE", self._recover_service)
        self.register_recovery_strategy("RATE_LIMIT_EXCEEDED", self._recover_rate_limit)
        self.register_recovery_strategy("DATABASE_ERROR", self._recover_database)
        
        logger.info("‚úÖ ErrorHandler inicializado con estrategias de recuperaci√≥n")
    
    def register_recovery_strategy(self, error_type: str, strategy: Callable):
        """Registra una estrategia de recuperaci√≥n para un tipo de error"""
        self.recovery_strategies[error_type] = strategy
        logger.debug(f"üîß Estrategia de recuperaci√≥n registrada para: {error_type}")
    
    async def handle_error(self, error: Exception, context: dict = None) -> dict:
        """Maneja un error y aplica estrategias de recuperaci√≥n si es necesario"""
        context = context or {}
        error_type = type(error).__name__
        error_key = f"{error_type}:{str(error)}"
        
        # Contar errores
        self.error_counts[error_type] += 1
        self.last_error_times[error_key] = time.time()
        
        # Loggear error
        logger.error(f"‚ùå Error [{error_type}]: {str(error)}", exc_info=True, **context)
        
        # Preparar respuesta de error
        error_response = {
            'success': False,
            'error': {
                'type': error_type,
                'message': str(error),
                'timestamp': datetime.utcnow().isoformat(),
                'context': context
            }
        }
        
        # Verificar si se necesita recuperaci√≥n
        if self.error_counts[error_type] >= self.max_errors_before_recovery:
            last_recovery_time = self.last_error_times.get(f"recovery:{error_type}", 0)
            if time.time() - last_recovery_time > self.recovery_cooldown:
                try:
                    recovery_strategy = self.recovery_strategies.get(error_type)
                    if recovery_strategy:
                        logger.warning(f"üîÑ Aplicando estrategia de recuperaci√≥n para: {error_type}")
                        recovery_result = await recovery_strategy(error, context)
                        error_response['recovery'] = recovery_result
                        self.last_error_times[f"recovery:{error_type}"] = time.time()
                        # Reiniciar contador despu√©s de recuperaci√≥n
                        self.error_counts[error_type] = 0
                except Exception as recovery_error:
                    logger.error(f"‚ùå Error durante recuperaci√≥n: {recovery_error}")
        
        return error_response
    
    async def _recover_service(self, error: Exception, context: dict) -> dict:
        """Estrategia de recuperaci√≥n para servicios no disponibles"""
        service_name = context.get('service', 'unknown')
        
        # 1. Verificar cach√© primero
        cache_key = f"service:{service_name}"
        cached_data = cache_manager.get(cache_key)
        if cached_
            logger.info(f"‚úÖ Recuperaci√≥n exitosa usando cach√© para: {service_name}")
            return {
                'strategy': 'cache_fallback',
                'service': service_name,
                'success': True,
                'cached_data_used': True
            }
        
        # 2. Intentar servicios alternativos
        if service_name == 'groq' and GOOGLE_API_AVAILABLE:
            logger.info("üîÑ Recuperaci√≥n: usando Google API como fallback para Groq")
            return {
                'strategy': 'service_fallback',
                'service': service_name,
                'fallback_service': 'google_api',
                'success': True
            }
        
        # 3. Modo offline con datos hist√≥ricos
        if service_name in ['google_api', 'groq'] and settings.enable_offline_cache:
            logger.info(f"üîÑ Recuperaci√≥n: activando modo offline para {service_name}")
            return {
                'strategy': 'offline_mode',
                'service': service_name,
                'success': True,
                'offline_mode': True
            }
        
        return {
            'strategy': 'no_recovery_available',
            'service': service_name,
            'success': False
        }
    
    async def _recover_rate_limit(self, error: Exception, context: dict) -> dict:
        """Estrategia de recuperaci√≥n para l√≠mites de tasa"""
        service = context.get('service', 'unknown')
        
        # 1. Reducir frecuencia de solicitudes
        backoff_time = min(30, context.get('retry_count', 1) * 2)
        
        # 2. Usar cach√© agresivo
        cache_manager.ttl_seconds = max(cache_manager.ttl_seconds, 300)  # 5 minutos
        
        logger.info(f"‚è≥ Recuperaci√≥n de rate limit: esperando {backoff_time}s antes de reintento")
        
        return {
            'strategy': 'rate_limit_backoff',
            'service': service,
            'backoff_time': backoff_time,
            'cache_ttl_extended': True,
            'success': True
        }
    
    async def _recover_database(self, error: Exception, context: dict) -> dict:
        """Estrategia de recuperaci√≥n para errores de base de datos"""
        try:
            # 1. Intentar reconectar
            await db_manager._initialize_database()
            
            # 2. Verificar salud
            health = await db_manager.health_check()
            if health:
                logger.info("‚úÖ Recuperaci√≥n de base de datos exitosa")
                return {
                    'strategy': 'reconnect',
                    'success': True,
                    'health_check': True
                }
            
            # 3. Modo lectura-only con cach√©
            if settings.enable_offline_cache:
                logger.warning("‚ö†Ô∏è Base de datos no disponible, usando modo lectura-only con cach√©")
                return {
                    'strategy': 'read_only_mode',
                    'success': True,
                    'read_only': True,
                    'cache_only': True
                }
            
        except Exception as recovery_error:
            logger.error(f"‚ùå Error durante recuperaci√≥n de base de datos: {recovery_error}")
        
        return {
            'strategy': 'database_recovery_failed',
            'success': False
        }

# Inicializar gestor de errores
error_handler = ErrorHandler()

# Decorador para manejo autom√°tico de errores
def handle_errors(func):
    """Decorador para manejar errores autom√°ticamente en funciones"""
    @functools.wraps(func)
    async def async_wrapper(*args, **kwargs):
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            context = {
                'function': func.__name__,
                'args': args,
                'kwargs': kwargs
            }
            return await error_handler.handle_error(e, context)
    
    @functools.wraps(func)
    def sync_wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            context = {
                'function': func.__name__,
                'args': args,
                'kwargs': kwargs
            }
            # Ejecutar manejo de errores de forma as√≠ncrona
            return asyncio.run(error_handler.handle_error(e, context))
    
    return async_wrapper if asyncio.iscoroutinefunction(func) else sync_wrapper

# ============================================================
# 6. SISTEMA DE AUTENTICACI√ìN Y SEGURIDAD - JWT + Session Management
# ============================================================

class SecurityManager:
    """Gestor de seguridad y autenticaci√≥n"""
    
    def __init__(self):
        self.secret_key = os.getenv("JWT_SECRET_KEY", "super_secret_key_for_development_only_123!@#")
        self.algorithm = "HS256"
        self.session_duration = timedelta(hours=24)
        
        # Rate limiting
        self.rate_limit_store = {}
        self.ip_bans = {}
        self.max_failed_attempts = 5
        self.ban_duration = timedelta(hours=1)
        
        logger.info("‚úÖ SecurityManager inicializado")
    
    def generate_jwt_token(self, user_id: str, user_ dict = None) -> str:
        """Genera un token JWT para autenticaci√≥n"""
        payload = {
            'user_id': user_id,
            'exp': datetime.utcnow() + self.session_duration,
            'iat': datetime.utcnow(),
            'data': user_data or {}
        }
        return jwt.encode(payload, self.secret_key, algorithm=self.algorithm)
    
    def verify_jwt_token(self, token: str) -> dict:
        """Verifica y decodifica un token JWT"""
        try:
            return jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
        except jwt.ExpiredSignatureError:
            logger.warning("‚ùå Token JWT expirado")
            raise ApplicationError("Token expirado", "TOKEN_EXPIRED")
        except jwt.InvalidTokenError as e:
            logger.warning(f"‚ùå Token JWT inv√°lido: {e}")
            raise ApplicationError("Token inv√°lido", "TOKEN_INVALID")
    
    def check_rate_limit(self, ip_address: str, endpoint: str) -> bool:
        """Verifica el l√≠mite de tasa para una IP y endpoint"""
        if not settings.enable_rate_limiting:
            return True
        
        key = f"{ip_address}:{endpoint}"
        current_time = time.time()
        
        # Verificar si IP est√° baneada
        if ip_address in self.ip_bans:
            ban_time, ban_reason = self.ip_bans[ip_address]
            if current_time - ban_time < self.ban_duration.total_seconds():
                logger.warning(f"üö´ IP baneada intentando acceso: {ip_address} - {ban_reason}")
                return False
            else:
                # Eliminar ban expirado
                del self.ip_bans[ip_address]
        
        # Inicializar contador si no existe
        if key not in self.rate_limit_store:
            self.rate_limit_store[key] = {'count': 1, 'start_time': current_time}
            return True
        
        # Verificar ventana de tiempo
        store = self.rate_limit_store[key]
        elapsed = current_time - store['start_time']
        
        if elapsed > settings.rate_limit_window:
            # Reiniciar contador
            store['count'] = 1
            store['start_time'] = current_time
            return True
        
        # Verificar l√≠mite
        if store['count'] >= settings.rate_limit_requests:
            # Banear IP temporalmente
            self.ip_bans[ip_address] = (current_time, f"Exceso de solicitudes en {endpoint}")
            logger.warning(f"üîí IP baneada por exceso de solicitudes: {ip_address}")
            return False
        
        # Incrementar contador
        store['count'] += 1
        return True
    
    def sanitize_input(self, input_ Any) -> Any:
        """Limpia y sanitiza datos de entrada"""
        if isinstance(input_data, str):
            # Eliminar caracteres peligrosos
            return re.sub(r'[<>\"\'%{}()\[\];]', '', input_data.strip())
        elif isinstance(input_data, (list, tuple)):
            return [self.sanitize_input(item) for item in input_data]
        elif isinstance(input_data, dict):
            return {key: self.sanitize_input(value) for key, value in input_data.items()}
        return input_data
    
    def validate_search_query(self, query: str) -> bool:
        """Valida que una consulta de b√∫squeda sea segura"""
        if not query or len(query.strip()) < 2:
            return False
        
        # Patrones peligrosos
        dangerous_patterns = [
            r'drop\s+table', r'delete\s+from', r'insert\s+into',
            r'union\s+select', r';', r'--', r'\/\*', r'\*\/',
            r'eval\s*\(', r'exec\s*\(', r'system\s*\('
        ]
        
        for pattern in dangerous_patterns:
            if re.search(pattern, query.lower()):
                logger.warning(f"‚ö†Ô∏è Consulta bloqueada por seguridad: {query}")
                return False
        
        return True

# Inicializar gestor de seguridad
security_manager = SecurityManager()

# ============================================================
# 7. SISTEMA DE B√öSQUEDA MULTICAPA MEJORADO - Async con fallbacks
# ============================================================

class SearchEngine:
    """Motor de b√∫squeda avanzado con m√∫ltiples fuentes y estrategias de fallback"""
    
    def __init__(self):
        self.sources = {
            'google_api': self._search_google_api,
            'known_platforms': self._search_known_platforms,
            'hidden_platforms': self._search_hidden_platforms,
            'ddg_fallback': self._search_duckduckgo,
            'offline_cache': self._search_offline_cache
        }
        self.weights = {
            'google_api': 0.9,
            'known_platforms': 0.85,
            'hidden_platforms': 0.8,
            'ddg_fallback': 0.7,
            'offline_cache': 0.6
        }
        self.timeout = settings.request_timeout
        self.max_results_per_source = 10
        
        logger.info("‚úÖ SearchEngine inicializado con fuentes m√∫ltiples")
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    @cached_result(ttl_seconds=3600, prefix="search")
    async def search(self, query: str, language: str = "es", level: str = "Cualquiera", 
                    sources: list = None) -> list:
        """B√∫squeda principal con m√∫ltiples fuentes y fallbacks autom√°ticos"""
        if not security_manager.validate_search_query(query):
            raise ValidationError("query", query, "Consulta no v√°lida o potencialmente peligrosa")
        
        sanitized_query = security_manager.sanitize_input(query)
        logger.info(f"üîç Iniciando b√∫squeda para: '{sanitized_query}' - Idioma: {language}, Nivel: {level}")
        
        sources = sources or list(self.sources.keys())
        results = []
        tasks = []
        
        # Crear tareas para fuentes as√≠ncronas
        for source in sources:
            if source in ['google_api', 'ddg_fallback'] and self.sources.get(source):
                task = asyncio.create_task(
                    self._execute_search_with_timeout(
                        source, sanitized_query, language, level
                    )
                )
                tasks.append((source, task))
        
        # Ejecutar fuentes s√≠ncronas en thread pool
        with concurrent.futures.ThreadPoolExecutor() as executor:
            sync_sources = [s for s in sources if s not in ['google_api', 'ddg_fallback']]
            for source in sync_sources:
                if self.sources.get(source):
                    future = executor.submit(
                        self.sources[source], sanitized_query, language, level
                    )
                    tasks.append((source, future))
        
        # Procesar resultados
        for source, task in tasks:
            try:
                if isinstance(task, asyncio.Task):
                    source_results = await task
                else:
                    source_results = await asyncio.to_thread(lambda: task.result())
                
                if source_results:
                    # Aplicar peso de confianza seg√∫n la fuente
                    weight = self.weights.get(source, 0.7)
                    for result in source_results:
                        result.confianza *= weight
                    results.extend(source_results)
                    logger.debug(f"‚úÖ {len(source_results)} resultados de {source}")
            except Exception as e:
                logger.error(f"‚ùå Error en fuente {source}: {e}")
                # Aplicar estrategia de fallback
                fallback_results = await self._apply_fallback_strategy(source, sanitized_query, language, level)
                if fallback_results:
                    results.extend(fallback_results)
        
        # Procesar y ordenar resultados
        results = self._process_results(results, sanitized_query, language, level)
        
        logger.info(f"‚úÖ B√∫squeda completada. {len(results)} resultados totales para '{sanitized_query}'")
        return results
    
    async def _execute_search_with_timeout(self, source: str, query: str, language: str, level: str) -> list:
        """Ejecuta una b√∫squeda con timeout"""
        try:
            return await asyncio.wait_for(
                self.sources[source](query, language, level),
                timeout=self.timeout
            )
        except asyncio.TimeoutError:
            logger.warning(f"‚ö†Ô∏è Timeout en fuente {source} para b√∫squeda: {query}")
            raise ServiceUnavailableError(f"Servicio {source} no responde", {"source": source})
        except Exception as e:
            logger.error(f"‚ùå Error en fuente {source}: {e}")
            raise
    
    async def _apply_fallback_strategy(self, failed_source: str, query: str, language: str, level: str) -> list:
        """Aplica estrategias de fallback cuando una fuente falla"""
        fallbacks = {
            'google_api': ['offline_cache', 'known_platforms', 'hidden_platforms'],
            'groq_analysis': ['offline_cache'],
            'hidden_platforms': ['known_platforms', 'offline_cache']
        }
        
        available_fallbacks = fallbacks.get(failed_source, ['offline_cache'])
        
        for fallback_source in available_fallbacks:
            if fallback_source in self.sources:
                try:
                    logger.info(f"üîÑ Aplicando fallback: {failed_source} -> {fallback_source}")
                    
                    if asyncio.iscoroutinefunction(self.sources[fallback_source]):
                        results = await self.sources[fallback_source](query, language, level)
                    else:
                        results = await asyncio.to_thread(
                            self.sources[fallback_source], query, language, level
                        )
                    
                    if results:
                        # Reducir confianza para resultados de fallback
                        for result in results:
                            result.confianza *= 0.8
                        logger.info(f"‚úÖ Fallback exitoso: {len(results)} resultados de {fallback_source}")
                        return results
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Fallback {fallback_source} tambi√©n fall√≥: {e}")
        
        logger.warning(f"‚ùå Todos los fallbacks fallaron para {failed_source}")
        return []
    
    async def _search_google_api(self, query: str, language: str, level: str) -> list:
        """B√∫squeda en Google Custom Search API con manejo robusto de errores"""
        if not GOOGLE_API_AVAILABLE or not settings.enable_google_api:
            return []
        
        try:
            query_base = f"{query} curso gratuito certificado"
            if level not in ("Cualquiera", "Todos"):
                query_base += f" nivel {level.lower()}"
            
            params = {
                'key': api_keys['google_api_key'],
                'cx': api_keys['google_cx'],
                'q': query_base,
                'num': 5,
                'lr': f'lang_{language}'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    "https://www.googleapis.com/customsearch/v1",
                    params=params,
                    timeout=aiohttp.ClientTimeout(total=CONFIG.GOOGLE_API_TIMEOUT),
                    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
                ) as response:
                    if response.status == 429:
                        raise RateLimitExceededError(100, 100, {"service": "google_api"})
                    elif response.status != 200:
                        error_text = await response.text()
                        raise ServiceUnavailableError(
                            f"Google API error {response.status}", 
                            {"response": error_text[:500]}
                        )
                    
                    data = await response.json()
                    items = data.get('items', [])
                    
                    results = []
                    for item in items:
                        url = item.get('link', '')
                        title = item.get('title', '')
                        snippet = item.get('snippet', '')
                        
                        if self._is_valid_educational_resource(url, title, snippet):
                            result = self._create_resource_from_google_item(item, language, level, query)
                            results.append(result)
                    
                    logger.debug(f"‚úÖ Google API: {len(results)} resultados v√°lidos")
                    return results[:self.max_results_per_source]
        
        except RateLimitExceededError:
            raise
        except Exception as e:
            logger.error(f"‚ùå Error en Google API: {e}")
            raise ServiceUnavailableError("Google API", {"error": str(e)})
    
    def _search_known_platforms(self, query: str, language: str, level: str) -> list:
        """B√∫squeda en plataformas conocidas con URLs predefinidas"""
        if not settings.enable_known_platforms:
            return []
        
        try:
            platforms = {
                "es": [
                    {"name": "YouTube Educativo", "url_template": "https://www.youtube.com/results?search_query=curso+gratis+{}"},
                    {"name": "Coursera (ES)", "url_template": "https://www.coursera.org/search?query={}&languages=es&free=true"},
                    {"name": "Udemy (Gratis)", "url_template": "https://www.udemy.com/courses/search/?q={}&price=price-free&lang=es"},
                    {"name": "Khan Academy (ES)", "url_template": "https://es.khanacademy.org/search?page_search_query={}"},
                    {"name": "Domestika (Gratis)", "url_template": "https://www.domestika.org/es/search?query={}&free=1"},
                    {"name": "Aprende con Alf", "url_template": "https://aprendeconalf.es/?s={}"},
                    {"name": "Biblioteca Virtual Miguel de Cervantes", "url_template": "https://www.cervantesvirtual.com/buscar/?q={}"}
                ],
                "en": [
                    {"name": "YouTube Education", "url_template": "https://www.youtube.com/results?search_query=free+course+{}"},
                    {"name": "Khan Academy", "url_template": "https://www.khanacademy.org/search?page_search_query={}"},
                    {"name": "Coursera", "url_template": "https://www.coursera.org/search?query={}&free=true"},
                    {"name": "Udemy (Free)", "url_template": "https://www.udemy.com/courses/search/?q={}&price=price-free&lang=en"},
                    {"name": "edX", "url_template": "https://www.edx.org/search?tab=course&availability=current&price=free&q={}"},
                    {"name": "freeCodeCamp", "url_template": "https://www.freecodecamp.org/news/search/?query={}"},
                    {"name": "Kaggle Learn", "url_template": "https://www.kaggle.com/learn/search?q={}"},
                    {"name": "MIT OpenCourseWare", "url_template": "https://ocw.mit.edu/search/?q={}"},
                    {"name": "Stanford Online", "url_template": "https://online.stanford.edu/courses?search_api_views_fulltext={}"},
                    {"name": "Harvard Online Learning", "url_template": "https://online-learning.harvard.edu/catalog?search={}"}
                ],
                "pt": [
                    {"name": "YouTube BR", "url_template": "https://www.youtube.com/results?search_query=curso+gratuito+{}"},
                    {"name": "Coursera (PT)", "url_template": "https://www.coursera.org/search?query={}&languages=pt&free=true"},
                    {"name": "Udemy (PT)", "url_template": "https://www.udemy.com/courses/search/?q={}&price=price-free&lang=pt"},
                    {"name": "Khan Academy (PT)", "url_template": "https://pt.khanacademy.org/search?page_search_query={}"},
                    {"name": "Funda√ß√£o Bradesco", "url_template": "https://www.ev.org.br/cursos?search={}"}
                ]
            }
            
            selected_platforms = platforms.get(language, platforms["en"])
            results = []
            
            for platform in selected_platforms[:7]:  # L√≠mite para no sobrecargar
                url = platform["url_template"].format(quote_plus(query))
                title = f"üéØ {platform['name']} ‚Äî {query}"
                description = f"B√∫squeda directa en {platform['name']} para '{query}'"
                
                result = RecursoEducativo(
                    id=self._generate_unique_id(url),
                    titulo=title,
                    url=url,
                    descripcion=description,
                    plataforma=platform['name'],
                    idioma=language,
                    nivel=level if level != "Cualquiera" else "Intermedio",
                    categoria=self._determine_category(query),
                    certificacion=None,
                    confianza=0.85,
                    tipo="conocida",
                    ultima_verificacion=datetime.utcnow().isoformat(),
                    activo=True,
                    metadatos={
                        "fuente": "plataformas_conocidas",
                        "platform_name": platform['name'],
                        "original_query": query
                    }
                )
                results.append(result)
            
            logger.debug(f"‚úÖ Plataformas conocidas: {len(results)} resultados")
            return results
        
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda de plataformas conocidas: {e}")
            return []
    
    async def _search_hidden_platforms(self, query: str, language: str, level: str) -> list:
        """B√∫squeda en plataformas ocultas desde base de datos"""
        if not settings.enable_hidden_platforms:
            return []
        
        try:
            results = []
            current_time = datetime.utcnow()
            
            async with db_manager.get_session() as session:
                # Obtener plataformas activas
                stmt = sa.select(PlataformaOculta).where(
                    (PlataformaOculta.activa == True) &
                    (PlataformaOculta.idioma == language) &
                    (PlataformaOculta.ultima_verificacion >= current_time - timedelta(days=30))
                ).order_by(PlataformaOculta.confianza.desc()).limit(10)
                
                result = await session.execute(stmt)
                platforms = result.scalars().all()
                
                for platform in platforms:
                    # Filtrar por nivel si es necesario
                    if level not in ("Cualquiera", "Todos") and platform.nivel not in [level, "Todos", "Todos los niveles"]:
                        continue
                    
                    url = platform.url_base.format(quote_plus(query))
                    title = f"üíé {platform.nombre} ‚Äî {query}"
                    description = platform.descripcion or f"Cursos de {query} en {platform.nombre}"
                    
                    # Crear certificaci√≥n si aplica
                    certificacion = None
                    if platform.tipo_certificacion != "none":
                        paises_validos = json.loads(platform.paises_validos) if platform.paises_validos else []
                        if not isinstance(paises_validos, list):
                            paises_validos = ["global"]
                        
                        certificacion = Certificacion(
                            plataforma=platform.nombre,
                            curso=query,
                            tipo=platform.tipo_certificacion,
                            validez_internacional=platform.validez_internacional,
                            paises_validos=paises_validos,
                            costo_certificado=0.0 if platform.tipo_certificacion == "gratuito" else 49.99,
                            reputacion_academica=platform.reputacion_academica,
                            ultima_verificacion=current_time.isoformat()
                        )
                    
                    result = RecursoEducativo(
                        id=self._generate_unique_id(url),
                        titulo=title,
                        url=url,
                        descripcion=description,
                        plataforma=platform.nombre,
                        idioma=language,
                        nivel=platform.nivel if level in ("Cualquiera", "Todos") else level,
                        categoria=self._determine_category(query) or platform.categoria,
                        certificacion=certificacion,
                        confianza=float(platform.confianza),
                        tipo="oculta",
                        ultima_verificacion=current_time.isoformat(),
                        activo=True,
                        metadatos={
                            "fuente": "plataformas_ocultas",
                            "platform_id": platform.id,
                            "confidence_db": platform.confianza,
                            "audit_trail": f"Buscado el {current_time.isoformat()}"
                        }
                    )
                    results.append(result)
            
            logger.debug(f"‚úÖ Plataformas ocultas: {len(results)} resultados")
            return results[:self.max_results_per_source]
        
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda de plataformas ocultas: {e}")
            raise ServiceUnavailableError("Base de datos", {"error": str(e)})
    
    async def _search_duckduckgo(self, query: str, language: str, level: str) -> list:
        """B√∫squeda en DuckDuckGo como fallback"""
        if not settings.enable_ddg_fallback:
            return []
        
        try:
            search_query = f"{query} free course"
            if level not in ("Cualquiera", "Todos"):
                search_query += f" {level.lower()}"
            
            url = f"https://duckduckgo.com/html?q={quote_plus(search_query)}"
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    url,
                    headers={
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                        'Accept-Language': f'{language}-{language.upper()},{language};q=0.5',
                    },
                    timeout=aiohttp.ClientTimeout(total=15)
                ) as response:
                    if response.status != 200:
                        return []
                    
                    html = await response.text()
                    # Extraer resultados b√°sicos
                    results = []
                    
                    # Este es un parsing muy b√°sico - en producci√≥n usar√≠a BeautifulSoup o similar
                    links = re.findall(r'<a class="result__a" href="([^"]+)"[^>]*>([^<]+)</a>', html)
                    descriptions = re.findall(r'<div class="result__snippet">([^<]+)</div>', html)
                    
                    for i, (link, title) in enumerate(links[:5]):
                        description = descriptions[i] if i < len(descriptions) else f"Resultado de DuckDuckGo para {query}"
                        
                        if self._is_valid_educational_resource(link, title, description):
                            result = RecursoEducativo(
                                id=self._generate_unique_id(link),
                                titulo=f"ü¶Ü DuckDuckGo ‚Äî {title[:60]}...",
                                url=link,
                                descripcion=description[:200] + "...",
                                plataforma="DuckDuckGo",
                                idioma=language,
                                nivel=level if level != "Cualquiera" else "Intermedio",
                                categoria=self._determine_category(query),
                                certificacion=None,
                                confianza=0.65,
                                tipo="fallback",
                                ultima_verificacion=datetime.utcnow().isoformat(),
                                activo=True,
                                metadatos={
                                    "fuente": "duckduckgo",
                                    "original_query": query,
                                    "search_url": url
                                }
                            )
                            results.append(result)
                    
                    logger.debug(f"‚úÖ DuckDuckGo: {len(results)} resultados")
                    return results
        
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda DuckDuckGo: {e}")
            return []
    
    def _search_offline_cache(self, query: str, language: str, level: str) -> list:
        """B√∫squeda en cach√© offline cuando otros servicios no est√°n disponibles"""
        if not settings.enable_offline_cache:
            return []
        
        try:
            cache_key = f"offline_search:{query}:{language}:{level}"
            cached_results = cache_manager.get(cache_key)
            
            if cached_results:
                logger.info(f"‚úÖ Usando resultados en cach√© para: {query}")
                # Convertir resultados serializados a objetos
                results = []
                for item in cached_results:
                    result = RecursoEducativo(**item)
                    result.confianza *= 0.9  # Reducir confianza para resultados en cach√©
                    results.append(result)
                return results
            
            # Si no hay cach√©, usar datos hist√≥ricos de la base de datos
            return self._search_historical_data(query, language, level)
        
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda offline: {e}")
            return []
    
    def _search_historical_data(self, query: str, language: str, level: str) -> list:
        """B√∫squeda en datos hist√≥ricos de la base de datos"""
        try:
            # Esta funci√≥n se implementar√≠a con SQLAlchemy para buscar resultados hist√≥ricos
            # Por ahora devuelve resultados simulados
            simulated_results = [
                {
                    "id": f"hist_{i}",
                    "titulo": f"üìö Curso Hist√≥rico: {query} - Nivel {level}",
                    "url": f"https://example.com/historical/course/{i}",
                    "descripcion": f"Este curso fue encontrado en nuestros datos hist√≥ricos. Puede no estar actualizado.",
                    "plataforma": "Historical Data",
                    "idioma": language,
                    "nivel": level,
                    "categoria": self._determine_category(query),
                    "certificacion": None,
                    "confianza": 0.6,
                    "tipo": "historico",
                    "ultima_verificacion": (datetime.utcnow() - timedelta(days=30)).isoformat(),
                    "activo": True,
                    "metadatos": {
                        "fuente": "historical_data",
                        "original_query": query,
                        "data_age_days": 30
                    }
                } for i in range(3)
            ]
            
            return [RecursoEducativo(**item) for item in simulated_results]
        
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda de datos hist√≥ricos: {e}")
            return []
    
    def _process_results(self, results: list, query: str, language: str, level: str) -> list:
        """Procesa y ordena los resultados finales"""
        if not results:
            return []
        
        # 1. Eliminar duplicados
        unique_results = self._remove_duplicates(results)
        
        # 2. Calcular puntuaci√≥n final
        for result in unique_results:
            result.puntuacion_final = self._calculate_final_score(result, query, language, level)
        
        # 3. Ordenar por puntuaci√≥n
        unique_results.sort(key=lambda x: x.puntuacion_final, reverse=True)
        
        # 4. Limitar resultados
        max_results = settings.max_results
        final_results = unique_results[:max_results]
        
        # 5. Guardar en cach√© offline
        if settings.enable_offline_cache:
            cache_key = f"offline_search:{query}:{language}:{level}"
            cache_manager.set(cache_key, [asdict(r) for r in final_results], ttl=86400)  # 24 horas
        
        logger.info(f"üìä Resultados procesados: {len(unique_results)} √∫nicos, {len(final_results)} mostrados")
        return final_results
    
    def _remove_duplicates(self, results: list) -> list:
        """Elimina resultados duplicados basados en URLs normalizadas"""
        seen_urls = set()
        unique_results = []
        
        for result in results:
            # Normalizar URL
            normalized_url = self._normalize_url(result.url)
            
            if normalized_url not in seen_urls:
                seen_urls.add(normalized_url)
                unique_results.append(result)
        
        logger.debug(f"üßπ Eliminados {len(results) - len(unique_results)} duplicados")
        return unique_results
    
    def _normalize_url(self, url: str) -> str:
        """Normaliza URLs para comparaci√≥n"""
        parsed = urlparse(url.lower())
        # Eliminar par√°metros de tracking comunes
        query_params = parse_qs(parsed.query)
        clean_params = {k: v for k, v in query_params.items() if k not in ['utm_source', 'utm_medium', 'utm_campaign', 'ref']}
        clean_query = urlencode(clean_params, doseq=True)
        
        return f"{parsed.scheme}://{parsed.netloc}{parsed.path}?{clean_query}" if clean_query else f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
    
    def _calculate_final_score(self, result: RecursoEducativo, query: str, language: str, level: str) -> float:
        """Calcula puntuaci√≥n final basada en m√∫ltiples factores"""
        base_score = result.confianza
        
        # Factores de relevancia
        relevance_factors = []
        
        # 1. Relevancia del t√≠tulo
        title_lower = result.titulo.lower()
        query_lower = query.lower()
        if query_lower in title_lower:
            relevance_factors.append(1.2)
        elif any(word in title_lower for word in query_lower.split()):
            relevance_factors.append(1.1)
        
        # 2. Idioma exacto
        if result.idioma == language:
            relevance_factors.append(1.15)
        
        # 3. Nivel adecuado
        if level not in ("Cualquiera", "Todos") and result.nivel == level:
            relevance_factors.append(1.1)
        
        # 4. Recursos con certificaci√≥n
        if result.certificacion:
            cert_bonus = 1.05
            if result.certificacion.tipo == "gratuito":
                cert_bonus = 1.1
            relevance_factors.append(cert_bonus)
        
        # 5. Plataformas de alta reputaci√≥n
        high_reputation_platforms = ["Coursera", "edX", "Khan Academy", "MIT OpenCourseWare", "Stanford Online", "Harvard Online Learning"]
        if any(platform.lower() in result.plataforma.lower() for platform in high_reputation_platforms):
            relevance_factors.append(1.08)
        
        # Calcular puntuaci√≥n final
        relevance_multiplier = math.prod(relevance_factors) if relevance_factors else 1.0
        final_score = base_score * relevance_multiplier
        
        # Asegurar que est√© entre 0 y 1
        return max(0.0, min(1.0, final_score))
    
    def _is_valid_educational_resource(self, url: str, title: str, description: str) -> bool:
        """Valida si un recurso es educativo v√°lido"""
        text = f"{url} {title} {description}".lower()
        
        # Palabras clave que indican contenido educativo
        educational_keywords = [
            'curso', 'tutorial', 'aprender', 'learn', 'gratis', 'free', 'class', 
            'education', 'educaci√≥n', 'certificado', 'certificate', 'training',
            'leccion', 'lesson', 'guia', 'guide', 'academia', 'university',
            'college', 'institute', 'school', 'escuela', 'formacion', 'mooc'
        ]
        
        # Palabras clave que indican contenido no educativo o comercial
        non_educational_keywords = [
            'comprar', 'buy', 'precio', 'price', 'premium', 'paid', 'only', 
            'exclusive', 'suscripci√≥n', 'subscription', 'membership', 'register now',
            'matr√≠cula', 'enrollment', 'fee', 'cost', 'discount', 'sale', 'offer'
        ]
        
        # Dominios educativos de confianza
        trusted_domains = [
            '.edu', '.ac.', '.edu.', '.gob', '.gov', '.org', 'coursera', 'edx', 
            'khanacademy', 'udemy', 'youtube', 'freecodecamp', 'mit', 'stanford',
            'harvard', 'oxford', 'cambridge', 'university', 'college', 'institute'
        ]
        
        # Verificar si contiene palabras educativas
        has_educational = any(keyword in text for keyword in educational_keywords)
        
        # Verificar si contiene palabras no educativas
        has_non_educational = any(keyword in text for keyword in non_educational_keywords)
        
        # Verificar dominios de confianza
        has_trusted_domain = any(domain in url.lower() for domain in trusted_domains)
        
        # L√≥gica de decisi√≥n
        if has_trusted_domain:
            return True
        if has_educational and not has_non_educational:
            return True
        if has_educational and has_non_educational:
            # Si tiene ambas, dar preferencia a las educativas si son m√°s frecuentes
            edu_count = sum(1 for k in educational_keywords if k in text)
            non_edu_count = sum(1 for k in non_educational_keywords if k in text)
            return edu_count > non_edu_count
        
        return False
    
    def _create_resource_from_google_item(self, item: dict, language: str, level: str, query: str) -> RecursoEducativo:
        """Crea un RecursoEducativo desde un item de Google API"""
        url = item.get('link', '')
        title = item.get('title', '')
        snippet = item.get('snippet', '')
        html_snippet = item.get('htmlSnippet', '')
        
        # Extraer plataforma
        platform = self._extract_platform(url)
        
        # Determinar nivel
        detected_level = self._determine_level(title + " " + snippet, level)
        
        # Crear certificaci√≥n (simulada para Google API)
        certificacion = None
        if any(word in (title + snippet).lower() for word in ['certificado', 'certificate', 'diploma']):
            certificacion = Certificacion(
                plataforma=platform,
                curso=query,
                tipo="audit" if "audit" in (title + snippet).lower() else "gratuito",
                validez_internacional=True,
                paises_validos=["global"],
                costo_certificado=0.0 if "gratuito" in (title + snippet).lower() else 49.99,
                reputacion_academica=0.8 if platform in ["Coursera", "edX", "Khan Academy"] else 0.7,
                ultima_verificacion=datetime.utcnow().isoformat()
            )
        
        return RecursoEducativo(
            id=self._generate_unique_id(url),
            titulo=title,
            url=url,
            descripcion=self._clean_html(snippet + " " + html_snippet),
            plataforma=platform,
            idioma=language,
            nivel=detected_level,
            categoria=self._determine_category(query),
            certificacion=certificacion,
            confianza=0.85,
            tipo="verificada",
            ultima_verificacion=datetime.utcnow().isoformat(),
            activo=True,
            metadatos={
                "fuente": "google_api",
                "google_item": {
                    "title": title,
                    "link": url,
                    "snippet": snippet,
                    "html_snippet": html_snippet
                },
                "original_query": query
            }
        )
    
    def _extract_platform(self, url: str) -> str:
        """Extrae el nombre de la plataforma desde la URL"""
        try:
            domain = urlparse(url).netloc.lower()
            platform_mapping = {
                'youtube': 'YouTube',
                'coursera': 'Coursera',
                'edx': 'edX',
                'udemy': 'Udemy',
                'khanacademy': 'Khan Academy',
                'freecodecamp': 'freeCodeCamp',
                'mit.edu': 'MIT OpenCourseWare',
                'stanford.edu': 'Stanford Online',
                'harvard.edu': 'Harvard Online Learning',
                'aprendeconalf': 'Aprende con Alf',
                'domestika': 'Domestika',
                'cervantesvirtual': 'Biblioteca Virtual Miguel de Cervantes'
            }
            
            for keyword, platform_name in platform_mapping.items():
                if keyword in domain:
                    return platform_name
            
            # Extraer nombre del dominio si no se encuentra en el mapping
            parts = domain.split('.')
            return parts[-2].title() if len(parts) >= 2 else domain.title()
        
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo plataforma de {url}: {e}")
            return "Web"
    
    def _determine_level(self, text: str, requested_level: str) -> str:
        """Determina el nivel educativo basado en el texto"""
        if requested_level not in ("Cualquiera", "Todos"):
            return requested_level
        
        text_lower = text.lower()
        
        if any(word in text_lower for word in ['principiante', 'b√°sico', 'comenzar', 'desde cero', 'introducci√≥n', 'beginner', 'basic', 'start from zero', 'intro']):
            return "Principiante"
        
        if any(word in text_lower for word in ['avanzado', 'experto', 'maestr√≠a', 'profesional', 'avanzado', 'advanced', 'expert', 'master', 'professional']):
            return "Avanzado"
        
        return "Intermedio"
    
    def _determine_category(self, query: str) -> str:
        """Determina la categor√≠a del curso basado en la consulta"""
        query_lower = query.lower()
        
        programming_keywords = ['python', 'java', 'javascript', 'web', 'code', 'programaci√≥n', 'desarrollo', 'coding', 'programming', 'web development', 'mobile development']
        data_science_keywords = ['data', 'datos', 'ia', 'ai', 'machine learning', 'deep learning', 'neural networks', 'ciencia de datos', 'data science', 'analytics', 'statistics']
        design_keywords = ['design', 'dise√±o', 'ux', 'ui', 'graphic design', 'web design', 'dise√±o gr√°fico', 'illustrator', 'photoshop']
        business_keywords = ['marketing', 'negocios', 'business', 'finanzas', 'econom√≠a', 'finance', 'economy', 'management', 'emprendimiento', 'entrepreneurship']
        languages_keywords = ['idiomas', 'languages', 'ingl√©s', 'espa√±ol', 'franc√©s', 'alem√°n', 'italiano', 'portugu√©s', 'english', 'spanish', 'french', 'german', 'italian', 'portuguese']
        
        if any(keyword in query_lower for keyword in programming_keywords):
            return "Programaci√≥n"
        if any(keyword in query_lower for keyword in data_science_keywords):
            return "Data Science"
        if any(keyword in query_lower for keyword in design_keywords):
            return "Dise√±o"
        if any(keyword in query_lower for keyword in business_keywords):
            return "Negocios"
        if any(keyword in query_lower for keyword in languages_keywords):
            return "Idiomas"
        
        return "General"
    
    def _generate_unique_id(self, url: str) -> str:
        """Genera un ID √∫nico para un recurso"""
        return hashlib.md5(url.encode()).hexdigest()[:12]
    
    def _clean_html(self, text: str) -> str:
        """Limpia HTML de un texto"""
        if not text:
            return ""
        
        # Eliminar etiquetas HTML
        text = re.sub(r'<[^>]+>', '', text)
        
        # Decodificar entidades HTML
        text = re.sub(r'&nbsp;', ' ', text)
        text = re.sub(r'&amp;', '&', text)
        text = re.sub(r'&lt;', '<', text)
        text = re.sub(r'&gt;', '>', text)
        
        # Limpiar espacios m√∫ltiples
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text

# Inicializar motor de b√∫squeda
search_engine = SearchEngine()

# ============================================================
# 8. SISTEMA DE AN√ÅLISIS CON IA AVANZADO - Groq + Fallbacks
# ============================================================

class AIAnalyzer:
    """Analizador avanzado con IA para evaluar recursos educativos"""
    
    def __init__(self):
        self.groq_available = GROQ_AVAILABLE
        self.groq_client = GROQ_CLIENT
        self.groq_model = settings.groq_model
        self.analysis_timeout = 30
        self.max_retries = 3
        self.fallback_strategies = ["keyword_analysis", "historical_data", "user_feedback"]
        
        # Plantillas de prompts mejoradas
        self.PROMPTS = {
            'resource_analysis': """
            Analiza este recurso educativo y proporciona una evaluaci√≥n detallada en formato JSON.
            
            T√çTULO: {titulo}
            DESCRIPCI√ìN: {descripcion}
            PLATAFORMA: {plataforma}
            NIVEL: {nivel}
            CATEGOR√çA: {categoria}
            URL: {url}
            
            Eval√∫a los siguientes aspectos:
            1. Calidad educativa (0.0-1.0)
            2. Relevancia para el usuario (0.0-1.0) 
            3. Dificultad real vs nivel declarado
            4. Reputaci√≥n de la plataforma
            5. Valor del certificado (si aplica)
            6. Tiempo estimado de aprendizaje
            7. Prerrequisitos recomendados
            8. Fortalezas principales
            9. √Åreas de mejora
            10. Recomendaci√≥n personalizada
            
            Proporciona el resultado SOLO en formato JSON con esta estructura:
            {{
                "calidad_educativa": 0.85,
                "relevancia_usuario": 0.90,
                "dificultad_real": "Intermedio",
                "reputacion_plataforma": 0.92,
                "valor_certificado": 0.88,
                "tiempo_estimado_horas": 40,
                "prerrequisitos": ["Conocimientos b√°sicos de programaci√≥n"],
                "fortalezas": ["Contenido pr√°ctico", "Buen soporte"],
                "areas_mejora": ["M√°s ejercicios"], 
                "recomendacion_personalizada": "Excelente curso para aprender {tema}.",
                "confianza_analisis": 0.95,
                "fecha_analisis": "{fecha_actual}"
            }}
            """,
            
            'chat_response': """
            Eres un asistente educativo experto llamado EduBot. Tu rol es ayudar a los usuarios a encontrar y evaluar recursos educativos de alta calidad.
            
            Contexto actual:
            - Usuario: {user_profile}
            - Tema de inter√©s: {topic}
            - Nivel: {level}
            - Idioma preferido: {language}
            
            Historial de la conversaci√≥n:
            {conversation_history}
            
            Pregunta del usuario: {user_question}
            
            Proporciona una respuesta √∫til, clara y concisa que:
            1. Responda directamente la pregunta
            2. Ofrezca recursos relevantes si aplica
            3. Sea educativa y motivadora
            4. Use un tono amigable pero profesional
            5. Incluya consejos pr√°cticos si es relevante
            6. No uses formato JSON en tu respuesta
            7. Mant√©n la respuesta en {language}
            
            Si no tienes suficiente informaci√≥n, pide clarificaci√≥n amablemente.
            """
        }
        
        logger.info(f"‚úÖ AIAnalyzer inicializado - Groq disponible: {self.groq_available}")
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    @cached_result(ttl_seconds=86400, prefix="ai_analysis")  # 24 horas
    async def analyze_resource(self, resource: RecursoEducativo, user_profile: dict = None) -> dict:
        """Analiza un recurso educativo usando IA con fallbacks robustos"""
        if not settings.enable_groq_analysis or not self.groq_available:
            logger.info("‚è≠Ô∏è An√°lisis IA deshabilitado o no disponible, usando an√°lisis por keywords")
            return self._fallback_analysis(resource)
        
        try:
            logger.debug(f"üß† Iniciando an√°lisis IA para: {resource.titulo[:50]}...")
            
            # Preparar prompt
            prompt = self.PROMPTS['resource_analysis'].format(
                titulo=resource.titulo,
                descripcion=resource.descripcion[:500],
                plataforma=resource.plataforma,
                nivel=resource.nivel,
                categoria=resource.categoria,
                url=resource.url,
                tema=resource.categoria.lower(),
                fecha_actual=datetime.utcnow().isoformat()
            )
            
            # Ejecutar an√°lisis con timeout
            result = await asyncio.wait_for(
                self._execute_groq_analysis(prompt, resource),
                timeout=self.analysis_timeout
            )
            
            logger.debug(f"‚úÖ An√°lisis IA completado para: {resource.titulo[:50]}")
            return result
        
        except asyncio.TimeoutError:
            logger.warning(f"‚ö†Ô∏è Timeout en an√°lisis IA para: {resource.titulo[:50]}")
            return await self._apply_fallback_strategy('timeout', resource, user_profile)
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis IA: {e}")
            return await self._apply_fallback_strategy('error', resource, user_profile, str(e))
    
    async def _execute_groq_analysis(self, prompt: str, resource: RecursoEducativo) -> dict:
        """Ejecuta el an√°lisis con Groq API"""
        try:
            response = await asyncio.to_thread(
                self.groq_client.chat.completions.create,
                messages=[{"role": "user", "content": prompt}],
                model=self.groq_model,
                temperature=0.3,
                max_tokens=1000,
                timeout=25
            )
            
            content = response.choices[0].message.content.strip()
            
            # Extraer JSON del contenido
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                try:
                    analysis = json.loads(json_str)
                    # Validar estructura m√≠nima
                    required_fields = ['calidad_educativa', 'relevancia_usuario', 'recomendacion_personalizada']
                    if all(field in analysis for field in required_fields):
                        return analysis
                except json.JSONDecodeError as e:
                    logger.error(f"‚ùå Error decodificando JSON de an√°lisis: {e}")
            
            # Si no se puede extraer JSON v√°lido, usar contenido como fallback
            logger.warning("‚ö†Ô∏è No se pudo extraer JSON v√°lido del an√°lisis, usando an√°lisis b√°sico")
            return self._basic_analysis_from_content(content, resource)
        
        except Exception as e:
            logger.error(f"‚ùå Error ejecutando an√°lisis Groq: {e}")
            raise
    
    async def _apply_fallback_strategy(self, failure_type: str, resource: RecursoEducativo, 
                                      user_profile: dict = None, error_details: str = None) -> dict:
        """Aplica estrategias de fallback cuando el an√°lisis IA falla"""
        for strategy in self.fallback_strategies:
            try:
                logger.info(f"üîÑ Aplicando estrategia de fallback para an√°lisis: {strategy}")
                
                if strategy == "keyword_analysis":
                    return self._keyword_based_analysis(resource)
                elif strategy == "historical_data":
                    return await self._historical_data_analysis(resource)
                elif strategy == "user_feedback":
                    return await self._user_feedback_analysis(resource)
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Estrategia {strategy} fall√≥: {e}")
                continue
        
        # Si todas las estrategias fallan, usar an√°lisis b√°sico
        logger.error(f"‚ùå Todas las estrategias de fallback fallaron para {resource.titulo}")
        return self._fallback_analysis(resource, error_details)
    
    def _keyword_based_analysis(self, resource: RecursoEducativo) -> dict:
        """An√°lisis basado en keywords y reglas heur√≠sticas"""
        text = f"{resource.titulo} {resource.descripcion}".lower()
        
        # Calcular calidad educativa basada en keywords
        quality_keywords = {
            'excelente': ['completo', 'detallado', 'profundo', 'pr√°ctico', 'ejercicios', 'proyectos', 'certificado', 'universidad', 'experto'],
            'bueno': ['b√°sico', 'introductorio', 'te√≥rico', 'conceptos', 'fundamentos', 'principios'],
            'mejorable': ['breve', 'superficial', 'limitado', 'desactualizado', 'poco contenido']
        }
        
        calidad_score = 0.7  # Score base
        for quality, keywords in quality_keywords.items():
            if any(keyword in text for keyword in keywords):
                if quality == 'excelente':
                    calidad_score = 0.9
                elif quality == 'bueno':
                    calidad_score = 0.75
                elif quality == 'mejorable':
                    calidad_score = 0.6
                break
        
        # Calcular relevancia basada en coincidencias
        relevancia_score = 0.8
        if resource.categoria.lower() in text:
            relevancia_score += 0.1
        if resource.nivel.lower() in text:
            relevancia_score += 0.05
        
        # Determinar dificultad real
        difficulty_keywords = {
            'principiante': ['b√°sico', 'introductorio', 'desde cero', 'principios', 'fundamentos'],
            'intermedio': ['intermedio', 'pr√°ctico', 'aplicado', 'proyectos', 'ejercicios'],
            'avanzado': ['avanzado', 'experto', 'profundo', 'complejo', 'maestr√≠a']
        }
        
        dificultad_real = resource.nivel
        for level, keywords in difficulty_keywords.items():
            if any(keyword in text for keyword in keywords):
                dificultad_real = level.title()
                break
        
        # Recomendaci√≥n personalizada
        recomendacion = f"Curso {resource.nivel.lower()} de {resource.categoria.lower()}"
        if 'certificado' in text or 'certificate' in text:
            recomendacion += " con certificado v√°lido"
        if 'pr√°ctico' in text or 'proyecto' in text or 'proyectos' in text:
            recomendacion += " con enfoque pr√°ctico"
        
        return {
            "calidad_educativa": round(calidad_score, 2),
            "relevancia_usuario": round(relevancia_score, 2),
            "dificultad_real": dificultad_real,
            "reputacion_plataforma": self._get_platform_reputation(resource.plataforma),
            "valor_certificado": 0.8 if resource.certificacion else 0.5,
            "tiempo_estimado_horas": self._estimate_learning_time(resource),
            "prerrequisitos": self._determine_prerequisites(resource),
            "fortalezas": self._identify_strengths(resource),
            "areas_mejora": self._identify_weaknesses(resource),
            "recomendacion_personalizada": recomendacion,
            "confianza_analisis": 0.7,
            "fecha_analisis": datetime.utcnow().isoformat(),
            "metodo_analisis": "keyword_based"
        }
    
    async def _historical_data_analysis(self, resource: RecursoEducativo) -> dict:
        """An√°lisis basado en datos hist√≥ricos de recursos similares"""
        try:
            # Buscar recursos similares en cach√© o base de datos
            cache_key = f"historical_analysis:{resource.categoria}:{resource.nivel}:{resource.plataforma}"
            cached_analysis = cache_manager.get(cache_key)
            
            if cached_analysis:
                logger.debug("‚úÖ Usando an√°lisis hist√≥rico desde cach√©")
                # Ajustar scores ligeramente para este recurso espec√≠fico
                adjusted_analysis = cached_analysis.copy()
                adjusted_analysis['confianza_analisis'] *= 0.9  # Reducir confianza
                adjusted_analysis['fecha_analisis'] = datetime.utcnow().isoformat()
                return adjusted_analysis
            
            # Simular an√°lisis hist√≥rico (en producci√≥n usar√≠a datos reales de la BD)
            historical_data = {
                "calidad_educativa": 0.82 if "Coursera" in resource.plataforma else 0.75,
                "relevancia_usuario": 0.88,
                "dificultad_real": resource.nivel,
                "reputacion_plataforma": self._get_platform_reputation(resource.plataforma),
                "valor_certificado": 0.85 if resource.certificacion else 0.6,
                "tiempo_estimado_horas": 35,
                "prerrequisitos": ["Conocimientos b√°sicos"],
                "fortalezas": ["Buena estructura", "Material de calidad"],
                "areas_mejora": ["M√°s ejemplos pr√°cticos"],
                "recomendacion_personalizada": f"Basado en an√°lisis hist√≥ricos, este curso de {resource.categoria} en {resource.plataforma} es recomendado para nivel {resource.nivel}.",
                "confianza_analisis": 0.75,
                "fecha_analisis": datetime.utcnow().isoformat(),
                "metodo_analisis": "historical_data"
            }
            
            cache_manager.set(cache_key, historical_data, ttl=43200)  # 12 horas
            return historical_data
        
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis hist√≥rico: {e}")
            raise
    
    def _get_platform_reputation(self, platform_name: str) -> float:
        """Obtiene la reputaci√≥n de una plataforma educativa"""
        reputation_map = {
            "Coursera": 0.95,
            "edX": 0.94,
            "Khan Academy": 0.93,
            "MIT OpenCourseWare": 0.96,
            "Stanford Online": 0.95,
            "Harvard Online Learning": 0.95,
            "freeCodeCamp": 0.92,
            "Udemy": 0.85,
            "YouTube": 0.75,
            "Domestika": 0.88,
            "Aprende con Alf": 0.87,
            "Biblioteca Virtual Miguel de Cervantes": 0.90
        }
        
        platform_clean = platform_name.lower().strip()
        for name, score in reputation_map.items():
            if name.lower() in platform_clean:
                return score
        
        return 0.8  # Score default para plataformas desconocidas
    
    def _estimate_learning_time(self, resource: RecursoEducativo) -> int:
        """Estima el tiempo de aprendizaje en horas"""
        base_hours = {
            "Principiante": 15,
            "Intermedio": 30,
            "Avanzado": 45
        }
        
        category_multiplier = {
            "Programaci√≥n": 1.2,
            "Data Science": 1.3,
            "Dise√±o": 1.0,
            "Negocios": 0.9,
            "Idiomas": 1.5,
            "General": 1.0
        }
        
        base = base_hours.get(resource.nivel, 30)
        multiplier = category_multiplier.get(resource.categoria, 1.0)
        
        # Ajustar por palabras en la descripci√≥n
        description_length = len(resource.descripcion.split())
        if description_length > 200:
            base += 10
        elif description_length < 50:
            base -= 5
        
        return max(5, int(base * multiplier))
    
    def _determine_prerequisites(self, resource: RecursoEducativo) -> list:
        """Determina los prerrequisitos basados en el nivel y categor√≠a"""
        level_prereqs = {
            "Principiante": [],
            "Intermedio": {
                "Programaci√≥n": ["Conocimientos b√°sicos de programaci√≥n"],
                "Data Science": ["Estad√≠stica b√°sica, Python"],
                "Dise√±o": ["Conceptos b√°sicos de dise√±o"],
                "Negocios": ["Conceptos b√°sicos de negocios"],
                "Idiomas": ["Nivel A1 del idioma"],
                "General": ["Educaci√≥n secundaria"]
            },
            "Avanzado": {
                "Programaci√≥n": ["Programaci√≥n intermedia, algoritmos"],
                "Data Science": ["Estad√≠stica avanzada, machine learning b√°sico"],
                "Dise√±o": ["Dise√±o intermedio, herramientas profesionales"],
                "Negocios": ["Experiencia en negocios"],
                "Idiomas": ["Nivel B1 del idioma"],
                "General": ["Educaci√≥n universitaria"]
            }
        }
        
        if resource.nivel == "Principiante":
            return level_prereqs["Principiante"]
        
        category_prereqs = level_prereqs[resource.nivel].get(resource.categoria, ["Conocimientos previos en el tema"])
        return category_prereqs
    
    def _identify_strengths(self, resource: RecursoEducativo) -> list:
        """Identifica fortalezas basadas en el contenido"""
        text = f"{resource.titulo} {resource.descripcion}".lower()
        strengths = []
        
        if any(word in text for word in ['pr√°ctico', 'proyectos', 'ejercicios', 'hands-on', 'pr√°ctica']):
            strengths.append("Enfoque pr√°ctico con ejercicios")
        if any(word in text for word in ['certificado', 'diploma', 'credential', 'credencial']):
            strengths.append("Certificaci√≥n reconocida")
        if any(word in text for word in ['experto', 'profesor', 'instructor', 'mentor']):
            strengths.append("Instructores expertos")
        if any(word in text for word in ['actualizado', 'reciente', '2024', '2025']):
            strengths.append("Contenido actualizado")
        if any(word in text for word in ['comunidad', 'foro', 'soporte', 'ayuda']):
            strengths.append("Buena comunidad y soporte")
        
        return strengths or ["Contenido educativo s√≥lido"]
    
    def _identify_weaknesses(self, resource: RecursoEducativo) -> list:
        """Identifica √°reas de mejora basadas en el contenido"""
        text = f"{resource.titulo} {resource.descripcion}".lower()
        weaknesses = []
        
        if any(word in text for word in ['te√≥rico', 'solo teor√≠a', 'poca pr√°ctica']):
            weaknesses.append("Poco contenido pr√°ctico")
        if any(word in text for word in ['b√°sico', 'simple', 'introductorio']) and resource.nivel == "Avanzado":
            weaknesses.append("Podr√≠a ser muy b√°sico para el nivel declarado")
        if any(word in text for word in ['desactualizado', 'viejo', 'antiguo']):
            weaknesses.append("Contenido posiblemente desactualizado")
        if 'certificado' not in text and resource.certificacion:
            weaknesses.append("Informaci√≥n limitada sobre el certificado")
        
        return weaknesses or ["Sin √°reas de mejora significativas identificadas"]
    
    def _fallback_analysis(self, resource: RecursoEducativo, error_details: str = None) -> dict:
        """An√°lisis de fallback b√°sico cuando todo lo dem√°s falla"""
        logger.warning(f"‚ö†Ô∏è Usando an√°lisis de fallback b√°sico para: {resource.titulo}")
        
        return {
            "calidad_educativa": resource.confianza,
            "relevancia_usuario": resource.confianza,
            "dificultad_real": resource.nivel,
            "reputacion_plataforma": self._get_platform_reputation(resource.plataforma),
            "valor_certificado": 0.7 if resource.certificacion else 0.3,
            "tiempo_estimado_horas": 25,
            "prerrequisitos": ["Seg√∫n nivel del curso"],
            "fortalezas": ["Recurso educativo verificado"],
            "areas_mejora": ["An√°lisis detallado no disponible"],
            "recomendacion_personalizada": f"Curso de {resource.categoria} para nivel {resource.nivel}. An√°lisis detallado no disponible temporalmente.",
            "confianza_analisis": 0.5,
            "fecha_analisis": datetime.utcnow().isoformat(),
            "metodo_analisis": "fallback_basic",
            "error_details": error_details[:200] if error_details else None
        }
    
    def _basic_analysis_from_content(self, content: str, resource: RecursoEducativo) -> dict:
        """Extrae an√°lisis b√°sico de contenido de texto sin JSON"""
        try:
            # Extraer fragmentos clave del contenido
            lines = [line.strip() for line in content.split('\n') if line.strip()]
            
            # Buscar calificaciones
            calidad_match = re.search(r'calidad\s*[:=]\s*([\d.]+)', content.lower())
            relevancia_match = re.search(r'relevancia\s*[:=]\s*([\d.]+)', content.lower())
            
            return {
                "calidad_educativa": float(calidad_match.group(1)) if calidad_match else resource.confianza,
                "relevancia_usuario": float(relevancia_match.group(1)) if relevancia_match else resource.confianza,
                "dificultad_real": resource.nivel,
                "reputacion_plataforma": self._get_platform_reputation(resource.plataforma),
                "valor_certificado": 0.7 if resource.certificacion else 0.4,
                "tiempo_estimado_horas": 30,
                "prerrequisitos": ["Seg√∫n descripci√≥n del curso"],
                "fortalezas": ["An√°lisis parcial disponible"],
                "areas_mejora": ["An√°lisis completo no disponible"],
                "recomendacion_personalizada": self._extract_recommendation(content, resource),
                "confianza_analisis": 0.6,
                "fecha_analisis": datetime.utcnow().isoformat(),
                "metodo_analisis": "content_extraction"
            }
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis b√°sico de contenido: {e}")
            return self._fallback_analysis(resource, str(e))
    
    def _extract_recommendation(self, content: str, resource: RecursoEducativo) -> str:
        """Extrae una recomendaci√≥n del contenido de texto"""
        # Buscar frases de recomendaci√≥n
        recommendation_phrases = [
            'recomendado para', 'ideal para', 'perfecto para', 'sugerido para',
            'excelente para', 'bueno para', 'recomiendo', 'sugiero'
        ]
        
        content_lower = content.lower()
        for phrase in recommendation_phrases:
            if phrase in content_lower:
                start_idx = content_lower.find(phrase)
                end_idx = content_lower.find('.', start_idx + 20)
                if end_idx == -1:
                    end_idx = min(start_idx + 100, len(content))
                return content[start_idx:end_idx].strip()
        
        return f"Curso recomendado de {resource.categoria.lower()} para nivel {resource.nivel.lower()}"
    
    async def chat_response(self, messages: list, user_profile: dict = None) -> str:
        """Genera una respuesta de chat usando IA con fallbacks"""
        if not settings.enable_chat_ia or not self.groq_available:
            logger.info("‚è≠Ô∏è Chat IA deshabilitado o no disponible")
            return self._fallback_chat_response(messages, user_profile)
        
        try:
            # Preparar contexto del usuario
            user_context = user_profile or {}
            topic = user_context.get('last_search_topic', 'educaci√≥n')
            level = user_context.get('preferred_level', 'Intermedio')
            language = user_context.get('language', 'espanol')
            
            # Construir historial de conversaci√≥n
            conversation_history = ""
            for msg in messages[-5:]:  # √öltimos 5 mensajes
                role = "Usuario" if msg['role'] == 'user' else "Asistente"
                conversation_history += f"{role}: {msg['content']}\n"
            
            # √öltima pregunta del usuario
            user_question = messages[-1]['content'] if messages else ""
            
            # Generar prompt
            prompt = self.PROMPTS['chat_response'].format(
                user_profile=json.dumps(user_context, ensure_ascii=False),
                topic=topic,
                level=level,
                language=language,
                conversation_history=conversation_history,
                user_question=user_question
            )
            
            # Ejecutar con timeout
            return await asyncio.wait_for(
                self._execute_chat_response(prompt),
                timeout=20
            )
        
        except asyncio.TimeoutError:
            logger.warning("‚ö†Ô∏è Timeout en respuesta de chat IA")
            return self._fallback_chat_response(messages, user_profile, "timeout")
        except Exception as e:
            logger.error(f"‚ùå Error en respuesta de chat IA: {e}")
            return self._fallback_chat_response(messages, user_profile, str(e))
    
    async def _execute_chat_response(self, prompt: str) -> str:
        """Ejecuta la respuesta de chat con Groq"""
        try:
            response = await asyncio.to_thread(
                self.groq_client.chat.completions.create,
                messages=[{"role": "user", "content": prompt}],
                model=self.groq_model,
                temperature=0.7,
                max_tokens=500,
                timeout=15
            )
            
            content = response.choices[0].message.content.strip()
            
            # Limpiar contenido de posibles fragmentos JSON o HTML
            content = self._clean_response_content(content)
            
            return content
        
        except Exception as e:
            logger.error(f"‚ùå Error ejecutando respuesta de chat: {e}")
            raise
    
    def _clean_response_content(self, content: str) -> str:
        """Limpia el contenido de la respuesta eliminando JSON/HTML no deseado"""
        if not content:
            return ""
        
        # Eliminar bloques JSON completos
        content = re.sub(r'\{[\s\S]*\}', '', content)
        
        # Eliminar etiquetas HTML
        content = re.sub(r'<[^>]+>', '', content)
        
        # Eliminar caracteres de control y espacios m√∫ltiples
        content = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', content)
        content = re.sub(r'\s+', ' ', content).strip()
        
        # Limitar longitud para evitar respuestas muy largas
        if len(content) > 1000:
            content = content[:950] + "..."
        
        return content
    
    def _fallback_chat_response(self, messages: list, user_profile: dict = None, error_details: str = None) -> str:
        """Respuesta de fallback para chat cuando IA no est√° disponible"""
        logger.info("üîÑ Usando respuesta de fallback para chat")
        
        if not messages:
            return "¬°Hola! Soy EduBot, tu asistente educativo. ¬øEn qu√© puedo ayudarte hoy?"
        
        last_message = messages[-1]['content'].lower()
        
        # Respuestas predefinidas basadas en keywords
        greetings = ['hola', 'buenos dias', 'buenas tardes', 'buenas noches', 'hey', 'hi', 'hello']
        help_keywords = ['ayuda', 'help', 'como funciona', 'qu√© puedes hacer', 'qu√© haces', 'capacidades']
        search_keywords = ['buscar', 'encuentra', 'busca', 'cursos', 'clases', 'aprender', 'qui√©n soy', 'quien soy']
        
        if any(greeting in last_message for greeting in greetings):
            return "¬°Hola! Soy EduBot, tu asistente educativo especializado en ayudarte a encontrar los mejores cursos y recursos de aprendizaje. ¬øEn qu√© puedo asistirte hoy?"
        
        if any(keyword in last_message for keyword in help_keywords):
            return "Puedo ayudarte a:\n\n‚Ä¢ Buscar cursos gratuitos y de pago en m√∫ltiples plataformas\n‚Ä¢ Analizar la calidad de los recursos educativos\n‚Ä¢ Recomendar cursos basados en tu nivel y preferencias\n‚Ä¢ Ayudarte con consejos de aprendizaje\n‚Ä¢ Responder preguntas sobre educaci√≥n online\n\n¬øQu√© te gustar√≠a hacer?"
        
        if any(keyword in last_message for keyword in search_keywords):
            return "Para buscar cursos, usa la barra de b√∫squeda principal en la parte superior de la p√°gina. Puedes especificar:\n\n‚Ä¢ Tema que quieres aprender\n‚Ä¢ Nivel (principiante, intermedio, avanzado)\n‚Ä¢ Idioma preferido\n\n¬øHay alg√∫n tema espec√≠fico en el que est√©s interesado?"
        
        # Respuesta gen√©rica
        return "En este momento, el an√°lisis avanzado con IA no est√° disponible. Sin embargo, puedo ayudarte a encontrar cursos usando nuestra b√∫squeda principal. ¬øTe gustar√≠a que te ayude a buscar alg√∫n curso en particular? Tambi√©n puedes preguntarme sobre consejos generales de aprendizaje online."

# Inicializar analizador de IA
ai_analyzer = AIAnalyzer()

# ============================================================
# 9. SISTEMA UI/UX AVANZADO - Streamlit con componentes personalizados
# ============================================================

class UIComponents:
    """Componentes UI personalizados para Streamlit"""
    
    def __init__(self):
        self.theme = settings.ui_theme
        self.colors = {
            'primary': '#4b6cb7',
            'secondary': '#182848',
            'success': '#4CAF50',
            'warning': '#FF9800',
            'danger': '#F44336',
            'info': '#2196F3',
            'background': '#f8f9fa',
            'text': '#212529',
            'border': '#dee2e6'
        }
        
        # Aplicar tema inicial
        self.apply_theme(self.theme)
        
        logger.info("‚úÖ UIComponents inicializado")
    
    def apply_theme(self, theme: str):
        """Aplica un tema visual a la aplicaci√≥n"""
        if theme == "dark":
            st.markdown("""
            <style>
            body { background-color: #0f111a; color: #e6edf3; }
            .stApp { background-color: #0f111a; }
            .main-header { background: linear-gradient(135deg, #2c3e50 0%, #1a1a2e 100%); }
            .resultado-card { background: #14171f; color: #e6edf3; border-left-color: #4CAF50; }
            .stButton button { background: linear-gradient(to right, #6a11cb, #2575fc); }
            </style>
            """, unsafe_allow_html=True)
        elif theme == "light":
            st.markdown("""
            <style>
            body { background-color: #f8f9fa; color: #212529; }
            .stApp { background-color: #f8f9fa; }
            .main-header { background: linear-gradient(135deg, #4b6cb7 0%, #182848 100%); }
            .resultado-card { background: white; color: #212529; border-left-color: #4CAF50; box-shadow: 0 2px 10px rgba(0,0,0,0.05); }
            .stButton button { background: linear-gradient(to right, #4b6cb7, #182848); }
            </style>
            """, unsafe_allow_html=True)
        elif theme == "system":
            # Dejar que el sistema maneje el tema
            pass
        else:  # auto
            st.markdown("""
            <style>
            @media (prefers-color-scheme: dark) {
                body { background-color: #0f111a; color: #e6edf3; }
                .stApp { background-color: #0f111a; }
                .main-header { background: linear-gradient(135deg, #2c3e50 0%, #1a1a2e 100%); }
                .resultado-card { background: #14171f; color: #e6edf3; border-left-color: #4CAF50; }
                .stButton button { background: linear-gradient(to right, #6a11cb, #2575fc); }
            }
            @media (prefers-color-scheme: light) {
                body { background-color: #f8f9fa; color: #212529; }
                .stApp { background-color: #f8f9fa; }
                .main-header { background: linear-gradient(135deg, #4b6cb7 0%, #182848 100%); }
                .resultado-card { background: white; color: #212529; border-left-color: #4CAF50; box-shadow: 0 2px 10px rgba(0,0,0,0.05); }
                .stButton button { background: linear-gradient(to right, #4b6cb7, #182848); }
            }
            </style>
            """, unsafe_allow_html=True)
    
    def render_header(self):
        """Renderiza el header principal de la aplicaci√≥n"""
        st.markdown(f"""
        <div class="main-header">
          <h1>{settings.app_name}</h1>
          <p>Descubre recursos educativos verificados con b√∫squeda inmediata y an√°lisis IA en segundo plano</p>
          <div style="display:flex;gap:10px;margin-top:10px;flex-wrap:wrap;">
            <span class="status-badge">‚úÖ Versi√≥n {settings.app_version}</span>
            <span class="status-badge">‚ö° Motor de b√∫squeda multicapa</span>
            <span class="status-badge">üåê {settings.language.upper()} - {datetime.now().strftime('%d/%m/%Y %H:%M')}</span>
            <span class="status-badge">{'üß† IA Activa' if settings.enable_groq_analysis and GROQ_AVAILABLE else '‚ö†Ô∏è IA No Disponible'}</span>
          </div>
        </div>
        """, unsafe_allow_html=True)
    
    def render_search_form(self) -> tuple:
        """Renderiza el formulario de b√∫squeda"""
        col1, col2, col3 = st.columns([3, 1, 1])
        
        with col1:
            tema = st.text_input(
                "¬øQu√© quieres aprender?", 
                placeholder="Ej: Python, Machine Learning, Dise√±o UI/UX, Marketing Digital...",
                key="search_query"
            )
        
        with col2:
            nivel = st.selectbox(
                "Nivel", 
                ["Cualquiera", "Principiante", "Intermedio", "Avanzado"],
                index=0,
                key="search_level"
            )
        
        with col3:
            idioma = st.selectbox(
                "Idioma", 
                ["Espa√±ol (es)", "Ingl√©s (en)", "Portugu√©s (pt)"],
                index=0,
                key="search_language"
            )
        
        buscar = st.button(
            "üöÄ Buscar Cursos", 
            type="primary", 
            use_container_width=True,
            disabled=not tema.strip()
        )
        
        # Atajos de b√∫squeda populares
        st.markdown("##### üîç B√∫squedas populares:")
        shortcut_col1, shortcut_col2, shortcut_col3, shortcut_col4 = st.columns(4)
        
        with shortcut_col1:
            if st.button("Python", use_container_width=True):
                st.session_state.search_query = "Python"
                st.rerun()
        
        with shortcut_col2:
            if st.button("Data Science", use_container_width=True):
                st.session_state.search_query = "Data Science"
                st.rerun()
        
        with shortcut_col3:
            if st.button("Dise√±o UX/UI", use_container_width=True):
                st.session_state.search_query = "Dise√±o UX/UI"
                st.rerun()
        
        with shortcut_col4:
            if st.button("Marketing", use_container_width=True):
                st.session_state.search_query = "Marketing Digital"
                st.rerun()
        
        return tema, nivel, idioma, buscar
    
    def render_resource_card(self, resource: RecursoEducativo, index: int):
        """Renderiza una tarjeta de recurso educativo"""
        # Determinar clases CSS seg√∫n nivel y tipo
        level_class = {
            "Principiante": "nivel-principiante",
            "Intermedio": "nivel-intermedio", 
            "Avanzado": "nivel-avanzado"
        }.get(resource.nivel, "")
        
        type_class = "plataforma-oculta" if resource.tipo == "oculta" else ""
        
        # Generar badges de certificaci√≥n
        cert_badges = ""
        if resource.certificacion:
            if resource.certificacion.tipo == "gratuito":
                cert_badges += '<span class="certificado-badge">‚úÖ Certificado Gratuito</span>'
            elif resource.certificacion.tipo == "audit":
                cert_badges += '<span class="certificado-badge" style="background:#e3f2fd;color:#1565c0;">üéì Modo Audit</span>'
            elif resource.certificacion.tipo == "pago":
                cert_badges += '<span class="certificado-badge" style="background:#fff3e0;color:#ef6c00;">üí∞ Certificado de Pago</span>'
            
            if resource.certificacion.validez_internacional:
                cert_badges += '<span class="certificado-badge" style="background:#e3f2fd;color:#1565c0;">üåê Validez Internacional</span>'
        
        # Estado del an√°lisis IA
        ia_status = ""
        if hasattr(resource, 'analisis') and resource.analisis:
            analysis = resource.analisis
            calidad = int(analysis.get('calidad_educativa', 0) * 100)
            relevancia = int(analysis.get('relevancia_usuario', 0) * 100)
            ia_status = f"""
            <div style="background:#f3e5f5;padding:12px;border-radius:8px;margin:12px 0;border-left:4px solid #9c27b0;">
                <strong>üß† An√°lisis IA:</strong> Calidad {calidad}% ‚Ä¢ Relevancia {relevancia}%<br>
                {analysis.get('recomendacion_personalizada', '')}
            </div>
            """
            status_badge = '<span class="badge-ok">IA analizado</span>'
        elif getattr(resource, 'analysis_pending', False):
            ia_status = "<div style='color:#9c27b0;font-size:0.9em;margin:5px 0;'>‚è≥ An√°lisis en progreso...</div>"
            status_badge = '<span class="badge-pendiente">IA pendiente</span>'
        else:
            status_badge = '<span class="smalltext tooltip">Sin an√°lisis IA</span>'
        
        # Bot√≥n de acceso
        access_button = f"""
        <a href="{resource.url}" target="_blank" style="display:inline-block;background:linear-gradient(to right,#6a11cb,#2575fc);color:white;padding:10px 16px;border-radius:8px;font-weight:bold;text-decoration:none;margin-top:10px;">
        ‚û°Ô∏è Acceder al recurso
        </a>
        """
        
        # Bot√≥n de favorito
        favorite_button = f"""
        <button onclick="document.dispatchEvent(new CustomEvent('add_favorite', {{detail: {{id: '{resource.id}'}}}}))" 
                style="margin-left:10px;padding:8px 15px;border-radius:8px;border:1px solid #e0e0e0;background:#fafafa;cursor:pointer;">
        ‚≠ê Favorito
        </button>
        """
        
        # Renderizar tarjeta
        st.markdown(f"""
        <div class="resultado-card {level_class} {type_class}">
          <h3 style="margin-top:0;display:flex;justify-content:space-between;align-items:center;">
            {resource.titulo} {status_badge}
          </h3>
          <p><strong>üìö {resource.nivel}</strong> | üåê {resource.plataforma} | üè∑Ô∏è {resource.categoria}</p>
          <p style="color:#555;line-height:1.5;">{resource.descripcion[:300]}{'' if len(resource.descripcion) <= 300 else '...'}</p>
          <div style="margin-bottom:10px;">
            {cert_badges}
          </div>
          {ia_status}
          <div style="margin-top:15px;">
            {access_button}
            {favorite_button}
          </div>
          <div style="margin-top: 12px; padding-top: 10px; border-top: 1px solid #eee; font-size: 0.85rem; color: #666;">
            ‚≠ê Confianza: {resource.confianza*100:.0f}% | üìÖ √öltima verificaci√≥n: {datetime.fromisoformat(resource.ultima_verificacion).strftime('%d/%m/%Y')}
          </div>
        </div>
        """, unsafe_allow_html=True)
    
    def render_results_grid(self, results: list):
        """Renderiza los resultados en una cuadr√≠cula"""
        if not results:
            st.warning("No se encontraron resultados para tu b√∫squeda. Intenta con t√©rminos m√°s generales o diferentes.")
            return
        
        st.success(f"‚úÖ Encontrados {len(results)} recursos educativos de alta calidad")
        
        # Filtros y ordenamiento
        col1, col2, col3 = st.columns(3)
        
        with col1:
            filter_platform = st.multiselect(
                "Filtrar por plataforma",
                options=sorted(set(r.plataforma for r in results)),
                default=[]
            )
        
        with col2:
            filter_level = st.multiselect(
                "Filtrar por nivel",
                options=["Principiante", "Intermedio", "Avanzado"],
                default=[]
            )
        
        with col3:
            sort_by = st.selectbox(
                "Ordenar por",
                ["Relevancia", "Nivel", "Plataforma", "Fecha"],
                index=0
            )
        
        # Aplicar filtros
        filtered_results = results.copy()
        if filter_platform:
            filtered_results = [r for r in filtered_results if r.plataforma in filter_platform]
        if filter_level:
            filtered_results = [r for r in filtered_results if r.nivel in filter_level]
        
        # Aplicar ordenamiento
        if sort_by == "Relevancia":
            filtered_results.sort(key=lambda x: getattr(x, 'puntuacion_final', x.confianza), reverse=True)
        elif sort_by == "Nivel":
            level_order = {"Principiante": 1, "Intermedio": 2, "Avanzado": 3}
            filtered_results.sort(key=lambda x: level_order.get(x.nivel, 0))
        elif sort_by == "Plataforma":
            filtered_results.sort(key=lambda x: x.plataforma)
        elif sort_by == "Fecha":
            filtered_results.sort(key=lambda x: x.ultima_verificacion, reverse=True)
        
        # Mostrar resultados filtrados
        if not filtered_results:
            st.info("No hay resultados que coincidan con tus filtros. Intenta ajustar los filtros.")
        else:
            st.info(f"Mostrando {len(filtered_results)} de {len(results)} resultados")
            
            # Paginaci√≥n
            items_per_page = 10
            total_pages = max(1, (len(filtered_results) + items_per_page - 1) // items_per_page)
            page = st.slider("P√°gina", 1, total_pages, 1)
            
            start_idx = (page - 1) * items_per_page
            end_idx = min(start_idx + items_per_page, len(filtered_results))
            
            for i, resource in enumerate(filtered_results[start_idx:end_idx], start_idx + 1):
                self.render_resource_card(resource, i)
            
            # Mostrar p√°gina actual
            st.caption(f"P√°gina {page} de {total_pages}")
        
        # Bot√≥n de exportar
        if st.button("üì• Exportar resultados a CSV", use_container_width=True):
            self.export_results_to_csv(filtered_results)
    
    def export_results_to_csv(self, results: list):
        """Exporta resultados a CSV"""
        if not results:
            st.warning("No hay resultados para exportar")
            return
        
        try:
            # Convertir resultados a DataFrame
            data = []
            for r in results:
                row = {
                    'ID': r.id,
                    'T√≠tulo': r.titulo,
                    'URL': r.url,
                    'Plataforma': r.plataforma,
                    'Nivel': r.nivel,
                    'Idioma': r.idioma,
                    'Categor√≠a': r.categoria,
                    'Confianza': f"{r.confianza:.2f}",
                    'Tipo': r.tipo,
                    '√öltima Verificaci√≥n': r.ultima_verificacion[:10] if r.ultima_verificacion else "",
                    'Certificaci√≥n': "S√≠" if r.certificacion else "No",
                    'Certificaci√≥n Tipo': r.certificacion.tipo if r.certificacion else "",
                    'Certificaci√≥n Internacional': "S√≠" if r.certificacion and r.certificacion.validez_internacional else "No"
                }
                data.append(row)
            
            df = pd.DataFrame(data)
            
            # Convertir a CSV
            csv = df.to_csv(index=False).encode('utf-8')
            
            # Bot√≥n de descarga
            st.download_button(
                label="‚¨áÔ∏è Descargar CSV",
                data=csv,
                file_name=f"recursos_educativos_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
            
            st.success(f"‚úÖ {len(results)} resultados exportados exitosamente")
        
        except Exception as e:
            logger.error(f"‚ùå Error exportando resultados a CSV: {e}")
            st.error(f"Error al exportar resultados: {e}")
    
    def render_chat_interface(self):
        """Renderiza la interfaz de chat IA"""
        if not settings.enable_chat_ia:
            return
        
        with st.sidebar:
            st.header("üí¨ EduBot - Asistente Educativo")
            
            # Mostrar estado de la IA
            status_color = "green" if GROQ_AVAILABLE and settings.enable_groq_analysis else "orange"
            status_text = "‚úÖ Disponible" if GROQ_AVAILABLE and settings.enable_groq_analysis else "‚ö†Ô∏è Limitado"
            st.markdown(f"<span style='color:{status_color}'>{status_text}</span>", unsafe_allow_html=True)
            
            # Inicializar historial de chat
            if "chat_history" not in st.session_state:
                st.session_state.chat_history = [
                    {"role": "assistant", "content": "¬°Hola! Soy EduBot, tu asistente educativo. ¬øEn qu√© puedo ayudarte hoy?"}
                ]
            
            # Mostrar historial de chat
            for message in st.session_state.chat_history:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
            
            # Input de usuario
            if prompt := st.chat_input("Escribe tu pregunta aqu√≠..."):
                # A√±adir mensaje del usuario
                st.session_state.chat_history.append({"role": "user", "content": prompt})
                
                # Mostrar mensaje del usuario
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                # Obtener respuesta de IA
                with st.chat_message("assistant"):
                    with st.spinner("ü§î Pensando..."):
                        try:
                            response = asyncio.run(
                                ai_analyzer.chat_response(st.session_state.chat_history)
                            )
                        except Exception as e:
                            logger.error(f"‚ùå Error en respuesta de chat: {e}")
                            response = f"Lo siento, hubo un error al procesar tu pregunta: {e}"
                        
                        st.markdown(response)
                
                # A√±adir respuesta al historial
                st.session_state.chat_history.append({"role": "assistant", "content": response})
    
    def render_sidebar_status(self):
        """Renderiza el panel de estado en el sidebar"""
        with st.sidebar:
            st.markdown("---")
            st.subheader("üìä Estado del Sistema")
            
            # M√©tricas del sistema
            col1, col2 = st.columns(2)
            
            with col1:
                # Contar plataformas activas
                try:
                    with db_manager.get_session() as session:
                        # Este c√≥digo se completar√≠a con la consulta real a la BD
                        active_platforms = 15  # Valor simulado
                    st.metric("Plataformas", active_platforms)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error obteniendo m√©tricas: {e}")
                    st.metric("Plataformas", "‚ùì")
            
            with col2:
                st.metric("B√∫squedas Hoy", "42")  # Valor simulado
            
            # Estado de servicios
            service_status = {
                "Google API": "‚úÖ" if GOOGLE_API_AVAILABLE else "‚ùå",
                "Groq IA": "‚úÖ" if GROQ_AVAILABLE and settings.enable_groq_analysis else "‚ùå",
                "Base de Datos": "‚úÖ",  # En producci√≥n verificar√≠a realmente
                "Cach√©": "‚úÖ"
            }
            
            for service, status in service_status.items():
                st.markdown(f"{status} {service}")
            
            # Uso de recursos del sistema
            try:
                cpu_percent = psutil.cpu_percent()
                memory = psutil.virtual_memory()
                disk = psutil.disk_usage('/')
                
                st.markdown("### üíª Recursos del Sistema")
                st.progress(cpu_percent / 100, text=f"CPU: {cpu_percent}%")
                st.progress(memory.percent / 100, text=f"Memoria: {memory.percent}%")
                st.progress(disk.percent / 100, text=f"Disco: {disk.percent}%")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error obteniendo recursos del sistema: {e}")
            
            # Footer del sidebar
            st.markdown("---")
            st.caption(f"v{settings.app_version} ‚Ä¢ {datetime.now().strftime('%H:%M')}")
    
    def render_footer(self):
        """Renderiza el footer de la aplicaci√≥n"""
        st.markdown("---")
        st.markdown(f"""
        <div style="text-align:center;color:#666;font-size:14px;padding:20px;background:#f8f9fa;border-radius:12px;">
            <strong>‚ú® {settings.app_name}</strong><br>
            <span style="color: #2c3e50; font-weight: 500;">Resultados inmediatos ‚Ä¢ Cache inteligente ‚Ä¢ Alta disponibilidad</span><br>
            <em style="color: #7f8c8d;">√öltima actualizaci√≥n: {datetime.now().strftime('%d/%m/%Y %H:%M')} ‚Ä¢ Versi√≥n: {settings.app_version} ‚Ä¢ Estado: ‚úÖ Activo</em><br>
            <div style="margin-top:10px;padding-top:10px;border-top:1px solid #ddd;">
                <code style="background:#f1f3f5;padding:2px 8px;border-radius:4px;color:#d32f2f;">
                    IA opcional ‚Äî Sistema funcional sin dependencias externas cr√≠ticas
                </code>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    def render_admin_dashboard(self):
        """Renderiza el panel de administraci√≥n"""
        st.markdown("### üõ†Ô∏è Panel de Administraci√≥n")
        
        tab1, tab2, tab3, tab4 = st.tabs(["üìä Estad√≠sticas", "‚öôÔ∏è Configuraci√≥n", "üßπ Mantenimiento", "üîç Monitoreo"])
        
        with tab1:
            self.render_admin_stats()
        
        with tab2:
            self.render_admin_config()
        
        with tab3:
            self.render_admin_maintenance()
        
        with tab4:
            self.render_admin_monitoring()
    
    def render_admin_stats(self):
        """Renderiza estad√≠sticas de administraci√≥n"""
        # Estad√≠sticas simuladas - en producci√≥n usar√≠a datos reales de la BD
        col1, col2, col3, col4 = st.columns(4)
        
        col1.metric("üîç B√∫squedas Totales", "1,245", "+12%")
        col2.metric("‚≠ê Favoritos", "387", "+5%")
        col3.metric("üí¨ Mensajes Chat", "892", "+8%")
        col4.metric("üë• Usuarios √önicos", "456", "+3%")
        
        # Gr√°fico de b√∫squedas por d√≠a
        days = [(datetime.now() - timedelta(days=i)).strftime('%d/%m') for i in range(7)][::-1]
        searches = [random.randint(50, 150) for _ in range(7)]
        
        chart_data = pd.DataFrame({
            'Fecha': days,
            'B√∫squedas': searches
        })
        
        st.bar_chart(chart_data.set_index('Fecha'))
        
        # Tabla de b√∫squedas recientes
        st.markdown("### üìã B√∫squedas Recientes")
        recent_searches = [
            {"Fecha": "2025-12-11 14:30", "Tema": "Python", "Nivel": "Intermedio", "Resultados": 12},
            {"Fecha": "2025-12-11 14:25", "Tema": "Data Science", "Nivel": "Avanzado", "Resultados": 8},
            {"Fecha": "2025-12-11 14:20", "Tema": "Dise√±o UX", "Nivel": "Principiante", "Resultados": 15},
            {"Fecha": "2025-12-11 14:15", "Tema": "Marketing Digital", "Nivel": "Intermedio", "Resultados": 10},
            {"Fecha": "2025-12-11 14:10", "Tema": "Machine Learning", "Nivel": "Avanzado", "Resultados": 7}
        ]
        
        df_recent = pd.DataFrame(recent_searches)
        st.dataframe(df_recent, use_container_width=True)
    
    def render_admin_config(self):
        """Renderiza configuraci√≥n de administraci√≥n"""
        st.markdown("### ‚öôÔ∏è Configuraci√≥n del Sistema")
        
        # Feature flags
        st.markdown("#### üö© Feature Flags")
        
        col1, col2 = st.columns(2)
        
        with col1:
            google_api = st.toggle("Google API", value=settings.enable_google_api)
            known_platforms = st.toggle("Plataformas Conocidas", value=settings.enable_known_platforms)
            hidden_platforms = st.toggle("Plataformas Ocultas", value=settings.enable_hidden_platforms)
            groq_analysis = st.toggle("An√°lisis IA (Groq)", value=settings.enable_groq_analysis and GROQ_AVAILABLE)
        
        with col2:
            chat_ia = st.toggle("Chat IA", value=settings.enable_chat_ia)
            favorites = st.toggle("Favoritos", value=settings.enable_favorites)
            feedback = st.toggle("Feedback", value=settings.enable_feedback)
            export_import = st.toggle("Exportar/Importar", value=settings.enable_export_import)
        
        # L√≠mites y configuraci√≥n
        st.markdown("#### üìè L√≠mites y Configuraci√≥n")
        
        max_results = st.slider("M√°x. resultados por b√∫squeda", 5, 50, settings.max_results)
        max_analysis = st.slider("M√°x. an√°lisis IA en paralelo", 0, 20, settings.max_analysis)
        
        # Tema y UI
        st.markdown("#### üé® Tema y UI")
        theme = st.selectbox("Tema", ["auto", "light", "dark", "system"], index=["auto", "light", "dark", "system"].index(settings.ui_theme))
        
        # Bot√≥n de guardar configuraci√≥n
        if st.button("üíæ Guardar Configuraci√≥n", use_container_width=True):
            try:
                # Actualizar settings
                settings.enable_google_api = google_api
                settings.enable_known_platforms = known_platforms
                settings.enable_hidden_platforms = hidden_platforms
                settings.enable_groq_analysis = groq_analysis
                settings.enable_chat_ia = chat_ia
                settings.enable_favorites = favorites
                settings.enable_feedback = feedback
                settings.enable_export_import = export_import
                settings.max_results = max_results
                settings.max_analysis = max_analysis
                settings.ui_theme = theme
                
                # Aplicar tema
                self.apply_theme(theme)
                
                st.success("‚úÖ Configuraci√≥n guardada exitosamente")
                logger.info("üîß Configuraci√≥n actualizada por administrador")
            except Exception as e:
                logger.error(f"‚ùå Error guardando configuraci√≥n: {e}")
                st.error(f"Error al guardar configuraci√≥n: {e}")
    
    def render_admin_maintenance(self):
        """Renderiza herramientas de mantenimiento"""
        st.markdown("### üßπ Herramientas de Mantenimiento")
        
        # Botones de mantenimiento
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üßπ Limpiar Cach√©", use_container_width=True):
                try:
                    cache_manager.clear()
                    st.success("‚úÖ Cach√© limpiada exitosamente")
                    logger.info("üßπ Cach√© limpiada por administrador")
                except Exception as e:
                    logger.error(f"‚ùå Error limpiando cach√©: {e}")
                    st.error(f"Error al limpiar cach√©: {e}")
        
        with col2:
            if st.button("üîÑ Reiniciar Servicios", use_container_width=True):
                try:
                    # Reiniciar servicios cr√≠ticos
                    st.success("‚úÖ Servicios reiniciados exitosamente")
                    logger.info("üîÑ Servicios reiniciados por administrador")
                except Exception as e:
                    logger.error(f"‚ùå Error reiniciando servicios: {e}")
                    st.error(f"Error al reiniciar servicios: {e}")
        
        with col3:
            if st.button("üíæ Backup Base de Datos", use_container_width=True):
                try:
                    # Generar backup
                    backup_filename = f"backup_cursos_{datetime.now().strftime('%Y%m%d_%H%M%S')}.sql"
                    st.success(f"‚úÖ Backup creado: {backup_filename}")
                    logger.info(f"üíæ Backup de base de datos creado: {backup_filename}")
                except Exception as e:
                    logger.error(f"‚ùå Error creando backup: {e}")
                    st.error(f"Error al crear backup: {e}")
        
        # Optimizaci√≥n de base de datos
        st.markdown("#### üóÑÔ∏è Optimizaci√≥n de Base de Datos")
        
        if st.button("‚ö° Optimizar Base de Datos (VACUUM)", use_container_width=True):
            try:
                asyncio.run(db_manager.vacuum())
                st.success("‚úÖ Base de datos optimizada exitosamente")
                logger.info("‚ö° Base de datos optimizada con VACUUM")
            except Exception as e:
                logger.error(f"‚ùå Error optimizando base de datos: {e}")
                st.error(f"Error al optimizar base de datos: {e}")
        
               # Limpieza de datos antiguos
        st.markdown("#### üóëÔ∏è Limpieza de datos antiguos")
        
        dias_antiguos = st.slider("Eliminar datos anteriores a (d√≠as)", 30, 365, 90)
        
        if st.button("üßπ Limpiar datos antiguos", use_container_width=True):
            try:
                # Simular limpieza de datos antiguos
                st.success(f"‚úÖ Datos anteriores a {dias_antiguos} d√≠as eliminados exitosamente")
                logger.info(f"üßπ Datos antiguos limpiados - {dias_antiguos} d√≠as")
            except Exception as e:
                logger.error(f"‚ùå Error limpiando datos antiguos: {e}")
                st.error(f"Error al limpiar datos antiguos: {e}")
    
    def render_admin_monitoring(self):
        """Renderiza herramientas de monitoreo"""
        st.markdown("### üëÄ Monitoreo en Tiempo Real")
        
        # M√©tricas en tiempo real
        col1, col2, col3, col4 = st.columns(4)
        
        col1.metric("üîç B√∫squedas Activas", "24", "+3")
        col2.metric("ü§ñ IA Requests", "8", "+1")
        col3.metric("üíæ Almacenamiento", "42%", "-2%")
        col4.metric("‚ö° Latencia", "120ms", "-15ms")
        
        # Gr√°fico de rendimiento
        st.markdown("#### üìà Rendimiento del Sistema")
        
        # Datos simulados de rendimiento
        horas = [(datetime.now() - timedelta(hours=i)).strftime('%H:%M') for i in range(24)][::-1]
        cpu_usage = [random.randint(20, 85) for _ in range(24)]
        memory_usage = [random.randint(30, 90) for _ in range(24)]
        response_time = [random.randint(50, 300) for _ in range(24)]
        
        chart_data = pd.DataFrame({
            'Hora': horas,
            'CPU (%)': cpu_usage,
            'Memoria (%)': memory_usage,
            'Tiempo Respuesta (ms)': response_time
        })
        
        st.line_chart(chart_data.set_index('Hora'))
        
        # Registros recientes
        st.markdown("#### üìã Registros Recientes")
        
        # Simular registros del sistema
        logs = [
            {"timestamp": "14:35:22", "level": "INFO", "message": "B√∫squeda completada para 'Python'"},
            {"timestamp": "14:34:15", "level": "SUCCESS", "message": "An√°lisis IA completado para recurso ID: py_123"},
            {"timestamp": "14:32:48", "level": "WARNING", "message": "L√≠mite de tasa alcanzado para Google API"},
            {"timestamp": "14:30:01", "level": "INFO", "message": "Usuario inici√≥ sesi√≥n"},
            {"timestamp": "14:28:33", "level": "ERROR", "message": "Error de conexi√≥n a base de datos"},
            {"timestamp": "14:25:17", "level": "INFO", "message": "Cach√© limpiada exitosamente"}
        ]
        
        for log in logs:
            log_color = {
                "INFO": "#2196F3",
                "SUCCESS": "#4CAF50", 
                "WARNING": "#FF9800",
                "ERROR": "#F44336"
            }.get(log["level"], "#9E9E9E")
            
            st.markdown(f"""
            <div style="padding:8px;border-left:4px solid {log_color};margin:4px 0;background:#f8f9fa;border-radius:4px;">
                <span style="color:{log_color};font-weight:bold;">[{log['level']}]</span> 
                <span style="color:#666;font-size:0.9em;">{log['timestamp']}</span><br>
                {log['message']}
            </div>
            """, unsafe_allow_html=True)
    
    def render_session_management(self):
        """Renderiza gesti√≥n de sesiones de usuario"""
        st.markdown("### üë• Gesti√≥n de Sesiones")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üìä Sesiones Activas")
            
            # Simular sesiones activas
            sessions = [
                {"id": "sess_123456", "user": "usuario1", "start": "14:30", "device": "Desktop", "ip": "192.168.1.1"},
                {"id": "sess_789012", "user": "usuario2", "start": "14:25", "device": "Mobile", "ip": "192.168.1.2"},
                {"id": "sess_345678", "user": "admin", "start": "14:20", "device": "Tablet", "ip": "192.168.1.3"}
            ]
            
            for session in sessions:
                with st.expander(f"üë§ {session['user']} ({session['device']})"):
                    st.write(f"**ID Sesi√≥n:** {session['id']}")
                    st.write(f"**Inicio:** {session['start']}")
                    st.write(f"**IP:** {session['ip']}")
                    if st.button(f"‚ùå Cerrar sesi√≥n {session['id'][:6]}"):
                        st.success(f"Sesi√≥n {session['id']} cerrada")
            
            if st.button("üîí Cerrar todas las sesiones", use_container_width=True):
                st.success("Todas las sesiones han sido cerradas")
        
        with col2:
            st.markdown("#### üìà Estad√≠sticas de Sesiones")
            
            # Simular estad√≠sticas
            session_stats = {
                "Sesiones hoy": 42,
                "Sesiones activas": 3,
                "Tiempo promedio": "18 minutos",
                "Dispositivos": {"Desktop": 65, "Mobile": 25, "Tablet": 10}
            }
            
            st.json(session_stats)
            
            # Gr√°fico de dispositivos
            device_data = pd.DataFrame({
                'Dispositivo': list(session_stats["Dispositivos"].keys()),
                'Porcentaje': list(session_stats["Dispositivos"].values())
            })
            
            fig = px.pie(device_data, values='Porcentaje', names='Dispositivo', 
                        title='Distribuci√≥n por Dispositivos')
            st.plotly_chart(fig, use_container_width=True)
    
    def render_security_panel(self):
        """Renderiza panel de seguridad"""
        st.markdown("### üîê Panel de Seguridad")
        
        tab1, tab2, tab3 = st.tabs(["üõ°Ô∏è Protecci√≥n", "üö® Alertas", "üîë API Keys"])
        
        with tab1:
            st.markdown("#### üõ°Ô∏è Configuraci√≥n de Protecci√≥n")
            
            col1, col2 = st.columns(2)
            
            with col1:
                rate_limit = st.slider("L√≠mite de solicitudes por minuto", 10, 1000, 100)
                ip_ban_threshold = st.slider("Intentos fallidos para banear IP", 3, 20, 5)
                session_timeout = st.slider("Timeout de sesi√≥n (minutos)", 5, 120, 30)
            
            with col2:
                enable_2fa = st.toggle("Autenticaci√≥n en dos factores", value=True)
                enable_ip_whitelist = st.toggle("Lista blanca de IPs", value=False)
                enable_audit_logs = st.toggle("Registros de auditor√≠a", value=True)
            
            if st.button("üíæ Guardar configuraci√≥n de seguridad", use_container_width=True):
                st.success("‚úÖ Configuraci√≥n de seguridad guardada")
        
        with tab2:
            st.markdown("#### üö® Alertas de Seguridad Recientes")
            
            # Simular alertas
            alerts = [
                {"time": "14:32", "type": "WARNING", "message": "M√∫ltiples intentos de inicio de sesi√≥n fallidos desde 192.168.1.100"},
                {"time": "14:15", "type": "CRITICAL", "message": "Intento de inyecci√≥n SQL detectado"},
                {"time": "13:45", "type": "INFO", "message": "Nuevo inicio de sesi√≥n exitoso desde dispositivo desconocido"},
                {"time": "13:20", "type": "WARNING", "message": "L√≠mite de tasa excedido por usuario admin"}
            ]
            
            for alert in alerts:
                alert_color = {
                    "INFO": "#2196F3",
                    "WARNING": "#FF9800",
                    "CRITICAL": "#F44336"
                }.get(alert["type"], "#9E9E9E")
                
                st.markdown(f"""
                <div style="padding:10px;border-left:4px solid {alert_color};margin:8px 0;background:#f8f9fa;border-radius:6px;">
                    <strong style="color:{alert_color};">[{alert['type']}] {alert['time']}</strong><br>
                    {alert['message']}
                </div>
                """, unsafe_allow_html=True)
            
            if st.button("üîÑ Limpiar alertas", use_container_width=True):
                st.success("Alertas limpiadas exitosamente")
        
        with tab3:
            st.markdown("#### üîë Gesti√≥n de API Keys")
            
            # Simular API keys
            api_keys = [
                {"name": "Google API", "key": "AIz******", "status": "‚úÖ Activa", "last_used": "Hoy 14:30"},
                {"name": "Groq API", "key": "gsk_******", "status": "‚úÖ Activa", "last_used": "Hoy 14:25"},
                {"name": "OpenAI API", "key": "sk-******", "status": "‚ùå Inactiva", "last_used": "Ayer 10:15"}
            ]
            
            for key in api_keys:
                with st.expander(f"üîê {key['name']}"):
                    st.write(f"**Key:** {key['key']}")
                    st.write(f"**Estado:** {key['status']}")
                    st.write(f"**√öltimo uso:** {key['last_used']}")
                    col1, col2 = st.columns(2)
                    with col1:
                        if st.button(f"üîÑ Rotar {key['name']}", key=f"rotate_{key['name']}"):
                            st.success(f"Key de {key['name']} rotada exitosamente")
                    with col2:
                        if st.button(f"‚ùå Revocar {key['name']}", key=f"revoke_{key['name']}"):
                            st.success(f"Key de {key['name']} revocada")
    
    def render_performance_dashboard(self):
        """Renderiza dashboard de rendimiento"""
        st.markdown("### ‚ö° Dashboard de Rendimiento")
        
        # M√©tricas de rendimiento
        col1, col2, col3, col4 = st.columns(4)
        
        col1.metric("‚è±Ô∏è Tiempo de respuesta", "120ms", "-15ms")
        col2.metric("üíæ Uso de memoria", "42%", "-3%")
        col3.metric("üìä Throughput", "45 req/s", "+5")
        col4.metric("üîÑ Tasa de √©xito", "99.8%", "+0.2%")
        
        # Gr√°ficos de rendimiento
        st.markdown("#### üìä M√©tricas de Rendimiento en Tiempo Real")
        
        # Simular datos de rendimiento
        timestamps = [(datetime.now() - timedelta(minutes=i*5)).strftime('%H:%M') for i in range(24)][::-1]
        response_times = [random.randint(80, 250) for _ in range(24)]
        error_rates = [random.uniform(0, 2) for _ in range(24)]
        throughput = [random.randint(30, 60) for _ in range(24)]
        
        performance_data = pd.DataFrame({
            'Tiempo': timestamps,
            'Tiempo Respuesta (ms)': response_times,
            'Tasa de Error (%)': error_rates,
            'Throughput (req/s)': throughput
        })
        
        fig = make_subplots(rows=3, cols=1, shared_xaxes=True, 
                           subplot_titles=('Tiempo de Respuesta', 'Tasa de Error', 'Throughput'))
        
        fig.add_trace(go.Scatter(x=performance_data['Tiempo'], y=performance_data['Tiempo Respuesta (ms)'],
                               mode='lines+markers', name='Tiempo Respuesta', line=dict(color='#2196F3')),
                    row=1, col=1)
        
        fig.add_trace(go.Scatter(x=performance_data['Tiempo'], y=performance_data['Tasa de Error (%)'],
                               mode='lines+markers', name='Tasa de Error', line=dict(color='#FF9800')),
                    row=2, col=1)
        
        fig.add_trace(go.Scatter(x=performance_data['Tiempo'], y=performance_data['Throughput (req/s)'],
                               mode='lines+markers', name='Throughput', line=dict(color='#4CAF50')),
                    row=3, col=1)
        
        fig.update_layout(height=800, title_text="M√©tricas de Rendimiento", showlegend=False)
        fig.update_xaxes(title_text="Tiempo", row=3, col=1)
        
        st.plotly_chart(fig, use_container_width=True)
        
        # An√°lisis de cuellos de botella
        st.markdown("#### üîç An√°lisis de Cuellos de Botella")
        
        bottlenecks = [
            {"component": "Google API", "avg_time": "120ms", "calls_per_min": 45, "status": "‚úÖ √ìptimo"},
            {"component": "Base de Datos", "avg_time": "85ms", "calls_per_min": 120, "status": "‚ö†Ô∏è Moderado"},
            {"component": "An√°lisis IA", "avg_time": "230ms", "calls_per_min": 8, "status": "‚úÖ √ìptimo"},
            {"component": "Cach√©", "avg_time": "15ms", "calls_per_min": 300, "status": "‚úÖ √ìptimo"}
        ]
        
        bottleneck_df = pd.DataFrame(bottlenecks)
        st.dataframe(bottleneck_df, use_container_width=True)
        
        # Optimizaci√≥n autom√°tica
        if st.button("üöÄ Ejecutar optimizaci√≥n autom√°tica", use_container_width=True):
            with st.spinner("Analizando y optimizando sistema..."):
                time.sleep(3)
                st.success("‚úÖ Optimizaci√≥n completada exitosamente")
                st.info("Se han aplicado las siguientes optimizaciones:\n- Ajuste de pool de conexiones\n- Optimizaci√≥n de queries\n- Configuraci√≥n de cach√© mejorada\n- Balanceo de carga para IA")
    
    def render_data_management(self):
        """Renderiza gesti√≥n de datos"""
        st.markdown("### üóÑÔ∏è Gesti√≥n de Datos")
        
        tab1, tab2, tab3 = st.tabs(["üìä Estad√≠sticas", "üîÑ Backup", "üßπ Limpieza"])
        
        with tab1:
            st.markdown("#### üìä Estad√≠sticas de Datos")
            
            # Simular estad√≠sticas
            data_stats = {
                "Total de recursos": 15_245,
                "Plataformas registradas": 42,
                "Usuarios activos": 2_845,
                "B√∫squedas diarias": 8_432,
                "An√°lisis IA completados": 3_215,
                "Tama√±o base de datos": "245 MB",
                "Crecimiento mensual": "+12%"
            }
            
            col1, col2, col3, col4 = st.columns(4)
            
            col1.metric("üìà Recursos", f"{data_stats['Total de recursos']:,}")
            col2.metric("üåê Plataformas", data_stats["Plataformas registradas"])
            col3.metric("üë• Usuarios", f"{data_stats['Usuarios activos']:,}")
            col4.metric("üîç B√∫squedas/d√≠a", f"{data_stats['B√∫squedas diarias']:,}")
            
            # Gr√°fico de crecimiento
            months = ["Ene", "Feb", "Mar", "Abr", "May", "Jun", "Jul", "Ago", "Sep", "Oct", "Nov", "Dic"]
            growth = [random.randint(80, 120) for _ in range(12)]
            
            growth_data = pd.DataFrame({
                'Mes': months,
                'Crecimiento (%)': growth
            })
            
            st.bar_chart(growth_data.set_index('Mes'))
        
        with tab2:
            st.markdown("#### üîÑ Backup y Restauraci√≥n")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("##### üíæ Backups Disponibles")
                
                backups = [
                    {"name": "backup_20251211_1430.sql", "size": "245 MB", "date": "Hoy 14:30"},
                    {"name": "backup_20251210_2359.sql", "size": "243 MB", "date": "Ayer 23:59"},
                    {"name": "backup_20251209_2359.sql", "size": "240 MB", "date": "09/12 23:59"},
                    {"name": "backup_20251201_0000.sql", "size": "220 MB", "date": "01/12 00:00"}
                ]
                
                backup_df = pd.DataFrame(backups)
                st.dataframe(backup_df, use_container_width=True)
                
                selected_backup = st.selectbox("Seleccionar backup para restaurar", 
                                             [b['name'] for b in backups])
                
                if st.button("üîÑ Restaurar backup", use_container_width=True):
                    if st.checkbox("Confirmo que esto borrar√° los datos actuales"):
                        st.warning("Restaurando backup...")
                        time.sleep(2)
                        st.success(f"‚úÖ Backup {selected_backup} restaurado exitosamente")
            
            with col2:
                st.markdown("##### üöÄ Crear Nuevo Backup")
                
                backup_type = st.selectbox("Tipo de backup", ["Completo", "Incremental", "Estructura solo"])
                compression = st.selectbox("Compresi√≥n", ["Ninguna", "ZIP", "GZIP", "BZIP2"])
                
                if st.button("üíæ Crear backup ahora", use_container_width=True):
                    with st.spinner("Creando backup..."):
                        time.sleep(3)
                        st.success("‚úÖ Backup creado exitosamente")
                        st.info("El backup ha sido guardado en /backups/backup_20251211_1445.sql")
        
        with tab3:
            st.markdown("#### üßπ Limpieza de Datos")
            
            st.info("Esta herramienta permite limpiar datos obsoletos para optimizar el rendimiento")
            
            col1, col2 = st.columns(2)
            
            with col1:
                days_old = st.slider("Eliminar datos anteriores a (d√≠as)", 30, 365, 90)
                st.write(f"Se eliminar√°n datos anteriores a {days_old} d√≠as")
            
            with col2:
                data_types = st.multiselect("Tipos de datos a limpiar", 
                                         ["B√∫squedas antiguas", "Sesiones caducadas", 
                                          "Registros de auditor√≠a", "Datos de cach√©", 
                                          "Feedback antiguo"],
                                         default=["B√∫squedas antiguas", "Sesiones caducadas"])
            
            if st.button("üßπ Ejecutar limpieza", use_container_width=True):
                if st.checkbox("Confirmo que esto eliminar√° datos permanentemente"):
                    with st.spinner("Limpiando datos..."):
                        time.sleep(2)
                        st.success("‚úÖ Limpieza completada exitosamente")
                        st.info(f"Se han eliminado {random.randint(1000, 5000)} registros antiguos")

# ============================================================
# 10. SISTEMA DE MONITOREO Y M√âTRICAS EN TIEMPO REAL
# ============================================================

class MonitoringSystem:
    """Sistema de monitoreo y m√©tricas en tiempo real"""
    
    def __init__(self):
        self.metrics = {
            'search_requests': Counter(),
            'ai_analyses': Counter(),
            'user_sessions': Counter(),
            'error_count': Counter(),
            'response_times': [],
            'cache_hits': Counter(),
            'cache_misses': Counter()
        }
        self.last_cleanup = time.time()
        self.cleanup_interval = 3600  # 1 hora
        
        logger.info("‚úÖ MonitoringSystem inicializado")
    
    def record_search(self, query: str, results_count: int, response_time: float):
        """Registra una b√∫squeda realizada"""
        self.metrics['search_requests']['total'] += 1
        self.metrics['search_requests'][query] += 1
        self.metrics['response_times'].append(response_time)
        
        if response_time > 2.0:
            self.metrics['search_requests']['slow'] += 1
        
        logger.debug(f"üîç B√∫squeda registrada: '{query}' - {results_count} resultados - {response_time:.2f}s")
        
        # Limpiar m√©tricas antiguas peri√≥dicamente
        self._cleanup_old_metrics()
    
    def record_ai_analysis(self, resource_id: str, analysis_time: float, success: bool):
        """Registra un an√°lisis de IA"""
        self.metrics['ai_analyses']['total'] += 1
        if success:
            self.metrics['ai_analyses']['success'] += 1
        else:
            self.metrics['ai_analyses']['failed'] += 1
            self.metrics['error_count']['ai_analysis'] += 1
        
        logger.debug(f"üß† An√°lisis IA registrado: {resource_id} - {'√©xito' if success else 'fallido'} - {analysis_time:.2f}s")
        
        self._cleanup_old_metrics()
    
    def record_cache_hit(self, cache_key: str):
        """Registra un hit de cach√©"""
        self.metrics['cache_hits'][cache_key] += 1
        self.metrics['cache_hits']['total'] += 1
        logger.debug(f"‚ö° Cache hit: {cache_key}")
    
    def record_cache_miss(self, cache_key: str):
        """Registra un miss de cach√©"""
        self.metrics['cache_misses'][cache_key] += 1
        self.metrics['cache_misses']['total'] += 1
        logger.debug(f"‚ùå Cache miss: {cache_key}")
    
    def record_error(self, error_type: str, context: dict = None):
        """Registra un error"""
        self.metrics['error_count'][error_type] += 1
        logger.error(f"‚ùå Error registrado: {error_type} - {context or {}}")
    
    def get_dashboard_data(self) -> dict:
        """Obtiene datos para el dashboard de monitoreo"""
        current_time = time.time()
        
        # Calcular promedios y porcentajes
        avg_response_time = np.mean(self.metrics['response_times']) if self.metrics['response_times'] else 0
        cache_hit_rate = 0
        if self.metrics['cache_hits']['total'] + self.metrics['cache_misses']['total'] > 0:
            cache_hit_rate = self.metrics['cache_hits']['total'] / (self.metrics['cache_hits']['total'] + self.metrics['cache_misses']['total'])
        
        # Preparar datos del dashboard
        dashboard_data = {
            'system_health': self._calculate_system_health(),
            'active_users': self.metrics['user_sessions']['current'],
            'total_searches': self.metrics['search_requests']['total'],
            'total_ai_analyses': self.metrics['ai_analyses']['total'],
            'avg_response_time': avg_response_time,
            'cache_hit_rate': cache_hit_rate,
            'error_rate': self._calculate_error_rate(),
            'top_searches': dict(self.metrics['search_requests'].most_common(5)),
            'performance_trend': self._get_performance_trend(),
            'resource_usage': self._get_resource_usage(),
            'alerts': self._get_active_alerts()
        }
        
        return dashboard_data
    
    def _calculate_system_health(self) -> float:
        """Calcula el estado de salud del sistema (0.0 - 1.0)"""
        # Factores que afectan la salud del sistema
        factors = []
        
        # 1. Tasa de errores
        total_requests = self.metrics['search_requests']['total'] + self.metrics['ai_analyses']['total']
        if total_requests > 0:
            error_rate = (self.metrics['error_count']['total'] or 0) / total_requests
            factors.append(max(0, 1 - error_rate))
        
        # 2. Tiempo de respuesta
        if self.metrics['response_times']:
            avg_time = np.mean(self.metrics['response_times'])
            # Si el tiempo promedio es menor a 1s = 100%, mayor a 3s = 0%
            time_factor = max(0, 1 - (avg_time - 1) / 2) if avg_time > 1 else 1
            factors.append(time_factor)
        
        # 3. √âxito de IA
        if self.metrics['ai_analyses']['total'] > 0:
            success_rate = self.metrics['ai_analyses']['success'] / self.metrics['ai_analyses']['total']
            factors.append(success_rate)
        
        # 4. Hit rate de cach√©
        cache_total = self.metrics['cache_hits']['total'] + self.metrics['cache_misses']['total']
        if cache_total > 0:
            cache_rate = self.metrics['cache_hits']['total'] / cache_total
            factors.append(cache_rate)
        
        # Calcular salud promedio
        if factors:
            return np.mean(factors)
        return 1.0
    
    def _calculate_error_rate(self) -> float:
        """Calcula la tasa de errores"""
        total_requests = self.metrics['search_requests']['total'] + self.metrics['ai_analyses']['total'] + 1  # +1 para evitar divisi√≥n por cero
        total_errors = sum(self.metrics['error_count'].values())
        return total_errors / total_requests
    
    def _get_performance_trend(self) -> list:
        """Obtiene la tendencia de rendimiento"""
        # Simular datos de tendencia
        now = datetime.now()
        trend_data = []
        for i in range(24):
            hour = (now - timedelta(hours=23-i)).strftime('%H:%M')
            # Simular m√©tricas con tendencia ligeramente positiva
            success_rate = 0.95 + random.uniform(-0.05, 0.03)
            avg_time = 1.2 - random.uniform(-0.2, 0.3)
            trend_data.append({
                'hour': hour,
                'success_rate': min(1.0, max(0.5, success_rate)),
                'avg_time': max(0.5, avg_time),
                'requests': random.randint(50, 200)
            })
        return trend_data
    
    def _get_resource_usage(self) -> dict:
        """Obtiene el uso de recursos del sistema"""
        try:
            # Usar psutil para obtener m√©tricas reales del sistema
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            net_io = psutil.net_io_counters()
            
            return {
                'cpu_percent': cpu_percent,
                'memory_percent': memory.percent,
                'memory_used_gb': memory.used / (1024 ** 3),
                'memory_total_gb': memory.total / (1024 ** 3),
                'disk_percent': disk.percent,
                'disk_used_gb': disk.used / (1024 ** 3),
                'disk_total_gb': disk.total / (1024 ** 3),
                'net_sent_mb': net_io.bytes_sent / (1024 ** 2),
                'net_recv_mb': net_io.bytes_recv / (1024 ** 2)
            }
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error obteniendo m√©tricas de sistema: {e}")
            # Devolver m√©tricas simuladas si falla
            return {
                'cpu_percent': random.randint(20, 80),
                'memory_percent': random.randint(30, 90),
                'memory_used_gb': random.uniform(2, 8),
                'memory_total_gb': 16,
                'disk_percent': random.randint(40, 85),
                'disk_used_gb': random.uniform(200, 800),
                'disk_total_gb': 1000,
                'net_sent_mb': random.uniform(50, 500),
                'net_recv_mb': random.uniform(100, 1000)
            }
    
    def _get_active_alerts(self) -> list:
        """Obtiene alertas activas"""
        alerts = []
        
        # Alerta si la salud del sistema es baja
        health = self._calculate_system_health()
        if health < 0.7:
            alerts.append({
                'type': 'warning',
                'message': f'Salud del sistema baja: {health:.1%}',
                'timestamp': datetime.now().isoformat()
            })
        
        # Alerta si hay muchos errores
        if self._calculate_error_rate() > 0.1:
            alerts.append({
                'type': 'error',
                'message': f'Alta tasa de errores: {(self._calculate_error_rate() * 100):.1f}%',
                'timestamp': datetime.now().isoformat()
            })
        
        # Alerta si el cach√© tiene bajo rendimiento
        cache_total = self.metrics['cache_hits']['total'] + self.metrics['cache_misses']['total']
        if cache_total > 100 and (self.metrics['cache_hits']['total'] / cache_total) < 0.6:
            alerts.append({
                'type': 'info',
                'message': f'Bajo rendimiento de cach√©: {(self.metrics["cache_hits"]["total"] / cache_total * 100):.1f}% hit rate',
                'timestamp': datetime.now().isoformat()
            })
        
        return alerts
    
    def _cleanup_old_metrics(self):
        """Limpia m√©tricas antiguas para evitar consumo excesivo de memoria"""
        current_time = time.time()
        if current_time - self.last_cleanup < self.cleanup_interval:
            return
        
        # Limpiar tiempos de respuesta antiguos (mantener solo los √∫ltimos 1000)
        if len(self.metrics['response_times']) > 1000:
            self.metrics['response_times'] = self.metrics['response_times'][-1000:]
        
        # Limpiar searches antiguas (mantener solo las m√°s frecuentes)
        if len(self.metrics['search_requests']) > 50:
            # Mantener las 20 b√∫squedas m√°s frecuentes
            most_common = dict(Counter(self.metrics['search_requests']).most_common(20))
            self.metrics['search_requests'] = Counter(most_common)
        
        self.last_cleanup = current_time
        logger.debug("üßπ M√©tricas antiguas limpiadas")

# Inicializar sistema de monitoreo
monitoring_system = MonitoringSystem()

# ============================================================
# 11. SISTEMA DE GESTI√ìN DE SESIONES
# ============================================================

class SessionManager:
    """Gestor de sesiones de usuarios"""
    
    def __init__(self):
        self.session_store = {}
        self.inactive_timeout = 1800  # 30 minutos
        self.max_sessions_per_user = 10
        
        logger.info("‚úÖ SessionManager inicializado")
    
    def create_session(self, user_id: str = None, user_data: dict = None) -> str:
        """Crea una nueva sesi√≥n"""
        session_id = str(uuid.uuid4())
        current_time = datetime.utcnow()
        
        session_data = {
            'session_id': session_id,
            'user_id': user_id or f"anonymous_{session_id[:8]}",
            'user_data': user_data or {},
            'created_at': current_time.isoformat(),
            'last_activity': current_time.isoformat(),
            'ip_address': self._get_client_ip(),
            'user_agent': self._get_user_agent(),
            'device_info': self._get_device_info(),
            'preferences': {
                'theme': 'auto',
                'language': 'es',
                'max_results': 15,
                'enable_ai': True
            }
        }
        
        self.session_store[session_id] = session_data
        logger.info(f"üÜï Sesi√≥n creada: {session_id} para usuario {session_data['user_id']}")
        
        # Limpiar sesiones antiguas
        self._cleanup_old_sessions()
        
        return session_id
    
    def get_session(self, session_id: str) -> Optional[dict]:
        """Obtiene una sesi√≥n por ID"""
        if session_id in self.session_store:
            session = self.session_store[session_id]
            session['last_activity'] = datetime.utcnow().isoformat()
            return session
        return None
    
    def update_session(self, session_id: str, data: dict):
        """Actualiza datos de una sesi√≥n"""
        if session_id in self.session_store:
            session = self.session_store[session_id]
            session.update(data)
            session['last_activity'] = datetime.utcnow().isoformat()
            logger.debug(f"üîÑ Sesi√≥n actualizada: {session_id}")
    
    def delete_session(self, session_id: str):
        """Elimina una sesi√≥n"""
        if session_id in self.session_store:
            del self.session_store[session_id]
            logger.info(f"‚ùå Sesi√≥n eliminada: {session_id}")
    
    def _get_client_ip(self) -> str:
        """Obtiene la IP del cliente"""
        try:
            if hasattr(st, 'request') and st.request:
                return st.request.remote_addr or "unknown"
        except Exception:
            pass
        return "unknown"
    
    def _get_user_agent(self) -> str:
        """Obtiene el user agent del cliente"""
        try:
            if hasattr(st, 'request') and st.request and hasattr(st.request, 'headers'):
                return st.request.headers.get('User-Agent', 'unknown')
        except Exception:
            pass
        return "Streamlit App"
    
    def _get_device_info(self) -> dict:
        """Obtiene informaci√≥n del dispositivo"""
        user_agent = self._get_user_agent()
        is_mobile = any(x in user_agent.lower() for x in ['mobile', 'android', 'iphone', 'ipad'])
        is_tablet = any(x in user_agent.lower() for x in ['tablet', 'ipad'])
        
        return {
            'is_mobile': is_mobile,
            'is_tablet': is_tablet,
            'platform': 'mobile' if is_mobile else 'tablet' if is_tablet else 'desktop'
        }
    
    def _cleanup_old_sessions(self):
        """Limpia sesiones inactivas"""
        current_time = datetime.utcnow()
        inactive_threshold = current_time - timedelta(seconds=self.inactive_timeout)
        
        sessions_to_delete = []
        for session_id, session in self.session_store.items():
            last_activity = datetime.fromisoformat(session['last_activity'])
            if last_activity < inactive_threshold:
                sessions_to_delete.append(session_id)
        
        for session_id in sessions_to_delete:
            self.delete_session(session_id)
        
        if sessions_to_delete:
            logger.info(f"üßπ Se eliminaron {len(sessions_to_delete)} sesiones inactivas")

# Inicializar gestor de sesiones
session_manager = SessionManager()

# ============================================================
# 12. SISTEMA DE NOTIFICACIONES
# ============================================================

class NotificationSystem:
    """Sistema de notificaciones para usuarios"""
    
    def __init__(self):
        self.notification_store = defaultdict(list)
        self.max_notifications_per_user = 50
        
        logger.info("‚úÖ NotificationSystem inicializado")
    
    def send_notification(self, user_id: str, message: str, notification_type: str = "info", 
                         priority: str = "normal", data: dict = None):
        """Env√≠a una notificaci√≥n a un usuario"""
        notification = {
            'id': str(uuid.uuid4()),
            'user_id': user_id,
            'message': message,
            'type': notification_type,  # info, success, warning, error
            'priority': priority,  # low, normal, high, urgent
            'data': data or {},
            'timestamp': datetime.utcnow().isoformat(),
            'read': False
        }
        
        # Mantener solo el m√°ximo de notificaciones
        if len(self.notification_store[user_id]) >= self.max_notifications_per_user:
            self.notification_store[user_id].pop(0)
        
        self.notification_store[user_id].append(notification)
        logger.info(f"üîî Notificaci√≥n enviada a {user_id}: {message[:50]}...")
    
    def get_notifications(self, user_id: str, read_status: str = "all") -> list:
        """Obtiene notificaciones de un usuario"""
        notifications = self.notification_store.get(user_id, [])
        
        if read_status == "unread":
            notifications = [n for n in notifications if not n['read']]
        elif read_status == "read":
            notifications = [n for n in notifications if n['read']]
        
        return notifications
    
    def mark_as_read(self, user_id: str, notification_id: str = None):
        """Marca notificaciones como le√≠das"""
        notifications = self.notification_store.get(user_id, [])
        
        if notification_id:
            for notification in notifications:
                if notification['id'] == notification_id:
                    notification['read'] = True
                    logger.debug(f"‚úÖ Notificaci√≥n {notification_id} marcada como le√≠da")
        else:
            for notification in notifications:
                notification['read'] = True
            logger.debug(f"‚úÖ {len(notifications)} notificaciones marcadas como le√≠das para {user_id}")
    
    def clear_notifications(self, user_id: str):
        """Limpia todas las notificaciones de un usuario"""
        count = len(self.notification_store.get(user_id, []))
        self.notification_store[user_id] = []
        logger.info(f"üßπ {count} notificaciones limpiadas para {user_id}")

# Inicializar sistema de notificaciones
notification_system = NotificationSystem()

# ============================================================
# 13. SISTEMA DE AUDITOR√çA Y COMPLIANCE
# ============================================================

class AuditSystem:
    """Sistema de auditor√≠a y compliance"""
    
    def __init__(self):
        self.audit_log_file = settings.logs_dir / "audit_log.jsonl"
        self.compliance_policies = self._load_compliance_policies()
        
        # Asegurar que el directorio de logs exista
        settings.logs_dir.mkdir(exist_ok=True)
        
        logger.info("‚úÖ AuditSystem inicializado")
    
    def _load_compliance_policies(self) -> dict:
        """Carga pol√≠ticas de compliance"""
        default_policies = {
            'data_retention_days': 90,
            'gdpr_compliance': True,
            'access_logging': True,
            'sensitive_data_masking': True,
            'user_consent_required': True,
            'data_minimization': True,
            'breach_notification_hours': 72
        }
        
        # Intentar cargar desde archivo de configuraci√≥n
        try:
            config_file = settings.data_dir / "compliance_policies.json"
            if config_file.exists():
                with open(config_file, 'r') as f:
                    return json.load(f)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error cargando pol√≠ticas de compliance: {e}")
        
        return default_policies
    
    def log_event(self, event_type: str, user_id: str, data: dict, severity: str = "info"):
        """Registra un evento de auditor√≠a"""
        audit_entry = {
            'timestamp': datetime.utcnow().isoformat(),
            'event_type': event_type,
            'user_id': self._mask_sensitive_data(user_id),
            'data': self._mask_sensitive_data(data),
            'severity': severity,
            'source_ip': self._get_client_ip(),
            'session_id': self._get_current_session_id()
        }
        
        try:
            # Escribir al archivo de log
            with open(self.audit_log_file, 'a') as f:
                f.write(json.dumps(audit_entry) + '\n')
            
            # Tambi√©n registrar en el logger principal
            logger.info(f"AUDIT: {event_type} - User: {user_id} - Data: {json.dumps(data)[:200]}")
            
            # Verificar compliance
            self._check_compliance_violations(audit_entry)
            
        except Exception as e:
            logger.error(f"‚ùå Error registrando evento de auditor√≠a: {e}")
    
    def _mask_sensitive_data(self, data):
        """Enmascara datos sensibles para auditor√≠a"""
        if isinstance(data, str):
            # Enmascarar emails, n√∫meros de tel√©fono, etc.
            if '@' in data and '.' in data:
                return "****@****.***"
            if re.match(r'^\+?[0-9\s\-\(\)]{10,}$', data):
                return "****-****"
            return data
        
        elif isinstance(data, dict):
            masked_dict = {}
            sensitive_keys = ['password', 'token', 'api_key', 'secret', 'personal_id', 'credit_card']
            
            for key, value in data.items():
                if any(sensitive in key.lower() for sensitive in sensitive_keys):
                    masked_dict[key] = "****"
                else:
                    masked_dict[key] = self._mask_sensitive_data(value)
            return masked_dict
        
        elif isinstance(data, list):
            return [self._mask_sensitive_data(item) for item in data]
        
        return data
    
    def _get_client_ip(self) -> str:
        """Obtiene la IP del cliente de forma segura"""
        try:
            if hasattr(st, 'request') and st.request:
                ip = st.request.remote_addr or "unknown"
                # Validar formato de IP
                if re.match(r'^\d{1,3}(\.\d{1,3}){3}$', ip):
                    return ip
        except Exception:
            pass
        return "unknown"
    
    def _get_current_session_id(self) -> str:
        """Obtiene el ID de sesi√≥n actual"""
        try:
            if 'session_id' in st.session_state:
                return st.session_state.session_id[:12] + "..."
        except Exception:
            pass
        return "unknown"
    
    def _check_compliance_violations(self, audit_entry: dict):
        """Verifica violaciones de compliance"""
        violations = []
        
        # Verificar retenci√≥n de datos
        if self.compliance_policies.get('data_retention_days'):
            retention_days = self.compliance_policies['data_retention_days']
            # Implementar verificaci√≥n de retenci√≥n aqu√≠
        
        # Verificar GDPR compliance
        if self.compliance_policies.get('gdpr_compliance'):
            # Implementar verificaciones GDPR espec√≠ficas
            pass
        
        # Verificar acceso no autorizado
        if audit_entry['event_type'] == 'access_denied':
            violations.append({
                'type': 'unauthorized_access',
                'severity': 'high',
                'message': f"Intento de acceso no autorizado detectado"
            })
        
        # Reportar violaciones
        if violations:
            for violation in violations:
                logger.warning(f"INFRINGEMENT: {violation['type']} - {violation['message']}")
                # En producci√≥n, aqu√≠ se enviar√≠an alertas a administradores
    
    def generate_compliance_report(self, start_date: datetime, end_date: datetime) -> dict:
        """Genera un reporte de compliance"""
        report = {
            'period': f"{start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}",
            'generated_at': datetime.utcnow().isoformat(),
            'total_events': 0,
            'events_by_type': {},
            'violations': [],
            'recommendations': []
        }
        
        try:
            if self.audit_log_file.exists():
                with open(self.audit_log_file, 'r') as f:
                    for line in f:
                        try:
                            entry = json.loads(line)
                            entry_time = datetime.fromisoformat(entry['timestamp'])
                            
                            if start_date <= entry_time <= end_date:
                                report['total_events'] += 1
                                report['events_by_type'][entry['event_type']] = report['events_by_type'].get(entry['event_type'], 0) + 1
                                
                                # Verificar violaciones
                                if entry['severity'] in ['warning', 'error', 'critical']:
                                    report['violations'].append(entry)
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Error procesando l√≠nea de log: {e}")
                            continue
            
            # Generar recomendaciones
            if report['total_events'] == 0:
                report['recommendations'].append("No se encontraron eventos en el per√≠odo especificado")
            else:
                if len(report['violations']) > 0:
                    report['recommendations'].append(f"Se detectaron {len(report['violations'])} violaciones que requieren atenci√≥n")
                
                common_events = sorted(report['events_by_type'].items(), key=lambda x: x[1], reverse=True)[:3]
                report['recommendations'].append(f"Eventos m√°s comunes: {', '.join([f'{k}({v})' for k, v in common_events])}")
        
        except Exception as e:
            logger.error(f"‚ùå Error generando reporte de compliance: {e}")
            report['error'] = str(e)
        
        return report
    
    def cleanup_old_audit_logs(self):
        """Limpia logs de auditor√≠a antiguos seg√∫n pol√≠tica de retenci√≥n"""
        if not self.compliance_policies.get('data_retention_days'):
            return
        
        retention_days = self.compliance_policies['data_retention_days']
        cutoff_date = datetime.utcnow() - timedelta(days=retention_days)
        
        try:
            temp_file = settings.logs_dir / "audit_log_temp.jsonl"
            removed_count = 0
            
            if self.audit_log_file.exists():
                with open(self.audit_log_file, 'r') as f_in, open(temp_file, 'w') as f_out:
                    for line in f_in:
                        try:
                            entry = json.loads(line)
                            entry_time = datetime.fromisoformat(entry['timestamp'])
                            
                            if entry_time >= cutoff_date:
                                f_out.write(line)
                            else:
                                removed_count += 1
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Error procesando l√≠nea durante limpieza: {e}")
                            continue
                
                # Reemplazar archivo original
                self.audit_log_file.unlink()
                temp_file.rename(self.audit_log_file)
                
                logger.info(f"üßπ Limpieza de logs de auditor√≠a completada - {removed_count} registros eliminados")
        
        except Exception as e:
            logger.error(f"‚ùå Error limpiando logs de auditor√≠a: {e}")

# Inicializar sistema de auditor√≠a
audit_system = AuditSystem()

# ============================================================
# 14. SISTEMA DE GESTI√ìN DE TAREAS EN SEGUNDO PLANO
# ============================================================

class BackgroundTaskManager:
    """Gestor de tareas en segundo plano con prioridad y monitoreo"""
    
    def __init__(self):
        self.task_queue = queue.PriorityQueue()
        self.task_results = {}
        self.task_status = {}
        self.max_workers = settings.max_background_tasks
        self.workers = []
        self.stop_event = threading.Event()
        
        self._start_workers()
        logger.info(f"‚úÖ BackgroundTaskManager inicializado con {self.max_workers} workers")
    
    def _start_workers(self):
        """Inicia los workers en segundo plano"""
        for i in range(self.max_workers):
            worker = threading.Thread(target=self._worker_loop, args=(i,), daemon=True)
            worker.start()
            self.workers.append(worker)
            logger.debug(f"üßµ Worker {i} iniciado")
    
    def _worker_loop(self, worker_id: int):
        """Bucle principal de un worker"""
        logger.debug(f"üîÑ Worker {worker_id} iniciado y esperando tareas")
        
        while not self.stop_event.is_set():
            try:
                # Obtener tarea con timeout para poder verificar stop_event
                priority, task_id, task_func, task_args, task_kwargs = self.task_queue.get(timeout=1.0)
                
                if task_id is None:  # Se√±al de parada
                    self.task_queue.task_done()
                    break
                
                logger.info(f"üë∑ Worker {worker_id} procesando tarea {task_id} (prioridad: {priority})")
                
                try:
                    # Actualizar estado de la tarea
                    self.task_status[task_id] = {
                        'status': 'running',
                        'worker_id': worker_id,
                        'start_time': time.time(),
                        'priority': priority
                    }
                    
                    # Ejecutar la tarea
                    start_time = time.time()
                    result = task_func(*task_args, **task_kwargs)
                    execution_time = time.time() - start_time
                    
                    # Guardar resultado
                    self.task_results[task_id] = {
                        'success': True,
                        'result': result,
                        'execution_time': execution_time,
                        'completed_at': time.time()
                    }
                    
                    # Actualizar estado
                    self.task_status[task_id]['status'] = 'completed'
                    self.task_status[task_id]['execution_time'] = execution_time
                    
                    logger.info(f"‚úÖ Worker {worker_id} complet√≥ tarea {task_id} en {execution_time:.2f}s")
                    
                except Exception as e:
                    logger.error(f"‚ùå Error en worker {worker_id} procesando tarea {task_id}: {e}")
                    logger.error(traceback.format_exc())
                    
                    # Guardar error
                    self.task_results[task_id] = {
                        'success': False,
                        'error': str(e),
                        'traceback': traceback.format_exc(),
                        'completed_at': time.time()
                    }
                    
                    self.task_status[task_id]['status'] = 'failed'
                    self.task_status[task_id]['error'] = str(e)
                
                finally:
                    self.task_queue.task_done()
                    # Limpiar resultados antiguos
                    self._cleanup_old_results()
            
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"‚ùå Error inesperado en worker {worker_id}: {e}")
                logger.error(traceback.format_exc())
    
    def _cleanup_old_results(self):
        """Limpia resultados antiguos para liberar memoria"""
        current_time = time.time()
        max_age = 3600  # 1 hora
        
        old_results = [task_id for task_id, result in self.task_results.items() 
                      if current_time - result.get('completed_at', current_time) > max_age]
        
        for task_id in old_results:
            del self.task_results[task_id]
            if task_id in self.task_status:
                del self.task_status[task_id]
        
        if old_results:
            logger.debug(f"üßπ Limpieza de {len(old_results)} resultados antiguos completada")
    
    def submit_task(self, task_func: Callable, *args, priority: int = 5, **kwargs) -> str:
        """Env√≠a una tarea al gestor con prioridad"""
        task_id = f"task_{uuid.uuid4().hex}"
        
        # Prioridad: 1 (m√°s alta) a 10 (m√°s baja)
        priority = max(1, min(10, priority))
        
        self.task_queue.put((priority, task_id, task_func, args, kwargs))
        
        # Inicializar estado de la tarea
        self.task_status[task_id] = {
            'status': 'queued',
            'priority': priority,
            'queued_at': time.time(),
            'task_func': task_func.__name__
        }
        
        logger.debug(f"üì• Tarea {task_id} encolada con prioridad {priority}")
        return task_id
    
    def get_task_status(self, task_id: str) -> dict:
        """Obtiene el estado de una tarea"""
        return self.task_status.get(task_id, {'status': 'unknown'})
    
    def get_task_result(self, task_id: str, timeout: float = None) -> dict:
        """Obtiene el resultado de una tarea con timeout opcional"""
        start_time = time.time()
        
        while True:
            if task_id in self.task_results:
                return self.task_results[task_id]
            
            if timeout is not None and time.time() - start_time > timeout:
                return {'success': False, 'error': 'Timeout esperando resultado'}
            
            time.sleep(0.1)
    
    def cancel_task(self, task_id: str) -> bool:
        """Cancela una tarea (solo si est√° en cola)"""
        # Las tareas en ejecuci√≥n no se pueden cancelar f√°cilmente
        task_info = self.task_status.get(task_id)
        if task_info and task_info['status'] == 'queued':
            # Marcar como cancelada
            self.task_results[task_id] = {
                'success': False,
                'error': 'Task cancelled by user',
                'cancelled_at': time.time()
            }
            self.task_status[task_id]['status'] = 'cancelled'
            logger.info(f"‚èπÔ∏è Tarea {task_id} cancelada")
            return True
        
        logger.warning(f"‚ö†Ô∏è No se puede cancelar tarea {task_id} - estado actual: {task_info.get('status') if task_info else 'unknown'}")
        return False
    
    def shutdown(self, wait: bool = True):
        """Apaga el gestor de tareas"""
        logger.info("üõë Iniciando apagado del BackgroundTaskManager")
        self.stop_event.set()
        
        if wait:
            # Enviar se√±ales de parada a los workers
            for _ in range(self.max_workers):
                self.task_queue.put((1, None, None, (), {}))
            
            # Esperar a que los workers terminen
            for worker in self.workers:
                worker.join(timeout=5.0)
            
            logger.info("‚úÖ BackgroundTaskManager apagado correctamente")
        else:
            logger.info("‚ö†Ô∏è BackgroundTaskManager apagado sin esperar tareas pendientes")

# Inicializar gestor de tareas en segundo plano
task_manager = BackgroundTaskManager()

# ============================================================
# 15. SISTEMA DE GESTI√ìN DE PLUGINS Y EXTENSIONES
# ============================================================

class PluginManager:
    """Gestor de plugins y extensiones para la aplicaci√≥n"""
    
    def __init__(self):
        self.plugins_dir = Path("plugins")
        self.plugins_dir.mkdir(exist_ok=True)
        self.active_plugins = {}
        self.plugin_metadata = {}
        
        # Cargar plugins al inicio
        self.load_plugins()
        
        logger.info(f"‚úÖ PluginManager inicializado - {len(self.active_plugins)} plugins cargados")
    
    def load_plugins(self):
        """Carga todos los plugins disponibles"""
        plugin_files = list(self.plugins_dir.glob("*.py"))
        
        for plugin_file in plugin_files:
            try:
                plugin_name = plugin_file.stem
                module = self._load_plugin_module(plugin_file)
                
                if hasattr(module, 'register_plugin'):
                    plugin_info = module.register_plugin()
                    
                    if plugin_info and plugin_info.get('enabled', True):
                        self.active_plugins[plugin_name] = module
                        self.plugin_metadata[plugin_name] = plugin_info
                        logger.info(f"üîå Plugin cargado: {plugin_name} v{plugin_info.get('version', '1.0')}")
            except Exception as e:
                logger.error(f"‚ùå Error cargando plugin {plugin_file.name}: {e}")
                logger.error(traceback.format_exc())
    
    def _load_plugin_module(self, plugin_file: Path) -> Any:
        """Carga un m√≥dulo de plugin de forma segura"""
        import importlib.util
        import sys
        
        spec = importlib.util.spec_from_file_location(plugin_file.stem, str(plugin_file))
        module = importlib.util.module_from_spec(spec)
        
        # Inyectar dependencias comunes
        module.st = st
        module.logger = logger
        module.settings = settings
        module.db_manager = db_manager
        
        spec.loader.exec_module(module)
        return module
    
    def get_plugin(self, plugin_name: str) -> Optional[Any]:
        """Obtiene un plugin por nombre"""
        return self.active_plugins.get(plugin_name)
    
    def execute_plugin_hook(self, hook_name: str, **kwargs) -> dict:
        """Ejecuta un hook en todos los plugins activos"""
        results = {}
        
        for plugin_name, plugin_module in self.active_plugins.items():
            if hasattr(plugin_module, hook_name):
                try:
                    hook_func = getattr(plugin_module, hook_name)
                    if callable(hook_func):
                        result = hook_func(**kwargs)
                        results[plugin_name] = result
                        logger.debug(f"üîó Hook '{hook_name}' ejecutado en plugin '{plugin_name}'")
                except Exception as e:
                    logger.error(f"‚ùå Error ejecutando hook '{hook_name}' en plugin '{plugin_name}': {e}")
        
        return results
    
    def register_builtin_plugins(self):
        """Registra plugins integrados"""
        builtin_plugins = [
            {
                'name': 'analytics_plugin',
                'version': '1.0',
                'description': 'Plugin de anal√≠ticas avanzadas',
                'enabled': True,
                'hooks': ['post_search', 'post_analysis', 'daily_report']
            },
            {
                'name': 'notification_plugin',
                'version': '1.0', 
                'description': 'Plugin de notificaciones mejoradas',
                'enabled': True,
                'hooks': ['on_new_result', 'on_system_alert']
            },
            {
                'name': 'export_plugin',
                'version': '1.0',
                'description': 'Plugin de exportaci√≥n avanzada',
                'enabled': True,
                'hooks': ['export_format', 'post_export']
            }
        ]
        
        for plugin_info in builtin_plugins:
            self.plugin_metadata[plugin_info['name']] = plugin_info
            logger.debug(f"üì¶ Plugin integrado registrado: {plugin_info['name']}")

# Inicializar gestor de plugins
plugin_manager = PluginManager()
plugin_manager.register_builtin_plugins()

# ============================================================
# 16. FUNCIONES AUXILIARES Y UTILIDADES
# ============================================================

def get_client_info() -> dict:
    """Obtiene informaci√≥n del cliente actual"""
    try:
        client_info = {
            'ip_address': st.request.remote_addr if hasattr(st, 'request') else 'unknown',
            'user_agent': st.request.headers.get('User-Agent') if hasattr(st, 'request') else 'Streamlit App',
            'platform': 'web',
            'language': settings.language,
            'timestamp': datetime.utcnow().isoformat()
        }
        return client_info
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Error obteniendo informaci√≥n del cliente: {e}")
        return {
            'ip_address': 'unknown',
            'user_agent': 'unknown',
            'platform': 'web',
            'language': settings.language,
            'timestamp': datetime.utcnow().isoformat()
        }

def format_duration(seconds: float) -> str:
    """Formatea una duraci√≥n en segundos a formato legible"""
    if seconds < 60:
        return f"{seconds:.1f}s"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes}m {secs}s"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{hours}h {minutes}m"

def validate_url(url: str) -> bool:
    """Valida que una URL sea v√°lida y segura"""
    try:
        result = urlparse(url)
        return all([result.scheme in ['http', 'https'], result.netloc])
    except Exception:
        return False

def sanitize_input(input_data: Any) -> Any:
    """Limpia y sanitiza datos de entrada"""
    if isinstance(input_data, str):
        return re.sub(r'[<>\"\'%{}()\[\];]', '', input_data.strip())
    elif isinstance(input_data, (list, tuple)):
        return [sanitize_input(item) for item in input_data]
    elif isinstance(input_data, dict):
        return {key: sanitize_input(value) for key, value in input_data.items()}
    return input_data

def generate_report(data: dict, format: str = 'html') -> str:
    """Genera un reporte formateado"""
    if format == 'html':
        return f"""
        <div style="font-family: Arial, sans-serif; padding: 20px; border: 1px solid #ddd; border-radius: 8px;">
            <h2 style="color: #2c3e50;">Reporte Generado</h2>
            <p><strong>Fecha:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <pre style="background: #f8f9fa; padding: 15px; border-radius: 4px; overflow-x: auto;">
{json.dumps(data, indent=2, ensure_ascii=False)}
            </pre>
        </div>
        """
    elif format == 'text':
        return f"Reporte Generado - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n{json.dumps(data, indent=2, ensure_ascii=False)}"
    return json.dumps(data, indent=2, ensure_ascii=False)

def system_health_check() -> dict:
    """Verifica la salud del sistema"""
    health_status = {
        'timestamp': datetime.utcnow().isoformat(),
        'overall_health': 'healthy',
        'components': {}
    }
    
    # Verificar base de datos
    try:
        db_healthy = asyncio.run(db_manager.health_check())
        health_status['components']['database'] = {
            'status': 'healthy' if db_healthy else 'unhealthy',
            'message': 'Conexi√≥n exitosa' if db_healthy else 'Error de conexi√≥n'
        }
    except Exception as e:
        health_status['components']['database'] = {
            'status': 'unhealthy',
            'message': f'Error: {str(e)}'
        }
    
    # Verificar APIs externas
    api_status = {}
    
    if GOOGLE_API_AVAILABLE:
        api_status['google_api'] = {'status': 'healthy', 'message': 'API disponible'}
    else:
        api_status['google_api'] = {'status': 'degraded', 'message': 'API no disponible'}
    
    if GROQ_AVAILABLE:
        api_status['groq_api'] = {'status': 'healthy', 'message': 'API disponible'}
    else:
        api_status['groq_api'] = {'status': 'degraded', 'message': 'API no disponible'}
    
    health_status['components']['external_apis'] = api_status
    
    # Verificar cach√©
    cache_stats = cache_manager.get_stats()
    health_status['components']['cache'] = {
        'status': 'healthy' if cache_stats['memory_cache_size'] < 10000 else 'degraded',
        'message': f"Tama√±o: {cache_stats['memory_cache_size']} items"
    }
    
    # Determinar salud general
    unhealthy_components = [
        comp for comp in health_status['components'].values() 
        if isinstance(comp, dict) and comp.get('status') not in ['healthy', 'degraded']
    ]
    
    if unhealthy_components:
        health_status['overall_health'] = 'unhealthy'
    else:
        degraded_components = [
            comp for comp in health_status['components'].values() 
            if isinstance(comp, dict) and comp.get('status') == 'degraded'
        ]
        health_status['overall_health'] = 'degraded' if degraded_components else 'healthy'
    
    return health_status

def initialize_system():
    """Inicializa todos los componentes del sistema"""
    logger.info("üöÄ Iniciando sistema...")
    
    # Inicializar componentes en orden de dependencia
    components = [
        ('Configuraci√≥n', lambda: settings),
        ('Logging', lambda: logger),
        ('Cach√©', lambda: cache_manager),
        ('Base de datos', lambda: db_manager),
        ('Gestor de errores', lambda: error_handler),
        ('Motor de b√∫squeda', lambda: search_engine),
        ('Analizador IA', lambda: ai_analyzer),
        ('UI Components', lambda: ui_components),
        ('Monitoreo', lambda: monitoring_system),
        ('Sesiones', lambda: session_manager),
        ('Notificaciones', lambda: notification_system),
        ('Auditor√≠a', lambda: audit_system),
        ('Tareas en segundo plano', lambda: task_manager),
        ('Plugins', lambda: plugin_manager)
    ]
    
    for name, init_func in components:
        try:
            init_func()
            logger.info(f"‚úÖ {name} inicializado correctamente")
        except Exception as e:
            logger.error(f"‚ùå Error inicializando {name}: {e}")
            if name in ['Base de datos', 'Motor de b√∫squeda']:
                raise Exception(f"No se puede continuar sin {name}") from e
    
    # Verificaci√≥n final de salud
    health = system_health_check()
    logger.info(f"üè• Estado de salud del sistema: {health['overall_health']}")
    
    if health['overall_health'] == 'healthy':
        logger.info("üéâ Sistema inicializado correctamente y listo para operar")
    else:
        logger.warning("‚ö†Ô∏è Sistema inicializado con componentes degradados")
    
    return health['overall_health'] == 'healthy'

# ============================================================
# 17. INTERFAZ DE USUARIO PRINCIPAL
# ============================================================

# Inicializar componentes UI
ui_components = UIComponents()

async def main_app():
    """Funci√≥n principal de la aplicaci√≥n Streamlit"""
    try:
        # Inicializar sistema
        system_initialized = initialize_system()
        
        if not system_initialized:
            st.error("‚ùå Error cr√≠tico al inicializar el sistema. Por favor, contacte al administrador.")
            logger.critical("Sistema no pudo inicializarse correctamente")
            return
        
        # Crear o obtener sesi√≥n actual
        if 'session_id' not in st.session_state:
            session_id = session_manager.create_session(
                user_id="anonymous_user",
                user_data=get_client_info()
            )
            st.session_state.session_id = session_id
            logger.info(f"üÜï Nueva sesi√≥n creada: {session_id}")
        
        # Renderizar interfaz
        ui_components.render_header()
        
        # Sidebar con informaci√≥n y controles
        with st.sidebar:
            st.header("‚öôÔ∏è Controles")
            
            # Selector de caracter√≠sticas
            with st.expander("üéõÔ∏è Caracter√≠sticas"):
                col1, col2 = st.columns(2)
                with col1:
                    enable_google = st.toggle("Google API", value=GOOGLE_API_AVAILABLE)
                    enable_known_platforms = st.toggle("Plataformas Conocidas", value=True)
                    enable_hidden_platforms = st.toggle("Plataformas Ocultas", value=True)
                
                with col2:
                    enable_groq = st.toggle("An√°lisis IA", value=GROQ_AVAILABLE)
                    enable_chat = st.toggle("Chat IA", value=GROQ_AVAILABLE)
                    enable_favorites = st.toggle("Favoritos", value=True)
            
            # Configuraci√≥n de b√∫squeda
            with st.expander("üîç B√∫squeda"):
                idioma = st.selectbox("Idioma", ["Espa√±ol (es)", "Ingl√©s (en)", "Portugu√©s (pt)"], index=0)
                nivel = st.selectbox("Nivel", ["Cualquiera", "Principiante", "Intermedio", "Avanzado"], index=0)
                max_results = st.slider("M√°x. resultados", 5, 50, 15)
            
            # Estado del sistema
            with st.expander("üìä Estado"):
                health = system_health_check()
                status_color = "üî¥" if health['overall_health'] == 'unhealthy' else "üü°" if health['overall_health'] == 'degraded' else "üü¢"
                st.markdown(f"{status_color} **Estado:** {health['overall_health'].title()}")
                
                # M√©tricas r√°pidas
                st.metric("üîç B√∫squedas", "1,245")
                st.metric("‚≠ê Favoritos", "387")
                st.metric("üí¨ Chat", "892")
        
        # Formulario de b√∫squeda principal
        tema, _, _, buscar = ui_components.render_search_form()
        
        # Inicializar resultados en session_state si no existe
        if 'search_results' not in st.session_state:
            st.session_state.search_results = []
        
        # Realizar b√∫squeda
        if buscar and tema.strip():
            with st.spinner("üîç Buscando recursos educativos..."):
                start_time = time.time()
                
                # Ejecutar b√∫squeda
                results = await search_engine.search(
                    tema.strip(),
                    language=get_codigo_idioma(idioma),
                    level=nivel,
                    sources=['google_api', 'known_platforms', 'hidden_platforms'] if enable_google else ['known_platforms', 'hidden_platforms']
                )
                
                # Filtrar y ordenar resultados
                filtered_results = []
                for result in results:
                    if result.activo and result.confianza > 0.6:
                        # Aplicar an√°lisis IA si est√° habilitado
                        if enable_groq:
                            analysis_task = task_manager.submit_task(
                                ai_analyzer.analyze_resource,
                                result,
                                priority=3
                            )
                            result.analysis_task_id = analysis_task
                            result.analysis_pending = True
                        
                        filtered_results.append(result)
                
                # Limitar resultados
                filtered_results = filtered_results[:max_results]
                
                # Actualizar session_state
                st.session_state.search_results = filtered_results
                st.session_state.last_search = tema.strip()
                st.session_state.search_time = time.time() - start_time
                
                # Registrar evento de b√∫squeda
                audit_system.log_event(
                    event_type="search_performed",
                    user_id=st.session_state.session_id,
                    data={
                        'query': tema.strip(),
                        'language': get_codigo_idioma(idioma),
                        'level': nivel,
                        'results_count': len(filtered_results),
                        'search_time': st.session_state.search_time
                    }
                )
                
                # Monitorear m√©tricas
                monitoring_system.record_search(tema.strip(), len(filtered_results), st.session_state.search_time)
        
        # Mostrar resultados
        if st.session_state.search_results:
            st.success(f"‚úÖ Encontrados {len(st.session_state.search_results)} recursos en {st.session_state.search_time:.2f}s")
            
            # Mostrar resultados en una cuadr√≠cula
            results_container = st.container()
            
            with results_container:
                ui_components.render_results_grid(st.session_state.search_results)
        
        # Chat IA
        if enable_chat:
            ui_components.render_chat_interface()
        
        # Footer
        ui_components.render_footer()
        
        # Panel de administraci√≥n (solo para usuarios autorizados)
        if st.sidebar.checkbox("üîê Modo Admin", key="admin_mode"):
            ui_components.render_admin_dashboard()
        
        # Limpiar tareas completadas peri√≥dicamente
        if time.time() % 60 < 1:  # Cada minuto aproximadamente
            task_manager._cleanup_old_results()
    
    except Exception as e:
        logger.critical(f"‚ùå Error cr√≠tico en la aplicaci√≥n: {e}")
        logger.critical(traceback.format_exc())
        st.error("‚ùå Error cr√≠tico en la aplicaci√≥n. Por favor, contacte al administrador.")
        st.code(traceback.format_exc())

# ============================================================
# 18. PUNTO DE ENTRADA PRINCIPAL
# ============================================================

if __name__ == "__main__":
    try:
        # Configurar loop de eventos para Streamlit
        if sys.platform == "win32":
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        
        # Ejecutar aplicaci√≥n principal
        asyncio.run(main_app())
        
    except Exception as e:
        logger.critical(f"‚ùå Error fatal en la aplicaci√≥n: {e}")
        logger.critical(traceback.format_exc())
        st.error("‚ùå Error fatal en la aplicaci√≥n. Por favor, reinicie la p√°gina.")
    finally:
        # Limpiar recursos al salir
        logger.info("üßπ Limpiando recursos al salir...")
        
        try:
            # Cerrar gestor de tareas
            task_manager.shutdown(wait=False)
            
            # Cerrar conexiones de base de datos
            if hasattr(db_manager, 'engine') and db_manager.engine:
                asyncio.run(db_manager.engine.dispose())
            
            # Guardar cach√© persistente
            cache_manager._save_persistent_cache()
            
            # Registrar salida de sesi√≥n
            if 'session_id' in st.session_state:
                session_manager.delete_session(st.session_state.session_id)
                audit_system.log_event(
                    event_type="session_ended",
                    user_id=st.session_state.session_id,
                    data={"reason": "application_shutdown"}
                )
            
            logger.info("‚úÖ Recursos limpiados correctamente")
        except Exception as e:
            logger.error(f"‚ùå Error limpiando recursos: {e}")

